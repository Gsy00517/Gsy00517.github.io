{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5_4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, num_classes = 1000): #imagenet图像库总共1000个类\n",
    "        super(VGG, self).__init__() #先运行父类nn.Module初始化函数\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, padding = 1)\n",
    "        #定义图像卷积函数：输入为图像（3个频道，即RGB图）,输出为64张特征图,卷积核为3x3正方形，为保留原空间分辨率，卷积层的空间填充为1 \n",
    "        self.conv1_2 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = 1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1)\n",
    "        self.conv3_4 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        self.conv4_4 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.conv5_1 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        self.conv5_2 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        self.conv5_3 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        self.conv5_4 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True) #inplace=TRUE表示原地操作\n",
    "        self.max = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 4096) #定义全连接函数1为线性函数:y = Wx + b，并将512*7*7个节点连接到4096个节点上。\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, num_classes)\n",
    "        #定义全连接函数3为线性函数:y = Wx + b，并将4096个节点连接到num_classes个节点上，然后可用softmax进行处理。\n",
    "        \n",
    "        #定义该神经网络的向前传播函数，该函数必须定义，一旦定义成功，向后传播函数也会自动生成（autograd）\n",
    "    def forward(self, x):\n",
    "        \n",
    "        '''\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2) \n",
    "        #输入x经过卷积之后，经过激活函数ReLU，循环两次，最后使用2x2的窗口进行最大池化Max pooling，然后更新到x。\n",
    "        \n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = F.relu(self.conv3_4(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = F.relu(self.conv4_4(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = F.relu(self.conv5_4(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        '''\n",
    "        \n",
    "        x = self.relu(self.conv1_1(x))\n",
    "        x = self.relu(self.conv1_2(x))\n",
    "        x = self.max(x) \n",
    "        #输入x经过卷积之后，经过激活函数ReLU，循环两次，最后使用2x2的窗口进行最大池化Max pooling，然后更新到x。\n",
    "        \n",
    "        x = self.relu(self.conv2_1(x))\n",
    "        x = self.relu(self.conv2_2(x))\n",
    "        x = self.max(x)\n",
    "        \n",
    "        x = self.relu(self.conv3_1(x))\n",
    "        x = self.relu(self.conv3_2(x))\n",
    "        x = self.relu(self.conv3_3(x))\n",
    "        x = self.relu(self.conv3_4(x))\n",
    "        x = self.max(x)\n",
    "        \n",
    "        x = self.relu(self.conv4_1(x))\n",
    "        x = self.relu(self.conv4_2(x))\n",
    "        x = self.relu(self.conv4_3(x))\n",
    "        x = self.relu(self.conv4_4(x))\n",
    "        x = self.max(x)\n",
    "        \n",
    "        x = self.relu(self.conv5_1(x))\n",
    "        x = self.relu(self.conv5_2(x))\n",
    "        x = self.relu(self.conv5_3(x))\n",
    "        x = self.relu(self.conv5_4(x))\n",
    "        x = self.max(x)\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x)) #view函数将张量x变形成一维的向量形式,总特征数并不改变,为接下来的全连接作准备。\n",
    "        \n",
    "        x = self.fc1(x) #输入x经过全连接1，然后更新x\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  #all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "vgg = VGG()\n",
    "print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.6427e-03,  9.5972e-03,  3.1802e-03, -1.6605e-02,  7.7749e-03,\n",
      "         -4.6755e-06,  1.2260e-02, -1.6783e-02,  1.9200e-02,  9.9323e-03,\n",
      "          1.0036e-02, -8.4269e-03,  2.3675e-03,  3.3829e-04, -1.3941e-02,\n",
      "         -3.9470e-03, -8.5117e-03, -6.9154e-03,  1.4663e-02,  1.4120e-02,\n",
      "          1.3385e-02,  4.5843e-03,  1.2353e-02, -1.2247e-02, -8.1727e-03,\n",
      "         -3.5982e-03, -1.0310e-02, -7.2554e-04,  8.7842e-03, -1.3217e-02,\n",
      "         -1.2126e-02, -1.8038e-02, -1.4186e-02,  9.9829e-04,  5.5606e-03,\n",
      "         -9.4807e-03, -1.0584e-02,  2.2883e-03, -4.1121e-04,  8.6961e-03,\n",
      "          2.4678e-02,  4.3937e-03, -2.4083e-02,  1.2747e-02,  2.1663e-03,\n",
      "         -1.0824e-02, -3.9958e-03,  5.9723e-03,  2.0893e-02, -1.0801e-02,\n",
      "         -1.3865e-02,  1.2610e-02, -7.9556e-03, -3.9196e-05, -1.6392e-03,\n",
      "          9.1531e-03,  1.9092e-03,  1.6406e-02, -1.3884e-02,  5.4677e-03,\n",
      "          1.3263e-02, -2.1338e-03, -1.8960e-03,  3.6387e-03, -9.8764e-03,\n",
      "          1.4083e-02, -4.8285e-03, -7.7005e-03, -1.5765e-02,  1.6228e-02,\n",
      "          4.3773e-03,  3.7721e-04, -2.2257e-02, -5.9619e-03, -1.7009e-02,\n",
      "         -6.9728e-03, -2.2469e-04, -1.2805e-03, -1.4180e-02, -1.0116e-02,\n",
      "         -4.1949e-04,  1.2990e-02, -1.3292e-02,  1.4827e-02, -2.8267e-03,\n",
      "          1.5951e-02,  1.1575e-02, -1.6386e-02,  2.9515e-03,  1.1022e-03,\n",
      "          6.6162e-03, -6.1092e-03, -3.1078e-03,  8.7289e-03, -1.3258e-02,\n",
      "          8.4391e-03,  9.9864e-03, -1.8811e-02,  1.0285e-02, -1.1898e-02,\n",
      "          1.0858e-02,  3.3455e-03, -4.9247e-04, -7.5768e-03,  1.4277e-03,\n",
      "         -1.3173e-02,  1.3042e-02,  2.0237e-02,  1.9022e-02,  1.0947e-02,\n",
      "          8.1478e-04, -8.5628e-03,  1.1907e-02,  9.4544e-03,  1.3419e-02,\n",
      "          7.3222e-05, -1.1818e-02,  8.1762e-03, -1.8346e-03, -1.8282e-02,\n",
      "         -6.1963e-03,  1.8863e-02,  7.2011e-04,  8.8386e-03,  5.6887e-03,\n",
      "          4.1266e-03,  1.0760e-02,  1.7690e-02,  1.9907e-02, -9.1130e-03,\n",
      "          6.9195e-03,  1.0128e-02, -1.6769e-02, -1.3124e-02,  1.6171e-02,\n",
      "          2.2423e-03, -4.1874e-03, -1.8757e-02, -1.4330e-02, -2.5606e-02,\n",
      "         -8.9203e-04, -8.0548e-03, -3.9592e-03,  1.2242e-02,  5.5529e-03,\n",
      "          1.0633e-02, -1.0010e-02,  4.7139e-03, -5.7853e-03, -9.9166e-03,\n",
      "         -2.7560e-03,  1.0846e-03,  9.3651e-03,  1.0183e-02,  4.2705e-03,\n",
      "         -7.5619e-03,  3.1459e-04, -1.6698e-02,  3.6000e-03,  7.4526e-03,\n",
      "         -1.4184e-02, -1.2066e-02, -1.0014e-02,  4.3181e-03, -1.3622e-02,\n",
      "          2.1591e-02,  1.6202e-02,  1.0393e-02, -1.1146e-02, -9.2815e-03,\n",
      "          3.8808e-04, -8.4514e-03, -6.4912e-03, -5.1606e-03,  5.5776e-03,\n",
      "          1.1557e-02, -7.4315e-03, -3.2607e-03, -1.9140e-02, -2.7201e-03,\n",
      "          3.5882e-03,  9.8943e-04, -1.0081e-02, -1.5442e-04,  3.2437e-05,\n",
      "         -3.0869e-03,  6.5081e-03,  1.1125e-02, -9.4238e-03,  4.1777e-03,\n",
      "         -4.8905e-03,  1.0825e-02, -2.5060e-02, -1.6875e-03, -1.2606e-02,\n",
      "         -1.0708e-03, -1.5720e-02, -8.8483e-03, -1.3498e-02, -4.6205e-03,\n",
      "          4.1457e-03, -1.1221e-02, -8.2683e-03,  1.2307e-02,  1.3154e-03,\n",
      "         -7.2093e-03, -4.8295e-04,  1.1518e-02,  3.4358e-03,  1.7534e-03,\n",
      "         -5.4301e-03,  6.2644e-03,  9.0152e-03, -3.0369e-03,  5.9771e-03,\n",
      "         -1.2804e-02,  8.4943e-03,  1.1166e-02, -1.5625e-02,  5.6935e-03,\n",
      "          1.0372e-02,  3.5747e-03, -2.0200e-03,  1.1596e-02,  1.8629e-02,\n",
      "         -4.8529e-03,  4.4667e-03, -1.0946e-02, -1.9659e-02,  1.7970e-02,\n",
      "          1.2043e-02,  2.7623e-03, -1.2623e-02, -6.0015e-03,  4.6893e-04,\n",
      "         -6.6041e-03,  1.1748e-02, -1.1735e-02,  9.1011e-03,  2.5093e-03,\n",
      "          1.5025e-02,  8.3332e-03, -9.5247e-03,  6.0265e-03, -3.8247e-03,\n",
      "         -1.2917e-02, -1.4181e-03,  3.8355e-03, -4.7365e-03, -1.7812e-02,\n",
      "          7.0380e-03,  1.3039e-02, -1.5310e-02, -6.7217e-03, -1.2291e-02,\n",
      "          2.2722e-03,  1.1097e-02,  9.6662e-04, -6.5859e-03,  2.6134e-03,\n",
      "          1.7960e-03, -1.3604e-03,  5.1163e-03,  2.5935e-03, -2.2518e-03,\n",
      "          2.1003e-02,  1.4659e-03,  1.3738e-03,  6.5432e-03, -1.8892e-02,\n",
      "          3.7913e-03,  7.2347e-03, -1.7353e-02, -6.6464e-03,  9.1506e-03,\n",
      "         -2.7183e-03,  2.9820e-03, -1.5251e-02,  1.4591e-02, -1.8852e-02,\n",
      "          3.2160e-03, -1.4242e-02, -1.6335e-02,  7.9956e-03, -4.4227e-03,\n",
      "          3.2527e-03,  2.0126e-02, -1.2853e-02, -4.5590e-03,  6.3506e-03,\n",
      "         -7.7987e-03, -7.0545e-04,  1.0562e-02, -1.2983e-02, -2.6784e-03,\n",
      "         -1.2807e-02, -1.3523e-02, -1.4977e-03,  2.1694e-03,  2.3308e-02,\n",
      "         -1.0298e-02,  1.7110e-02,  1.2715e-02,  1.3766e-02,  8.3191e-03,\n",
      "          4.0755e-03, -1.2467e-02, -1.2698e-02,  2.2811e-03, -9.0822e-03,\n",
      "         -6.1540e-04, -1.3997e-03, -1.2238e-02, -7.0042e-03, -2.4653e-03,\n",
      "         -1.6370e-02, -3.2781e-03,  7.6374e-03, -6.1412e-03,  1.4372e-02,\n",
      "          3.1383e-03,  6.6265e-03, -8.1030e-03,  3.7686e-03, -1.4622e-03,\n",
      "          1.1617e-02,  6.4157e-03,  6.8971e-03,  2.1440e-04,  9.2363e-03,\n",
      "          8.4289e-03, -1.2143e-02, -1.1945e-02,  1.4737e-02,  2.1117e-02,\n",
      "         -7.7215e-03, -4.1042e-03, -5.5791e-04,  6.8290e-03, -8.4101e-03,\n",
      "         -5.2714e-03,  3.4148e-03, -3.3607e-03,  1.6492e-02,  5.7510e-03,\n",
      "          1.1247e-02,  7.2947e-03, -1.8422e-02, -1.0514e-03,  2.4426e-02,\n",
      "         -7.5497e-03,  4.1005e-03, -3.9398e-03, -8.6503e-03,  6.7649e-03,\n",
      "          1.9678e-02,  5.4220e-03,  2.4082e-02, -1.0933e-02, -1.3158e-03,\n",
      "         -1.0174e-02,  6.2089e-03, -2.3756e-02, -2.4745e-03, -6.2920e-03,\n",
      "         -2.6597e-03,  1.4065e-02, -1.4245e-02, -8.8602e-03,  1.1670e-02,\n",
      "         -2.3606e-02, -1.1594e-02,  3.5201e-03, -5.6888e-03, -1.6072e-02,\n",
      "          1.3026e-02, -6.7886e-03, -4.3301e-03, -6.7143e-03,  1.9882e-02,\n",
      "         -6.4950e-03,  7.8067e-03, -1.9299e-02, -1.3667e-02,  2.9580e-03,\n",
      "         -6.3886e-03,  1.7557e-03,  9.0066e-03, -3.5767e-03, -3.4201e-03,\n",
      "          1.0430e-02, -1.1768e-02, -3.6334e-03,  1.6085e-02, -4.9297e-03,\n",
      "          1.1265e-02,  3.5230e-03, -1.3477e-02,  2.3356e-02, -1.5824e-02,\n",
      "         -1.0521e-02, -1.2232e-02, -9.2313e-03, -1.3231e-03, -7.6708e-03,\n",
      "         -1.9652e-02, -5.0965e-03, -1.0022e-03,  1.3672e-02, -3.7650e-03,\n",
      "          2.1079e-04,  1.2643e-02,  1.2677e-03, -2.9273e-03, -2.3512e-02,\n",
      "         -6.3968e-03,  1.4387e-02,  4.1803e-03, -3.0263e-03,  8.4755e-03,\n",
      "          3.5673e-03, -1.1719e-02, -3.1779e-03, -1.0907e-02, -9.2651e-03,\n",
      "          1.4930e-02, -1.8936e-02, -1.5515e-02, -1.2360e-03,  3.3494e-04,\n",
      "          1.1000e-02, -1.2989e-03, -1.5206e-03,  1.0150e-02,  6.0000e-03,\n",
      "         -1.2800e-03, -3.1579e-03, -1.5726e-02,  7.9298e-03,  1.7253e-02,\n",
      "         -4.0593e-03,  1.6214e-04, -5.6970e-03,  3.0656e-03, -1.3798e-03,\n",
      "         -2.3444e-02, -3.8709e-03,  9.7896e-04, -1.5025e-02,  2.3148e-04,\n",
      "         -1.0306e-02, -1.7814e-03,  2.5182e-03,  3.6473e-03, -1.6662e-02,\n",
      "          2.8507e-04,  9.5926e-03, -1.6903e-02, -1.9050e-04,  1.0171e-02,\n",
      "          5.2261e-03, -7.2180e-03, -4.3463e-03,  1.1388e-03,  2.2883e-02,\n",
      "         -2.0564e-02, -2.9987e-03, -1.2733e-02, -8.1088e-03,  1.2589e-02,\n",
      "         -3.1711e-03,  1.3687e-02,  7.6119e-03, -1.2972e-02,  1.2551e-02,\n",
      "          2.3813e-03,  2.4782e-04,  3.0759e-03, -2.3873e-03, -1.6436e-02,\n",
      "         -7.5109e-03,  1.7808e-02,  5.4235e-03,  8.5468e-03, -1.1613e-02,\n",
      "         -6.1310e-03,  2.0450e-02, -1.3067e-03,  1.4373e-02,  8.8106e-03,\n",
      "          9.4023e-03, -1.2665e-02,  1.7381e-03,  1.7943e-03, -9.6851e-03,\n",
      "          1.9187e-02,  8.4883e-03, -1.8559e-02,  6.1082e-03,  1.7249e-02,\n",
      "          1.3214e-02, -6.6714e-04, -7.1124e-03,  1.5172e-02, -5.0100e-03,\n",
      "          5.3362e-03, -3.1882e-03,  8.9374e-03, -1.4855e-02,  7.2384e-03,\n",
      "         -1.3379e-02, -1.1486e-02, -3.6001e-03, -3.6015e-03,  4.2813e-04,\n",
      "         -1.5701e-02, -7.0601e-03,  1.2007e-02,  1.0104e-02, -1.6556e-02,\n",
      "          1.3100e-02,  2.4375e-03,  1.2153e-02, -1.0204e-02,  1.1881e-02,\n",
      "         -8.4740e-03, -2.8862e-03, -1.9218e-02, -3.6988e-03,  1.3252e-02,\n",
      "         -2.4397e-03,  7.7594e-03,  1.0938e-02, -4.8630e-03,  4.8576e-03,\n",
      "         -1.2071e-02, -8.5717e-03,  6.1677e-03,  7.7409e-03, -8.2284e-03,\n",
      "         -8.8186e-04, -6.0949e-03,  1.1341e-02,  1.5386e-02, -4.5908e-03,\n",
      "         -1.3050e-02,  1.2275e-02, -4.8149e-03, -5.3334e-03, -7.4672e-03,\n",
      "         -7.6722e-03,  1.0321e-02, -1.1575e-02, -5.6430e-03,  6.1892e-03,\n",
      "          8.4099e-03,  4.6101e-03,  1.3391e-02,  1.0893e-02, -4.5600e-03,\n",
      "          8.5779e-03,  9.9971e-03, -3.2002e-03, -3.8922e-03,  7.4023e-03,\n",
      "         -3.4899e-03, -1.5272e-03,  2.3089e-02, -1.6758e-02,  8.6489e-03,\n",
      "         -7.6571e-03,  1.5670e-03, -1.7694e-02,  2.3268e-02, -1.0404e-03,\n",
      "          1.5911e-02,  6.1504e-04,  8.1298e-03,  1.8148e-02, -8.2914e-04,\n",
      "          9.9010e-03, -7.7370e-03,  6.4001e-03,  3.5460e-03, -1.6841e-02,\n",
      "         -1.2731e-02,  1.0681e-02, -1.0203e-03,  1.7288e-02,  7.0204e-03,\n",
      "          7.0639e-03, -7.8190e-03, -6.2254e-03,  1.4306e-02,  2.7057e-03,\n",
      "          1.4777e-02,  2.0585e-03, -5.8257e-03, -7.1280e-03, -1.8323e-02,\n",
      "         -1.6223e-02, -1.4933e-02,  8.5513e-03,  4.8981e-03, -5.9076e-03,\n",
      "         -3.1886e-03, -7.1903e-03, -1.1584e-03,  6.8538e-04,  4.9023e-03,\n",
      "          1.1525e-02, -9.8511e-03, -2.7091e-04,  2.3337e-02,  8.9020e-03,\n",
      "          1.4239e-02,  1.0083e-02, -1.8972e-03, -1.0701e-02, -1.4961e-02,\n",
      "         -1.5733e-02, -1.3736e-02,  5.7604e-03, -3.2105e-03, -1.8176e-02,\n",
      "          1.1743e-02, -2.3702e-03,  1.2012e-02, -8.0075e-03, -4.2593e-03,\n",
      "         -1.1091e-02,  8.4491e-03,  1.2688e-03,  1.3469e-02, -1.1387e-02,\n",
      "         -1.6382e-02,  1.5451e-02, -7.4260e-03,  1.2259e-02,  1.7199e-02,\n",
      "         -3.9909e-04,  1.7391e-03,  1.0570e-02, -6.9442e-03,  2.5786e-03,\n",
      "          7.9490e-03, -2.3664e-02, -2.2497e-03, -3.3434e-03,  9.0960e-04,\n",
      "         -4.9112e-03,  2.1102e-02,  1.2441e-02, -9.5735e-04, -1.4160e-02,\n",
      "          2.6207e-03, -2.0267e-02, -2.1931e-03, -2.2968e-03,  3.3154e-03,\n",
      "         -1.8268e-02, -6.7622e-03, -5.6928e-03, -5.9474e-03, -1.8352e-02,\n",
      "         -2.5912e-04, -6.7914e-03,  1.8271e-02, -1.8116e-02, -1.2970e-02,\n",
      "          1.0824e-02, -5.5554e-03,  8.9469e-03,  1.0813e-03,  1.6063e-02,\n",
      "         -1.8807e-02,  3.3341e-03, -4.4697e-03,  1.0998e-02,  5.7596e-03,\n",
      "         -5.3960e-03, -1.5293e-02, -1.0948e-02,  9.9163e-03, -1.2389e-02,\n",
      "         -1.8976e-02,  1.1326e-02, -9.8263e-03, -4.3942e-03,  5.3275e-03,\n",
      "          1.2451e-02, -1.9558e-02, -4.1212e-04,  1.2883e-02, -6.9854e-03,\n",
      "          6.4856e-03, -8.5167e-03,  8.8022e-03,  1.1549e-02,  4.4414e-04,\n",
      "          3.3784e-03, -2.0123e-03, -2.4800e-02, -1.0893e-02, -9.3866e-03,\n",
      "         -4.4456e-04,  9.5169e-03,  6.6976e-03,  1.4936e-02,  1.1435e-02,\n",
      "         -1.2826e-02,  1.0602e-02,  4.8603e-03, -8.6997e-03, -2.0732e-02,\n",
      "          4.1723e-04, -1.1615e-02, -2.8016e-03, -9.0349e-03, -1.2934e-02,\n",
      "         -8.6288e-03, -4.6025e-03, -3.9875e-03,  7.1027e-03,  7.5448e-03,\n",
      "          1.0477e-02,  1.7449e-02, -1.0035e-02,  1.5985e-03, -1.3452e-02,\n",
      "         -2.8002e-03,  2.9650e-03, -2.0665e-03,  2.1550e-03, -7.9691e-04,\n",
      "         -5.7492e-03,  1.1520e-02,  1.0150e-02,  2.3187e-03, -1.9657e-02,\n",
      "          5.3587e-03, -2.8030e-03,  1.0514e-02,  6.4968e-03, -1.9763e-02,\n",
      "         -1.2303e-03,  6.5426e-03, -1.7575e-03, -1.5258e-03, -1.1755e-02,\n",
      "         -5.4871e-03,  2.4839e-03, -1.0131e-02, -2.7023e-03,  4.1987e-03,\n",
      "         -3.8990e-03, -1.3731e-03, -1.4572e-02, -1.4084e-02,  1.8120e-02,\n",
      "          1.8637e-04,  1.4551e-03, -1.0463e-03, -1.5465e-02, -1.3836e-02,\n",
      "         -9.7135e-03,  1.9274e-02,  1.1274e-04,  1.1596e-02,  4.6173e-03,\n",
      "         -8.0315e-03,  1.9383e-02,  9.8101e-03,  2.3053e-03,  1.6713e-02,\n",
      "          3.0918e-03,  4.3221e-03,  1.0289e-02, -9.0308e-04, -1.5946e-02,\n",
      "          8.8841e-03, -6.3083e-03, -2.8051e-02, -3.1819e-04,  7.0254e-03,\n",
      "          8.1304e-03,  1.0984e-02,  1.2294e-02,  6.3559e-03,  5.5714e-03,\n",
      "          2.0740e-05,  7.5111e-03,  7.2449e-03, -5.6449e-03, -2.6836e-02,\n",
      "         -6.6896e-03,  1.7039e-02, -8.5625e-03, -1.6271e-02,  1.5518e-02,\n",
      "         -8.6852e-03,  3.4914e-03, -9.1022e-03, -1.0701e-02, -6.2884e-03,\n",
      "         -3.3671e-03, -1.4801e-02, -1.6036e-02,  1.3159e-02,  6.6186e-03,\n",
      "         -2.3014e-02, -5.8956e-03,  1.6069e-03, -9.1324e-03,  7.0336e-03,\n",
      "          3.4166e-03, -9.0370e-03, -1.1715e-02, -1.8889e-02,  1.3134e-02,\n",
      "          1.7538e-04,  5.8426e-03, -1.7656e-02,  1.0442e-02,  1.5378e-02,\n",
      "          5.6290e-03,  2.3090e-03, -7.4161e-03,  5.9560e-03,  3.7046e-03,\n",
      "         -2.0505e-04,  3.1461e-04, -9.8634e-03,  1.8414e-02, -1.1832e-02,\n",
      "          5.4122e-04,  2.8931e-03, -1.1024e-02, -5.3821e-03,  6.6850e-03,\n",
      "         -6.4666e-03, -8.2349e-03, -1.5277e-04, -1.6822e-02,  2.6197e-03,\n",
      "          5.5684e-03, -4.3098e-03, -6.0721e-03, -1.0658e-03, -1.9747e-03,\n",
      "          1.0443e-02,  5.9312e-03,  1.1370e-02, -2.4830e-02, -1.2766e-02,\n",
      "          1.6508e-05, -1.1396e-02, -2.1636e-02,  1.4448e-02,  3.6800e-03,\n",
      "         -9.9228e-04, -2.1058e-03, -1.5625e-02, -1.9029e-02,  2.2594e-03,\n",
      "         -1.0669e-02, -8.1791e-03,  2.2892e-03,  1.1905e-03, -1.6217e-02,\n",
      "         -1.3113e-02, -2.9596e-04, -1.2954e-02,  2.1116e-02,  1.0086e-02,\n",
      "         -1.7484e-02, -2.0205e-03,  8.0593e-03, -3.8674e-03, -1.2913e-02,\n",
      "          2.2101e-02,  1.5129e-02,  2.9601e-04,  1.6110e-02,  1.0012e-02,\n",
      "          7.3931e-03,  1.0423e-02, -1.8864e-02,  6.4327e-03,  6.8865e-03,\n",
      "         -1.2433e-03,  1.9774e-02, -1.3987e-02,  7.8015e-03,  6.3156e-03,\n",
      "          3.8850e-03,  7.4771e-03, -8.8864e-03,  1.3932e-02, -7.5197e-03,\n",
      "          4.5223e-03,  6.2259e-03,  6.5164e-03,  5.9324e-03, -1.6010e-02,\n",
      "          2.2342e-03, -1.4224e-02,  5.0055e-05,  5.5092e-03,  1.3291e-02,\n",
      "          2.5887e-02,  1.0570e-02, -6.9809e-03,  1.6479e-02,  9.2960e-03,\n",
      "         -6.4759e-03,  3.9383e-03, -2.8155e-03, -5.1462e-03,  1.2679e-02,\n",
      "          1.3585e-02, -2.9645e-03,  5.4717e-04,  4.1787e-03,  7.7525e-03,\n",
      "         -9.8588e-03, -1.0228e-02,  1.6144e-02,  7.3597e-03,  4.2179e-03,\n",
      "         -1.0375e-02,  1.1142e-02,  3.6584e-04, -5.9498e-03, -2.3804e-03,\n",
      "          5.8060e-03, -6.4595e-03, -5.5685e-03, -2.2865e-03,  7.3089e-03,\n",
      "          1.2161e-02, -8.2525e-03, -1.0095e-02,  9.4414e-03, -1.8272e-02,\n",
      "         -8.4108e-03,  4.2161e-03, -1.3917e-02, -1.3479e-02, -1.4907e-02,\n",
      "          1.2710e-02, -5.2526e-03, -1.0111e-02, -9.7907e-03,  9.5825e-03,\n",
      "          1.3245e-03,  1.4438e-02,  6.2285e-03, -2.1942e-03, -1.3018e-02,\n",
      "         -1.8710e-02, -2.1542e-03, -7.6228e-04, -1.8284e-02,  6.9243e-03,\n",
      "          3.4510e-04, -2.2258e-03, -4.0624e-03, -1.0673e-02,  1.9211e-02,\n",
      "         -1.2226e-02, -1.5755e-03,  1.3548e-02, -1.9488e-02,  4.6195e-04,\n",
      "          4.3438e-03, -1.4564e-02, -1.5251e-03, -1.6247e-02, -3.8843e-04,\n",
      "         -5.6329e-03, -1.0888e-02,  1.1564e-02, -1.1263e-02,  9.1323e-04,\n",
      "          8.4115e-03,  2.1347e-03, -4.9832e-03, -7.2855e-03, -1.6975e-03,\n",
      "          5.0085e-03, -1.2024e-02,  9.5338e-03, -3.0338e-03,  1.5675e-02,\n",
      "         -2.7011e-03, -1.9971e-02,  4.0214e-03,  5.8378e-03,  6.2522e-03]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 3, 224, 224)\n",
    "out = vgg(input)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
