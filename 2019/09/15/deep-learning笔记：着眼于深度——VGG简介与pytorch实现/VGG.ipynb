{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4_4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5_4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (fc3): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, num_classes = 1000): #imagenet图像库总共1000个类\n",
    "        super(VGG, self).__init__() #先运行父类nn.Module初始化函数\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, padding = 1)\n",
    "        #定义图像卷积函数：输入为图像（3个频道，即RGB图）,输出为64张特征图,卷积核为3x3正方形，为保留原空间分辨率，卷积层的空间填充为1 \n",
    "        self.conv1_2 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = 1)\n",
    "        self.conv2_2 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = 1)\n",
    "        self.conv3_2 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1)\n",
    "        self.conv3_3 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1)\n",
    "        self.conv3_4 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        self.conv4_2 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        self.conv4_3 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        self.conv4_4 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.conv5_1 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        self.conv5_2 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        self.conv5_3 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        self.conv5_4 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = 1)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True) #inplace=TRUE表示原地操作\n",
    "        self.max = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 4096) #定义全连接函数1为线性函数:y = Wx + b，并将512*7*7个节点连接到4096个节点上。\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, num_classes)\n",
    "        #定义全连接函数3为线性函数:y = Wx + b，并将4096个节点连接到num_classes个节点上，然后可用softmax进行处理。\n",
    "        \n",
    "        #定义该神经网络的向前传播函数，该函数必须定义，一旦定义成功，向后传播函数也会自动生成（autograd）\n",
    "    def forward(self, x):\n",
    "        \n",
    "        '''\n",
    "        x = F.relu(self.conv1_1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2) \n",
    "        #输入x经过卷积之后，经过激活函数ReLU，循环两次，最后使用2x2的窗口进行最大池化Max pooling，然后更新到x。\n",
    "        \n",
    "        x = F.relu(self.conv2_1(x))\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        x = F.relu(self.conv3_1(x))\n",
    "        x = F.relu(self.conv3_2(x))\n",
    "        x = F.relu(self.conv3_3(x))\n",
    "        x = F.relu(self.conv3_4(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        x = F.relu(self.conv4_1(x))\n",
    "        x = F.relu(self.conv4_2(x))\n",
    "        x = F.relu(self.conv4_3(x))\n",
    "        x = F.relu(self.conv4_4(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        \n",
    "        x = F.relu(self.conv5_1(x))\n",
    "        x = F.relu(self.conv5_2(x))\n",
    "        x = F.relu(self.conv5_3(x))\n",
    "        x = F.relu(self.conv5_4(x))\n",
    "        x = F.max_pool2d(x, kernel_size = 2, stride = 2)\n",
    "        '''\n",
    "        \n",
    "        x = self.relu(self.conv1_1(x))\n",
    "        x = self.relu(self.conv1_2(x))\n",
    "        x = self.max(x) \n",
    "        #输入x经过卷积之后，经过激活函数ReLU，循环两次，最后使用2x2的窗口进行最大池化Max pooling，然后更新到x。\n",
    "        \n",
    "        x = self.relu(self.conv2_1(x))\n",
    "        x = self.relu(self.conv2_2(x))\n",
    "        x = self.max(x)\n",
    "        \n",
    "        x = self.relu(self.conv3_1(x))\n",
    "        x = self.relu(self.conv3_2(x))\n",
    "        x = self.relu(self.conv3_3(x))\n",
    "        x = self.relu(self.conv3_4(x))\n",
    "        x = self.max(x)\n",
    "        \n",
    "        x = self.relu(self.conv4_1(x))\n",
    "        x = self.relu(self.conv4_2(x))\n",
    "        x = self.relu(self.conv4_3(x))\n",
    "        x = self.relu(self.conv4_4(x))\n",
    "        x = self.max(x)\n",
    "        \n",
    "        x = self.relu(self.conv5_1(x))\n",
    "        x = self.relu(self.conv5_2(x))\n",
    "        x = self.relu(self.conv5_3(x))\n",
    "        x = self.relu(self.conv5_4(x))\n",
    "        x = self.max(x)\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x)) #view函数将张量x变形成一维的向量形式,总特征数并不改变,为接下来的全连接作准备。\n",
    "        \n",
    "        x = self.fc1(x) #输入x经过全连接1，然后更新x\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  #all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "vgg = VGG()\n",
    "print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.6930e-04, -1.2858e-02,  1.4560e-02, -1.1398e-02, -2.7681e-03,\n",
      "          1.9526e-03,  3.2673e-03,  9.3997e-04, -8.0323e-03,  1.4868e-02,\n",
      "          5.3629e-03,  1.2219e-02, -2.3189e-03, -4.6629e-03, -1.2333e-02,\n",
      "          1.4715e-02, -3.4259e-03,  1.2734e-02, -3.4117e-03, -9.0783e-03,\n",
      "          7.3091e-03, -1.3552e-02,  2.0448e-03, -6.9766e-03, -5.5218e-03,\n",
      "          6.8434e-03,  5.7853e-03,  1.2266e-02,  1.2640e-02, -5.1145e-03,\n",
      "          3.3651e-03, -1.1021e-02, -1.8222e-02,  7.9006e-03,  5.9719e-03,\n",
      "         -8.7177e-03,  7.0143e-06,  1.0694e-02,  1.5275e-02, -1.3986e-02,\n",
      "         -8.9050e-03, -6.3402e-04,  1.1830e-02,  1.2600e-03, -1.2570e-03,\n",
      "          9.0288e-03, -5.1945e-03, -1.0277e-02,  1.3896e-02, -4.9178e-03,\n",
      "         -1.6270e-02,  1.5308e-02, -7.3821e-03, -5.5639e-03,  1.4749e-03,\n",
      "         -3.6655e-03, -5.2353e-03, -1.3244e-02, -9.8176e-04, -8.9970e-04,\n",
      "          1.8033e-03,  1.7773e-02, -2.3198e-03,  8.1871e-03, -1.0822e-02,\n",
      "         -1.3075e-02, -4.5852e-03,  1.8901e-02, -6.1739e-03, -3.4756e-03,\n",
      "          1.5189e-02,  2.2038e-03, -7.3815e-03, -1.1059e-02,  1.1285e-02,\n",
      "         -8.3551e-03,  1.5719e-03, -1.1803e-02, -6.9091e-03, -1.6805e-02,\n",
      "         -2.6267e-03, -1.1770e-02, -2.5057e-03, -1.9944e-04,  1.2266e-02,\n",
      "          1.5802e-02, -8.3234e-03, -1.3691e-02, -1.8025e-03,  5.7065e-03,\n",
      "          1.9073e-02, -4.0018e-03,  3.4685e-03,  1.3203e-02, -1.0087e-02,\n",
      "          4.7171e-03, -6.4738e-03,  7.4388e-04, -4.2449e-03, -4.2881e-03,\n",
      "          3.6859e-03,  3.6656e-03, -2.1517e-03, -9.1010e-04,  4.6374e-03,\n",
      "         -1.1556e-02, -3.5697e-03,  3.8018e-03, -5.1916e-04, -4.4825e-04,\n",
      "         -1.4141e-02, -1.4707e-02,  8.4397e-03, -9.7133e-03, -1.4554e-02,\n",
      "          1.1923e-02, -5.3439e-03, -1.3184e-02,  2.1529e-03,  1.6761e-03,\n",
      "         -5.0496e-03, -7.4994e-03, -2.3329e-03,  2.9153e-03, -1.6481e-02,\n",
      "          2.6767e-03,  5.1203e-03, -6.7679e-03,  1.4766e-02, -1.7560e-02,\n",
      "          6.3907e-03, -9.6675e-03,  7.3024e-04, -4.9552e-03, -1.2775e-02,\n",
      "         -7.1166e-03,  1.7661e-02,  6.2578e-03, -1.0691e-02,  2.4832e-03,\n",
      "         -1.3122e-02,  1.5139e-02,  1.9727e-02,  1.0332e-02, -2.9184e-03,\n",
      "         -1.2023e-03, -2.1420e-02, -3.5689e-03, -8.5612e-03,  2.3535e-03,\n",
      "          6.5299e-03, -6.7756e-03, -2.6133e-04, -1.3615e-02, -7.8641e-03,\n",
      "         -1.6738e-02,  1.6984e-02, -6.0307e-03,  9.9395e-03, -2.0195e-03,\n",
      "          4.6851e-03,  1.4706e-02, -1.1037e-02, -5.7042e-03,  2.2979e-02,\n",
      "         -5.6231e-03,  1.9182e-02, -1.2516e-02,  1.8986e-03,  7.4788e-03,\n",
      "          4.0110e-04, -9.3576e-03, -3.0289e-03,  6.7273e-05, -6.8615e-03,\n",
      "          4.3802e-03,  8.4476e-03, -7.7407e-03,  4.9489e-03, -1.5206e-02,\n",
      "         -2.1037e-03,  4.9483e-03,  4.7505e-03,  1.7458e-02, -1.0228e-02,\n",
      "         -9.6235e-04, -8.1118e-03, -9.8347e-03, -1.4025e-02, -7.8657e-03,\n",
      "          9.3259e-03,  1.9761e-02,  1.9855e-02, -3.9474e-03, -8.4119e-03,\n",
      "         -8.8459e-03,  1.7118e-02,  2.7488e-03, -6.2624e-04,  4.0948e-03,\n",
      "         -4.7633e-03,  3.5349e-03,  2.1149e-04,  9.8729e-03,  5.7706e-03,\n",
      "          1.3364e-02, -9.9090e-03,  3.1699e-03, -5.9787e-03,  2.4680e-02,\n",
      "         -5.0705e-03,  4.2453e-03, -1.0628e-02,  1.4203e-02, -9.1798e-03,\n",
      "         -1.9912e-02,  1.6381e-02, -1.0716e-02, -7.4044e-03,  4.8157e-03,\n",
      "          7.6975e-03,  4.9346e-03,  2.5097e-02,  8.1092e-03, -1.5671e-02,\n",
      "          4.1802e-04, -5.8481e-03,  5.9916e-03,  1.0922e-04, -3.9122e-04,\n",
      "         -9.3012e-03,  1.8903e-02, -1.2453e-02,  2.9231e-03, -1.1319e-02,\n",
      "          6.2631e-03, -1.7907e-03, -8.8298e-03, -1.6671e-02,  1.1899e-02,\n",
      "         -2.0674e-02, -6.6308e-03, -1.8310e-02,  1.0834e-02,  8.4142e-03,\n",
      "          7.6229e-03, -4.6318e-03, -8.3346e-04, -2.0113e-02,  2.1230e-03,\n",
      "         -4.7345e-03,  2.5676e-03,  2.0426e-02, -1.4028e-02, -1.4268e-02,\n",
      "          1.3952e-02,  1.2038e-02,  7.5165e-03, -1.0505e-02, -2.5694e-04,\n",
      "         -1.2413e-02,  5.0402e-03, -4.3644e-03,  3.4614e-03,  6.7457e-03,\n",
      "         -1.4154e-02,  2.0642e-03, -1.4014e-02, -8.9839e-03, -1.3731e-02,\n",
      "         -1.0388e-02,  9.2716e-03,  1.1974e-02, -2.3464e-02, -1.5310e-02,\n",
      "          1.3568e-03,  1.1480e-02,  1.6657e-02, -1.6082e-02, -1.1949e-02,\n",
      "          1.1368e-04,  1.0612e-02, -1.3114e-02,  2.7562e-03, -1.3868e-03,\n",
      "         -1.5938e-02,  1.9244e-02,  8.3785e-03,  6.2931e-03,  2.6962e-03,\n",
      "          1.0691e-02, -7.4148e-03, -6.0618e-04,  2.9177e-03, -2.1171e-03,\n",
      "         -3.6290e-03,  1.1890e-02,  1.0045e-02,  1.9629e-02, -6.2131e-03,\n",
      "         -7.7234e-03,  3.0837e-03, -2.2835e-03, -5.7956e-03,  1.2950e-02,\n",
      "          4.8792e-04,  1.0293e-03,  8.4881e-03, -3.2911e-03, -1.6196e-03,\n",
      "         -1.3113e-02, -1.8513e-02, -1.3364e-02,  6.6027e-03, -2.6911e-03,\n",
      "         -4.9002e-03, -6.9412e-03, -4.4737e-03,  5.1503e-03,  6.9605e-03,\n",
      "          4.7832e-03,  1.0829e-02,  6.3903e-03,  1.6976e-02,  1.9001e-02,\n",
      "         -1.8096e-02, -3.5778e-03,  5.5311e-03, -9.0013e-03,  2.9177e-02,\n",
      "         -6.3953e-03,  4.1752e-03,  1.2061e-02, -9.5352e-03,  1.0585e-02,\n",
      "          5.8797e-03, -1.7453e-02, -1.3514e-02,  1.9128e-02, -7.8493e-03,\n",
      "         -6.8864e-03, -5.8100e-04, -1.8232e-02, -2.0613e-03, -6.8719e-03,\n",
      "          3.1012e-03, -1.5171e-03, -3.6055e-03,  1.7614e-02,  1.5611e-02,\n",
      "         -1.4043e-02, -1.0513e-02, -4.5229e-03, -1.1819e-02, -9.9530e-03,\n",
      "         -2.1879e-02,  1.3694e-02,  1.6867e-03,  3.2829e-03,  2.1724e-02,\n",
      "          1.8783e-02,  1.7502e-03,  1.3465e-02,  1.1735e-02, -1.1980e-03,\n",
      "         -1.3264e-03,  4.3508e-03, -1.4747e-02,  1.0812e-02,  1.3084e-02,\n",
      "          7.2186e-03, -6.1893e-03, -4.5481e-03, -1.8963e-02,  1.2792e-02,\n",
      "         -1.4114e-02, -2.9169e-03,  1.3827e-02, -1.2974e-02, -3.4847e-03,\n",
      "         -2.6853e-03, -1.3767e-02,  8.3571e-03, -2.1587e-03,  5.7473e-03,\n",
      "          1.5258e-02,  2.9661e-03,  4.9376e-03,  2.2858e-02, -1.2505e-02,\n",
      "          9.8714e-03,  6.6894e-03,  6.3513e-03, -9.4410e-03, -1.2568e-02,\n",
      "          2.1702e-02,  7.2691e-03,  1.5984e-02, -9.8814e-03, -1.5993e-02,\n",
      "          8.1532e-03,  5.6599e-03,  6.9698e-04, -3.2609e-04, -1.1357e-02,\n",
      "          1.6423e-02, -4.2607e-03,  8.2830e-03, -1.5570e-02,  5.6272e-04,\n",
      "         -9.8142e-03,  2.1942e-03, -1.1045e-02, -9.3086e-03, -2.4650e-03,\n",
      "          1.8795e-02, -8.4651e-03, -3.7697e-03, -8.4142e-04,  1.4121e-02,\n",
      "         -9.8227e-03,  5.3882e-03,  6.3506e-03, -1.1517e-02, -9.8017e-03,\n",
      "         -2.2441e-02, -3.9106e-03, -1.2337e-02,  8.9398e-03, -8.8311e-03,\n",
      "          5.9729e-03,  4.0031e-04, -1.8977e-03,  7.6193e-03,  7.7978e-03,\n",
      "          6.4110e-03, -8.6283e-03,  1.0231e-02,  1.4659e-04, -4.5894e-03,\n",
      "          1.5476e-02, -1.0840e-03,  1.9101e-03, -8.3134e-03, -9.2042e-03,\n",
      "         -1.1530e-02,  1.6321e-02,  1.4894e-02,  1.2163e-03,  1.0024e-02,\n",
      "         -1.0015e-02,  1.0083e-02, -4.1479e-03, -1.4563e-02, -7.5359e-03,\n",
      "         -1.8347e-02,  4.1281e-03,  4.4105e-03,  1.2966e-02,  1.2208e-02,\n",
      "          1.1858e-02, -1.7196e-03,  1.3637e-02,  5.1986e-03,  7.5870e-03,\n",
      "          8.5425e-03,  1.5674e-02,  2.3007e-03, -2.0888e-02,  2.4093e-03,\n",
      "         -3.2044e-03, -7.3575e-03,  9.5152e-03, -1.6748e-03,  7.2065e-03,\n",
      "          1.7037e-02,  1.0452e-02,  7.4352e-03,  2.2163e-02,  1.9295e-02,\n",
      "         -1.2135e-02,  1.3746e-02, -1.3003e-02,  1.4587e-03,  4.9055e-03,\n",
      "         -5.7549e-03, -9.4925e-03, -1.6784e-03, -1.6008e-03, -1.5527e-02,\n",
      "          9.0800e-03, -8.7414e-03, -4.8387e-03, -9.0491e-03,  1.0220e-02,\n",
      "         -1.2188e-02,  7.5946e-03, -1.3787e-02, -1.2894e-03,  2.5219e-02,\n",
      "         -1.0817e-02, -1.5159e-02,  2.3529e-02,  1.1376e-02, -4.5696e-03,\n",
      "         -1.6466e-02, -4.4941e-03, -7.7152e-03, -2.1875e-03, -1.4356e-02,\n",
      "          1.5359e-02, -1.3266e-02, -3.2256e-03,  1.7762e-02,  1.1617e-02,\n",
      "          3.7324e-03,  1.5674e-02,  9.7905e-03,  5.7910e-03, -7.1106e-03,\n",
      "         -5.9174e-03,  9.1791e-03,  6.2795e-03,  1.7117e-02, -6.4551e-03,\n",
      "          7.7022e-03, -1.1523e-02,  1.0747e-02,  9.1227e-03,  1.2313e-02,\n",
      "         -3.9598e-03, -5.4621e-03,  1.1944e-02, -3.5634e-03,  1.6433e-02,\n",
      "          1.4393e-02, -1.1625e-02, -3.1748e-03, -1.0255e-02, -6.8869e-03,\n",
      "          3.6182e-03, -1.5650e-02, -5.0792e-03, -1.1191e-02, -9.3998e-03,\n",
      "          1.0038e-02, -7.4525e-03, -2.6175e-03,  5.0217e-03, -1.0086e-02,\n",
      "         -1.3342e-02,  4.4634e-03, -5.0743e-03,  2.1609e-03, -1.0295e-02,\n",
      "         -1.1415e-02,  1.0882e-02,  4.3512e-03,  9.0425e-03, -9.0482e-03,\n",
      "         -6.8264e-03,  8.9588e-03,  1.8513e-02, -6.3140e-03, -1.1486e-02,\n",
      "         -7.8118e-03, -1.1886e-02,  3.3706e-03, -1.8236e-02,  1.8800e-03,\n",
      "         -1.1083e-02,  4.3634e-03, -1.1180e-02,  8.5022e-03, -9.6649e-03,\n",
      "         -1.0518e-02,  6.1861e-03,  2.3091e-03,  7.5139e-03, -1.2550e-02,\n",
      "         -1.7089e-02,  5.6128e-03,  3.1741e-03,  2.8226e-03,  1.5734e-02,\n",
      "          8.5961e-03, -7.6124e-03, -1.3236e-02, -1.7295e-02,  4.5336e-03,\n",
      "          1.7060e-02, -7.6494e-03,  1.3459e-02,  5.6665e-03, -1.3979e-02,\n",
      "         -1.7348e-02,  9.0951e-03, -2.5121e-03,  4.7554e-03,  1.5570e-02,\n",
      "         -1.7425e-03, -1.7550e-02,  7.7451e-03,  5.2177e-03,  1.9412e-02,\n",
      "          4.1954e-03, -8.2054e-03, -1.4215e-02, -9.0899e-03, -1.0978e-02,\n",
      "          1.8184e-03, -1.6888e-02,  1.0371e-03, -7.3978e-03,  5.7541e-04,\n",
      "         -2.9960e-03,  5.9168e-03,  8.2374e-03,  1.8352e-03, -7.8242e-03,\n",
      "         -8.9464e-03, -9.1641e-03,  5.4974e-03, -4.8693e-03,  1.9484e-02,\n",
      "         -7.4906e-03, -2.4900e-03, -5.3348e-03, -1.6976e-02,  7.1450e-03,\n",
      "          2.1043e-02,  1.0730e-03, -7.0784e-03,  3.6952e-03, -7.6610e-03,\n",
      "          9.5771e-03,  1.1587e-02,  1.7892e-02, -5.7347e-03, -1.5505e-02,\n",
      "         -2.3748e-02, -1.3202e-02,  9.1273e-03,  1.8310e-03,  4.9272e-03,\n",
      "         -1.2978e-02,  1.3802e-04, -1.6976e-02, -1.4280e-02, -3.0135e-03,\n",
      "          1.9929e-03,  1.9286e-02, -1.4505e-03, -7.0917e-03,  1.5145e-02,\n",
      "          5.5993e-03,  1.1450e-02, -3.6159e-03,  2.5925e-03,  1.2592e-02,\n",
      "         -1.7634e-02,  2.7277e-03,  1.5536e-03, -5.6438e-03,  1.6642e-02,\n",
      "          9.9381e-03,  1.1209e-02, -2.4683e-03, -8.4246e-03, -1.0627e-02,\n",
      "          2.2541e-02,  5.1030e-04, -1.0072e-02,  7.1503e-03, -4.6256e-03,\n",
      "          1.3325e-03,  1.5887e-02,  1.4163e-02, -2.8938e-03,  3.1585e-02,\n",
      "          4.3590e-03,  8.0098e-03, -4.5871e-03, -9.5558e-03, -1.7668e-02,\n",
      "         -8.6115e-03,  4.9782e-04,  3.0808e-03, -6.9828e-04,  1.4381e-02,\n",
      "          8.7331e-03,  1.5734e-02,  3.6517e-04, -1.1926e-03, -7.8500e-04,\n",
      "          1.1281e-02,  6.0093e-03,  6.8326e-03, -2.3269e-02, -4.8826e-03,\n",
      "         -1.3733e-02, -1.2931e-02, -2.2745e-02,  6.7512e-03, -1.8391e-03,\n",
      "         -6.1539e-03,  4.5423e-03,  1.6716e-02,  1.5959e-02, -3.2976e-03,\n",
      "         -1.0210e-02,  7.3632e-03,  1.8586e-03, -1.2617e-02,  2.4152e-03,\n",
      "          1.9458e-02, -1.8791e-02,  4.9839e-04,  7.8257e-03, -4.2729e-03,\n",
      "          6.2440e-03, -1.0414e-02, -6.4607e-03,  8.5440e-03,  9.3160e-03,\n",
      "          7.7058e-03,  5.8042e-03,  1.0185e-02,  1.4513e-02,  4.7198e-03,\n",
      "          5.5479e-04, -1.3581e-02, -2.2431e-02,  7.8282e-03, -3.5034e-03,\n",
      "         -2.9883e-03, -1.4114e-03,  9.6914e-05,  3.0160e-03,  1.3357e-02,\n",
      "         -4.6007e-03, -9.1360e-03,  1.2010e-02,  9.8761e-04,  9.6552e-03,\n",
      "         -1.9262e-02,  9.7084e-04, -1.3619e-02,  7.7846e-04,  1.5258e-02,\n",
      "         -9.1247e-03, -1.0790e-02, -2.3397e-03, -1.3918e-04,  7.5730e-03,\n",
      "          1.2544e-02, -1.5804e-03, -9.0353e-03,  5.8011e-03, -1.5361e-02,\n",
      "          5.4379e-04, -9.1945e-03, -6.6997e-03, -6.1435e-03,  9.0363e-03,\n",
      "          3.1307e-03,  8.3057e-03,  1.7048e-02, -1.8782e-02,  1.0685e-02,\n",
      "          1.1500e-02, -2.7936e-03,  6.1201e-03,  6.5184e-03,  7.5206e-03,\n",
      "         -4.5594e-03, -2.3279e-03, -3.6425e-03, -4.6075e-03,  1.3513e-03,\n",
      "          1.9265e-03, -3.2730e-03,  8.5735e-03,  1.4598e-02,  1.3752e-03,\n",
      "         -5.1359e-03,  2.4117e-03, -5.2818e-03,  1.4449e-02, -1.0927e-02,\n",
      "         -1.4235e-02,  1.4800e-03, -4.0868e-03,  6.0638e-03, -1.8043e-02,\n",
      "         -1.0894e-02,  3.4386e-03,  3.9459e-04, -2.9107e-03, -1.3472e-02,\n",
      "          1.3127e-02, -1.1870e-02,  9.5579e-03, -2.0518e-03,  4.0302e-03,\n",
      "         -1.2800e-02, -7.1097e-03, -1.9759e-03, -1.1504e-02,  3.7011e-03,\n",
      "          5.3977e-03, -9.3513e-03,  1.1359e-02,  7.8198e-03,  1.5539e-03,\n",
      "         -2.7921e-03,  4.8897e-03,  1.2355e-02, -1.2415e-02,  1.6966e-02,\n",
      "          1.2387e-03, -1.5270e-02,  9.3423e-03,  3.8032e-03,  3.2036e-03,\n",
      "         -2.3425e-03,  1.9567e-02, -8.8082e-03,  1.1250e-02,  1.1615e-02,\n",
      "          2.2863e-03,  9.3507e-03, -4.0066e-03,  9.4113e-03, -1.3231e-02,\n",
      "         -1.8371e-02, -1.4427e-03,  1.0210e-02, -6.7741e-03, -1.2020e-02,\n",
      "         -8.0456e-03, -4.9045e-03,  1.7275e-02,  2.2390e-03, -2.8285e-03,\n",
      "         -6.8012e-03, -2.3072e-03,  1.5892e-03,  6.1473e-03, -7.9236e-03,\n",
      "          2.2408e-03, -1.0288e-02, -1.4925e-02,  1.2850e-03,  4.8179e-03,\n",
      "          1.1205e-02,  3.5565e-03,  2.1430e-02, -8.7399e-03,  3.2496e-03,\n",
      "         -2.7134e-03,  1.7746e-02, -8.9636e-03,  1.3782e-02, -1.7318e-02,\n",
      "         -9.0413e-03,  1.5423e-02,  4.6388e-03, -4.9356e-03, -1.1526e-02,\n",
      "         -1.1901e-02,  2.2548e-02,  1.6249e-02, -1.1636e-02,  1.8485e-02,\n",
      "         -1.9417e-02,  9.6300e-03, -6.4372e-03,  7.9139e-03,  9.7005e-03,\n",
      "          2.5786e-03,  4.0919e-04,  2.7124e-04,  7.2371e-03,  1.5473e-04,\n",
      "          6.8718e-03,  1.6798e-02, -1.8107e-02, -1.2706e-02,  3.9233e-03,\n",
      "         -5.2628e-03,  1.8039e-02, -1.0704e-03,  5.0777e-03, -1.3978e-02,\n",
      "          7.3029e-03, -1.7475e-04,  2.0974e-03,  2.0192e-02,  5.3310e-03,\n",
      "          6.1057e-03,  6.5263e-03,  2.3289e-02, -4.5812e-03,  6.3536e-03,\n",
      "         -1.6086e-03, -9.2271e-04, -8.8025e-03,  5.8929e-03,  7.2151e-03,\n",
      "         -2.3342e-03, -1.4658e-02,  6.6846e-03,  1.1927e-02, -1.9332e-02,\n",
      "          9.6338e-04, -7.2766e-04,  1.1547e-02, -4.8710e-03,  1.4169e-02,\n",
      "          1.7184e-02, -8.3782e-03,  7.2984e-03, -2.2110e-03, -2.2668e-02,\n",
      "          6.8875e-03, -1.2524e-02, -1.4020e-02, -3.1576e-04,  1.7419e-02,\n",
      "         -1.1729e-02,  8.1182e-03,  1.5623e-03,  3.5766e-03, -1.0528e-03,\n",
      "          1.3234e-02, -7.0176e-03, -2.1962e-03,  8.1893e-03,  8.9498e-03,\n",
      "         -1.2636e-02, -1.4223e-02, -4.1717e-03,  2.5082e-02,  1.5753e-02,\n",
      "          3.8848e-03,  2.0449e-02, -1.2272e-02, -1.0613e-02, -1.2653e-03,\n",
      "         -6.1139e-03, -5.2453e-03,  1.0615e-02, -1.2068e-02,  7.8758e-04,\n",
      "         -1.0091e-02, -6.9149e-03, -9.2436e-03,  1.2078e-02, -8.8986e-04,\n",
      "          6.4394e-04,  1.1975e-02,  3.5348e-03,  1.0307e-02,  5.2610e-03,\n",
      "          4.3711e-05,  2.6961e-02,  1.4306e-02,  1.0082e-02,  7.0936e-03,\n",
      "         -7.2990e-03,  1.4940e-02,  2.0716e-03,  1.2535e-02,  9.3960e-03,\n",
      "         -1.5054e-02, -2.7439e-03,  1.3186e-03,  1.4085e-02,  1.5495e-02,\n",
      "          8.6440e-03, -1.1157e-02, -4.7603e-03, -9.0450e-03, -1.2364e-02,\n",
      "          3.0843e-03,  5.3273e-03, -2.0349e-02, -9.9669e-03, -2.2600e-03,\n",
      "          8.9575e-03, -1.7258e-02, -1.1189e-02,  2.8377e-03,  5.0155e-03,\n",
      "         -7.3278e-03, -1.2012e-02,  7.7196e-03, -1.4677e-02,  5.5809e-03]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 3, 244, 244)\n",
    "out = vgg(input)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
