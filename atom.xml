<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>高深远的博客</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://gsy00517.github.io/"/>
  <updated>2019-11-02T07:02:02.173Z</updated>
  <id>https://gsy00517.github.io/</id>
  
  <author>
    <name>高深远</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>kaggle笔记：手写数字识别——使用KNN和CNN尝试MNIST数据集</title>
    <link href="https://gsy00517.github.io/kaggle20191102112435/"/>
    <id>https://gsy00517.github.io/kaggle20191102112435/</id>
    <published>2019-11-02T03:24:35.000Z</published>
    <updated>2019-11-02T07:02:02.173Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>kaggle是一个著名的数据科学竞赛平台，暑假里我也抽空自己独立完成了三四个getting started级别的比赛。对于MNIST数据集，想必入门计算机是觉的人应该也不会陌生。kaggle上getting started的第一个比赛就是Digit Recognizer：Learn computer vision fundamentals with the famous MNIST data。当时作为入门小白的我，使用了入门级的方法KNN完成了我的第一次机器学习（自认为KNN是最最基础的算法，对它的介绍可见我的另一篇博文<a href="https://gsy00517.github.io/machine-learning20191101192042/" target="_blank">machine-learning笔记：机器学习的几个常见算法及其优缺点</a>，真的非常简单，但也极其笨拙）。而最近我又使用CNN再一次尝试了这个数据集，踩了不少坑，因此想把两次经历统统记录在这，可能会有一些不足之处，留作以后整理优化。</p><p>本文参考自：<a href="https://blog.csdn.net/gybinlero/article/details/79294649" target="_blank" rel="noopener">https://blog.csdn.net/gybinlero/article/details/79294649</a><br><a href="https://blog.csdn.net/qq_43497702/article/details/95005248" target="_blank" rel="noopener">https://blog.csdn.net/qq_43497702/article/details/95005248</a><br><a href="https://blog.csdn.net/a19990412/article/details/90349429" target="_blank" rel="noopener">https://blog.csdn.net/a19990412/article/details/90349429</a></p><hr><h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><p>首先导入必要的包，这里基本用不到太多：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure><p></p><p>导入训练数据：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">trainSet = []</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'train.csv'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> trainFile:</span><br><span class="line">    lines=csv.reader(trainFile)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">        trainSet.append(line)</span><br><span class="line">    trainSet.remove(trainSet[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">trainSet = np.array(trainSet)</span><br><span class="line">rawTrainLabel = trainSet[:, <span class="number">0</span>] <span class="comment">#分割出训练集标签</span></span><br><span class="line">rawTrainData = trainSet[:, <span class="number">1</span>:] <span class="comment">#分割出训练集数据</span></span><br></pre></td></tr></table></figure><p></p><p>我当时用了一种比较笨拙的办法转换数据类型：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">rawTrainData = np.mat(rawTrainData) <span class="comment">#转化成矩阵，或许不需要</span></span><br><span class="line">m, n = np.shape(rawTrainData)</span><br><span class="line">trainData = np.zeros((m, n)) <span class="comment">#创建初值为0的ndarray</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        trainData[i, j] = int(rawTrainData[i, j]) <span class="comment">#转化并赋值</span></span><br><span class="line"></span><br><span class="line">rawTrainLabel = np.mat(rawTrainLabel) <span class="comment">#或许不需要</span></span><br><span class="line">m, n = np.shape(rawTrainLabel)</span><br><span class="line">trainLabel = np.zeros((m, n))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        trainLabel[i, j] = int(rawTrainLabel[i, j])</span><br></pre></td></tr></table></figure><p></p><p>这里我们可以查看以下数据的维度，确保没有出错。<br><img src="/kaggle20191102112435/查看维度.png" title="查看维度"><br>为了方便起见，我们把所有pixel不为0的点都设置为1。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">m, n = np.shape(trainData)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> trainData[i, j] != <span class="number">0</span>:</span><br><span class="line">            trainData[i, j] = <span class="number">1</span></span><br></pre></td></tr></table></figure><p></p><p>仿照训练集的步骤，导入测试集并做相同处理：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">testSet = []</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'test.csv'</span>,<span class="string">'r'</span>) <span class="keyword">as</span> testFile:</span><br><span class="line">    lines=csv.reader(testFile)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> lines:</span><br><span class="line">        testSet.append(line)</span><br><span class="line">    testSet.remove(testSet[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">testSet = np.array(testSet)</span><br><span class="line">rawTestData = testSet</span><br><span class="line"></span><br><span class="line">rawTestData = np.mat(rawTestData)</span><br><span class="line">m, n = np.shape(rawTestData)</span><br><span class="line">testData = np.zeros((m, n))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        testData[i, j] = int(rawTestData[i, j])</span><br><span class="line"></span><br><span class="line">m, n = np.shape(testData)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> testData[i, j] != <span class="number">0</span>:</span><br><span class="line">            testData[i, j] = <span class="number">1</span></span><br></pre></td></tr></table></figure><p></p><p>同样的，可使用<code>testData.shape</code>查看测试集的维度，保证它是28000*784，由此可知操作无误。<br>接下来，我们定义KNN的分类函数。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify</span><span class="params">(inX, dataSet, labels, k)</span>:</span></span><br><span class="line">    inX = np.mat(inX)</span><br><span class="line">    dataSet = np.mat(dataSet)</span><br><span class="line">    labels = np.mat(labels)</span><br><span class="line">    dataSetSize = dataSet.shape[<span class="number">0</span>]</span><br><span class="line">    diffMat = np.tile(inX, (dataSetSize, <span class="number">1</span>)) - dataSet     </span><br><span class="line">    sqDiffMat = np.array(diffMat) ** <span class="number">2</span></span><br><span class="line">    sqDistances = sqDiffMat.sum(axis = <span class="number">1</span>)       </span><br><span class="line">    distances = sqDistances ** <span class="number">0.5</span></span><br><span class="line">    sortedDistIndicies = distances.argsort()</span><br><span class="line">    classCount=&#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        voteIlabel = labels[<span class="number">0</span>, sortedDistIndicies[i]]</span><br><span class="line">        classCount[voteIlabel] = classCount.get(voteIlabel, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line">    sortedClassCount = sorted(classCount.iteritems(), key = operator.itemgetter(<span class="number">1</span>), reverse = <span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p></p><p>为了更好地分类，这里我们需要选择合适的k值，我选取了4000个样本作为验证机进行尝试，找到误差最小的k值并作为最终的k值输入。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">trainingTestSize = <span class="number">4000</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#分割出验证集</span></span><br><span class="line">m, n = np.shape(trainLabel)</span><br><span class="line">trainingTrainLabel = np.zeros((m, n - trainingTestSize))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n - trainingTestSize):</span><br><span class="line">        trainingTrainLabel[i, j] = trainLabel[i, j]</span><br><span class="line">        </span><br><span class="line">trainingTestLabel = np.zeros((m, trainingTestSize))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(trainingTestSize):</span><br><span class="line">        trainingTestLabel[i, j] = trainLabel[i, n - trainingTestSize + j]</span><br><span class="line">        </span><br><span class="line">m, n = np.shape(trainData)</span><br><span class="line">trainingTrainData = np.zeros((m - trainingTestSize, n))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m - trainingTestSize):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        trainingTrainData[i, j] = trainData[i, j]</span><br><span class="line">        </span><br><span class="line">trainingTestData = np.zeros((trainingTestSize, n))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(trainingTestSize):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(n):</span><br><span class="line">        trainingTestData[i, j] = trainData[m - trainingTestSize + i, j]</span><br><span class="line"></span><br><span class="line"><span class="comment">#使k值为3到9依次尝试</span></span><br><span class="line">training = []</span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">3</span>, <span class="number">10</span>):</span><br><span class="line">    error = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> range(trainingTestSize):</span><br><span class="line">        answer = (classify(trainingTestData[y], trainingTrainData, trainingTrainLabel, x))</span><br><span class="line">        <span class="keyword">print</span> <span class="string">'the classifier came back with: %d, %.2f%% has done, the k now is %d'</span> % (answer, (y + (x - <span class="number">3</span>) * trainingTestSize) / float(trainingTestSize * <span class="number">7</span>) * <span class="number">100</span>, x) <span class="comment">#方便知道进度</span></span><br><span class="line">        <span class="keyword">if</span> answer != trainingTestLabel[<span class="number">0</span>, y]:</span><br><span class="line">            error += <span class="number">1</span></span><br><span class="line">    training.append(error)</span><br></pre></td></tr></table></figure><p></p><p>这个过程比较长，结果会得到training的结果是[156, 173, 159, 164, 152, 155, 156]。<br>可以使用<code>plt.plot(training)</code>更直观地查看误差，呈现如下：<br><img src="/kaggle20191102112435/各k值的误差.png" title="各k值的误差"></p><blockquote><p>注意：这里的下标应该加上3才是对应的k值。</p></blockquote><p>可以看图手动选择k值，但由于事先无法把握训练结束的时间，可以编写函数自动选择并使程序继续进行。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">theK = <span class="number">3</span></span><br><span class="line">hasError = training[<span class="number">0</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">7</span>):</span><br><span class="line">    <span class="keyword">if</span> training[i] &lt; hasError:</span><br><span class="line">        theK = i + <span class="number">3</span></span><br><span class="line">        hasError = training[i]</span><br></pre></td></tr></table></figure><p></p><p>在确定k值后，接下来就是代入测试集进行结果的计算了。由于KNN算法相对而言比较低级，因此就别指望效率了，跑CPU的话整个过程大概需要半天左右。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">m, n = np.shape(testData)</span><br><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(m):</span><br><span class="line">    answer = (classify(testData[i], trainData, trainLabel, theK))</span><br><span class="line">    result.append(answer)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'the classifier came back with: %d, %.2f%% has done'</span> % (answer, i / float(m) * <span class="number">100</span>)</span><br></pre></td></tr></table></figure><p></p><p>最后，定义一个保存结果的函数，然后<code>saveResult(result)</code>之后，再对csv文件进行处理（后文会提到），然后就可以submit了。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveResult</span><span class="params">(result)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'result.csv'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> myFile:      </span><br><span class="line">        myWriter = csv.writer(myFile)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">            tmp = []</span><br><span class="line">            tmp.append(i)</span><br><span class="line">            myWriter.writerow(tmp)</span><br></pre></td></tr></table></figure><p></p><p>最终此方法在kaggle上获得的score为0.96314，准确率还是挺高的，主要是因为问题相对简单，放到leaderboard上，这结果的排名就要到两千左右了。</p><hr><h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1><p>在学习了卷积神经网络和pytorch框架之后，我决定使用CNN对这个比赛再进行一次尝试。<br>首先还是导入相关的包。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.cm <span class="keyword">as</span> cm</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch.utils.data <span class="keyword">as</span> Data</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> csv</span><br></pre></td></tr></table></figure><p></p><p>导入训练数据，可以使用<code>train.head()</code>查看导入的结果，便于后续的处理。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train = pd.read_csv(<span class="string">"train.csv"</span>)</span><br></pre></td></tr></table></figure><p></p><p>对数据进行处理，由于要使用的是CNN，我们必须要把数据整理成能输入的形式，即从数组变成高维张量。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">train_labels = torch.from_numpy(np.array(train.label[:]))</span><br><span class="line"></span><br><span class="line">image_size = train.iloc[:, <span class="number">1</span>:].shape[<span class="number">1</span>]</span><br><span class="line">image_width = image_height = np.ceil(np.sqrt(image_size)).astype(np.uint8)</span><br><span class="line">train_data = torch.FloatTensor(np.array(train.iloc[:, <span class="number">1</span>:]).reshape((<span class="number">-1</span>, <span class="number">1</span>, image_width, image_height))) / <span class="number">255</span> <span class="comment">#灰度压缩，进行归一化</span></span><br></pre></td></tr></table></figure><p></p><blockquote><p>注：reshape中的-1表示自适应，这样我们能让我们更好的变化数据的形式。</p></blockquote><p>我们可以使用matplotlib查看数据处理的结果。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(train_data[<span class="number">1</span>].numpy().squeeze(), cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'%i'</span> % train_labels[<span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p></p><p>可以看到如下图片。<br><img src="/kaggle20191102112435/处理结果.png" title="处理结果"></p><blockquote><p>注：可以用squeeze()函数来降维，例如：从<code>[[1]]</code>—&gt;<code>[1]</code>。<br>与之相反的是便是unsqueeze(dim = 1)，该函数可以从<code>[1]</code>—&gt;<code>[[1]]</code>。</p></blockquote><p>以同样的方式导入并处理测试集。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">test= pd.read_csv(<span class="string">"test.csv"</span>)</span><br><span class="line">test_data = torch.FloatTensor(np.array(test).reshape((<span class="number">-1</span>, <span class="number">1</span>, image_width, image_height))) / <span class="number">255</span></span><br></pre></td></tr></table></figure><p></p><p>接下来我们定义几个超参数，这里将要使用的是小批梯度下降的优化算法，因此定义如下：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#超参数</span></span><br><span class="line">EPOCH = <span class="number">1</span> <span class="comment">#整个数据集循环训练的轮数</span></span><br><span class="line">BATCH_SIZE = <span class="number">10</span> <span class="comment">#每批的样本个数</span></span><br><span class="line">LR = <span class="number">0.01</span> <span class="comment">#学习率</span></span><br></pre></td></tr></table></figure><p></p><p>定义好超参数之后，我们使用Data对数据进行最后的处理。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">trainData = Data.TensorDataset(train_data, train_labels) <span class="comment">#用后会变成元组类型</span></span><br><span class="line"></span><br><span class="line">train_loader = Data.DataLoader(</span><br><span class="line">    dataset = trainData,</span><br><span class="line">    batch_size = BATCH_SIZE,</span><br><span class="line">    shuffle = <span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p></p><p>上面的Data.TensorDataset可以把数据进行打包，以方便我们更好的使用；而Data.DataLoade可以将我们的数据打乱并且分批。要注意的是，这里不要对测试集进行操作，否则最终输出的结果就难以再与原来的顺序匹配了。<br>接下来，我们定义卷积神经网络。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#build CNN</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(CNN, self).__init__()</span><br><span class="line">        <span class="comment">#一个卷积层</span></span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d( <span class="comment">#输入(1, 28, 28)</span></span><br><span class="line">                in_channels = <span class="number">1</span>,      <span class="comment">#1个通道</span></span><br><span class="line">                out_channels = <span class="number">16</span>,    <span class="comment">#输出层数</span></span><br><span class="line">                kernel_size = <span class="number">5</span>,      <span class="comment">#过滤器的大小</span></span><br><span class="line">                stride = <span class="number">1</span>,           <span class="comment">#步长</span></span><br><span class="line">                padding = <span class="number">2</span>           <span class="comment">#填白</span></span><br><span class="line">            ), <span class="comment">#输出(16, 28, 28)</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size = <span class="number">2</span>), <span class="comment">#输出(16, 14, 14)</span></span><br><span class="line">        )</span><br><span class="line">        self.conv2 = nn.Sequential( <span class="comment">#输入(16, 14, 14)</span></span><br><span class="line">            nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>), <span class="comment">#这里用了两个过滤器，将16层变成了32层</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size = <span class="number">2</span>) <span class="comment">#输出(32, 7, 7)</span></span><br><span class="line">        )</span><br><span class="line">        self.out = nn.Linear(<span class="number">32</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">10</span>) <span class="comment">#全连接层，将三维的数据展为2维的数据并输出</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        output = F.softmax(self.out(x))</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">optimzer = torch.optim.Adam(cnn.parameters(), lr = LR) <span class="comment"># define optimezer</span></span><br><span class="line">loss_func = nn.CrossEntropyLoss()   <span class="comment"># loss function使用交叉嫡误差</span></span><br><span class="line"></span><br><span class="line">cnn = CNN()</span><br><span class="line">print(cnn)  <span class="comment"># 查看net architecture</span></span><br></pre></td></tr></table></figure><p></p><p>完成以上的操作之后，就可以开始训练了，整个训练时间在CPU上只需要几分钟，这比KNN算法要优越许多。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(EPOCH):</span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> enumerate(train_loader):</span><br><span class="line">        b_x = Variable(x)</span><br><span class="line">        b_y = Variable(y)</span><br><span class="line">        output = cnn(b_x)</span><br><span class="line">        loss = loss_func(output, b_y) <span class="comment">#cross entropy loss</span></span><br><span class="line">        <span class="comment">#update W</span></span><br><span class="line">        optimzer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimzer.step()</span><br><span class="line">        print(<span class="string">'epoch%d'</span> % (epoch + <span class="number">1</span>),<span class="string">" "</span>,<span class="string">'batch%d'</span> % step)</span><br><span class="line">    print(<span class="string">'train is over'</span>)</span><br></pre></td></tr></table></figure><p></p><p>代入测试集求解：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">output = cnn(test_data[:])</span><br><span class="line"><span class="comment">#print(output)</span></span><br><span class="line"></span><br><span class="line">result = torch.max(output, <span class="number">1</span>)[<span class="number">1</span>].squeeze()</span><br><span class="line"><span class="comment">#print(result)</span></span><br></pre></td></tr></table></figure><p></p><p>仿照KNN中的结果转存函数，定义saveResult函数。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">saveResult</span><span class="params">(result)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'result.csv'</span>, <span class="string">'w'</span>) <span class="keyword">as</span> myFile:      </span><br><span class="line">        myWriter = csv.writer(myFile)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> result:</span><br><span class="line">            tmp = []</span><br><span class="line">            tmp.append(i)</span><br><span class="line">            myWriter.writerow(tmp)</span><br></pre></td></tr></table></figure><p></p><p>最后使用<code>saveResult(result.numpy())</code>把结果存入csv文件。</p><hr><h1 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h1><p>然而，若使用上述的CNN，得出的结果在leaderboard上会达到两千三百多名，这已经进入所有参赛者的倒数两百名之内了。为什么这个CNN的表现甚至不如我前面的KNN算法呢？我觉得主要有下面三个原因。</p><ol><li><p>首先，由于CNN的参数较多，仅经过1轮epoch应该是不足够把所有参数训练到最优或者接近最优的位置的。个人认为，靠前的数据在参数相对远离最优值时参与训练而在之后不起作用，很有可能导致最后顾此失彼，因此有必要增加epoch使之前的数据多次参与参数的校正。同时，也要增大batch size使每次优化参数使用的样本更多，从而在测试集上表现更好。训练结束后，我发现我的C盘会被占用几个G，不知道是不是出错了，也有可能是参数占用的空间，必须停止kernel才能得到释放（我关闭了VScode后刷新，空间就回来了）。关于内存，这里似乎存在着一个问题，我将在后文阐述。</p><blockquote><p>注：由于VScode前段时间也开始支持ipynb，喜欢高端暗黑科技风又懒得自己修改jupyter notebook的小伙伴可以试一试。</p></blockquote></li><li><p>学习率过大。尽管我这里的学习率设置为0.01，但对于最后的收敛来说或许还是偏大，这就导致了最后会在最优解附近来回抖动而难以接近的问题。关于这个问题，可以到<a href="https://gsy00517.github.io/deep-learning20191001151454/" target="_blank">deep-learning笔记：学习率衰减与批归一化</a>中看看我较为详细的分析与解决方法。</p></li><li>由于训练时间和epoch轮数相对较小，我推测模型可能会存在过拟合的问题。尤其是最后的全连接层，它的结构很容易造成过拟合。关于这个问题，也可以到<a href="https://gsy00517.github.io/machine-learning20191001104538/" target="_blank">machine-learning笔记：过拟合与欠拟合</a>和<a href="https://gsy00517.github.io/machine-learning20190915150339/" target="_blank">machine-learning笔记：机器学习中正则化的理解</a>中看看我较为详细的分析与解决方法。<br>针对上述原因，我对我的CNN模型做了如下调整：</li><li><p>首先，增加训练量，调整超参数如下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#超参数</span></span><br><span class="line">EOPCH = <span class="number">3</span></span><br><span class="line">BATCH_SIZE = <span class="number">50</span></span><br><span class="line">LR = <span class="number">1e-4</span></span><br></pre></td></tr></table></figure></li><li><p>引入dropout随机失活，加强全连接层的鲁棒性，修改网络结构如下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#build CNN</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CNN</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(CNN, self).__init__()</span><br><span class="line">        <span class="comment">#一个卷积层</span></span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d( <span class="comment">#输入(1, 28, 28)</span></span><br><span class="line">                in_channels = <span class="number">1</span>,      <span class="comment">#1个通道</span></span><br><span class="line">                out_channels = <span class="number">16</span>,    <span class="comment">#输出层数</span></span><br><span class="line">                kernel_size = <span class="number">5</span>,      <span class="comment">#过滤器的大小</span></span><br><span class="line">                stride = <span class="number">1</span>,           <span class="comment">#步长</span></span><br><span class="line">                padding = <span class="number">2</span>           <span class="comment">#填白</span></span><br><span class="line">            ), <span class="comment">#输出(16, 28, 28)</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size = <span class="number">2</span>), <span class="comment">#输出(16, 14, 14)</span></span><br><span class="line">        )</span><br><span class="line">        self.conv2 = nn.Sequential( <span class="comment">#输入(16, 14, 14)</span></span><br><span class="line">            nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">2</span>), <span class="comment">#这里用了两个过滤器，将16层变成了32层</span></span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size = <span class="number">2</span>) <span class="comment">#输出(32, 7, 7)</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.dropout = nn.Dropout(p = <span class="number">0.5</span>) <span class="comment">#每次减少50%神经元之间的连接</span></span><br><span class="line"></span><br><span class="line">        self.fc = nn.Linear(<span class="number">32</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">1024</span>)</span><br><span class="line">        self.out = nn.Linear(<span class="number">1024</span>, <span class="number">10</span>) <span class="comment">#全连接层，将三维的数据展为2维的数据并输出</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        output = F.softmax(self.out(x))</span><br><span class="line">        <span class="keyword">return</span> output</span><br></pre></td></tr></table></figure></li></ol><p>本想直接使用torch.nn.functional中的dropout函数轻松实现随机失活正则化，但在网上看到这个函数好像有点坑，因此就不以身试坑了，还是在网络初始化中先定义dropout。<br>经过上面的改进后，我再次训练网络并提交结果，在kaggle上的评分提高至0.97328，大约处在1600名左右，可以继续调整超参数（可以分割验证集寻找）和加深网络结构以取得更高的分数，但我的目的已经达到了。与之前的KNN相比，无论从时间效率还是准确率，CNN都有很大的进步，这也体现了深度学习相对于一些经典机器学习算法的优势。</p><hr><h1 id="出现的问题"><a href="#出现的问题" class="headerlink" title="出现的问题"></a>出现的问题</h1><p>由于这个最后的网络是我重复构建之后完成的，因此下列部分问题可能不存在于我上面的代码中，但我还是想汇总在这，以防之后继续踩相同的坑。</p><ol><li><h2 id="报错element-0-of-tensors-does-not-require-grad-and-does-not-have-a-grad-fn"><a href="#报错element-0-of-tensors-does-not-require-grad-and-does-not-have-a-grad-fn" class="headerlink" title="报错element 0 of tensors does not require grad and does not have a grad_fn"></a>报错element 0 of tensors does not require grad and does not have a grad_fn</h2>pytorch具有自动求导机制，这就省去了我们编写反向传播的代码。每个Variable变量都有两个标志：requires_grad和volatile。出现上述问题的原因是requires_grad = False，修改或者增加（因为默认是false）成True即可。</li><li><h2 id="RuntimeError-Dimension-out-of-range-expected-to-be-in-range-of-1-0-but-got-1"><a href="#RuntimeError-Dimension-out-of-range-expected-to-be-in-range-of-1-0-but-got-1" class="headerlink" title="RuntimeError: Dimension out of range (expected to be in range of [-1, 0], but got 1)"></a>RuntimeError: Dimension out of range (expected to be in range of [-1, 0], but got 1)</h2>这个好像是我在计算交叉熵时遇到的，原因是因为torch的交叉熵的输入第一个位置的输入应该是在每个label下的概率，而不是对应的label，详细分析与举例可参考文首给出的第三个链接。</li><li><h2 id="AttributeError-‘tuple’-object-has-no-attribute-‘numpy’"><a href="#AttributeError-‘tuple’-object-has-no-attribute-‘numpy’" class="headerlink" title="AttributeError: ‘tuple’ object has no attribute ‘numpy’"></a>AttributeError: ‘tuple’ object has no attribute ‘numpy’</h2>为了查看数据处理效果，我在数据预处理过程中使用matplotlib绘制出处理后的图像，但是却出现了如上报错，当时的代码如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(trainData[<span class="number">1</span>].numpy().squeeze(), cmap = <span class="string">'gray'</span>)</span><br><span class="line">plt.title(<span class="string">'%i'</span> % train_labels[<span class="number">1</span>])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure></li></ol><p>查找相关资料之后，我才知道torch.utils.data会把打包的数据变成元组类型，因此我们绘图还是要使用原来train_data中的数据。</p><ol><li><h2 id="转存结果时提醒DefaultCPUAllocator-not-enough-memory"><a href="#转存结果时提醒DefaultCPUAllocator-not-enough-memory" class="headerlink" title="转存结果时提醒DefaultCPUAllocator: not enough memory"></a>转存结果时提醒DefaultCPUAllocator: not enough memory</h2>由于当初在实现KNN算法转存结果时使用的函数存入csv文件后还要对文件进行空值删除处理，比较麻烦（后文会写具体如何处理），因此我想借用文章顶部给出的第二个链接中提供的方法：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">out = pd.DataFrame(np.array(result), index = range(<span class="number">1</span>, <span class="number">1</span> + len(result)), columns = [<span class="string">'ImageId'</span>, <span class="string">'Label'</span>])</span><br><span class="line"><span class="comment">#torch和pandas的类型不能直接的转换，所以需要借助numpy中间的步骤，将torch的数据转给pandas</span></span><br><span class="line">out.to_csv(<span class="string">'result.csv'</span>, header = <span class="literal">None</span>)</span><br></pre></td></tr></table></figure></li></ol><p>结果出现如下错误：<br><img src="/kaggle20191102112435/内存不够？.png" title="内存不够？"><br>我好歹也是八千多买的DELL旗舰本，8G内存，它居然说我不够让我换块新的RAM？什么情况…<br>尝试许久，我怀疑是训练得到的参数占用了我的内存，那只好先把训练出的result保存下来，再导入到csv文件。<br>最后我还是选择自己手动处理csv文件中的空值，应该有其它的转存csv文件的方法或者上述问题的解决措施，留待以后实践过程中发现解决，也欢迎大家不吝赐教。</p><hr><h1 id="excel-csv快速删除空白行"><a href="#excel-csv快速删除空白行" class="headerlink" title="excel/csv快速删除空白行"></a>excel/csv快速删除空白行</h1><p>如果你使用的是我的saveResult函数或者类似，你就很有可能发现更新后的csv文件中数据之间双数行都是留空的，即一列数据之间都有空白行相隔，那么可以使用如下方法快速删除空白行。</p><ol><li>选中对应列或者区域。</li><li>在“开始”工具栏中找到“查找与选择”功能并点击。</li><li>在下拉菜单中，点击“定位条件”选项。</li><li>在打开的定位条件窗口中，选择“空值”并确定。</li><li>待电脑为你选中所有空值后，任意右键一个被选中的空白行，在弹出的菜单中点击“删除”。</li><li>如果数据量比较大，这时候会有一个处理时间可能会比较长的提醒弹出，确认即可。</li><li>等待处理完毕。</li></ol><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;kaggle是一个著名的数据科学竞赛平台，暑假里我也抽空自己独立完成了三四个getting started级别的比赛。对于MNIST数据集，想必
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://gsy00517.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="机器学习" scheme="https://gsy00517.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://gsy00517.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="代码实现" scheme="https://gsy00517.github.io/tags/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    
      <category term="pytorch" scheme="https://gsy00517.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>hexo笔记：SEO优化</title>
    <link href="https://gsy00517.github.io/hexo20191101212014/"/>
    <id>https://gsy00517.github.io/hexo20191101212014/</id>
    <published>2019-11-01T13:20:14.000Z</published>
    <updated>2019-11-02T03:17:51.904Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>在<a href="https://gsy00517.github.io/toefl20191019150438/" target="_blank">toefl笔记：首考考托福——记一次裸考经历</a>文章末尾我曾提到在被百度收录之后要好好做SEO，这段时间我也的确有所尝试与改进，因此在本文中将一些我认为比较有效的或者依旧存疑的SEO优化方法写下来，供日后参考深究。</p><p>本文参考自：<a href="https://blog.csdn.net/lzy98/article/details/81140704" target="_blank" rel="noopener">https://blog.csdn.net/lzy98/article/details/81140704</a><br><a href="https://www.jianshu.com/p/86557c34b671" target="_blank" rel="noopener">https://www.jianshu.com/p/86557c34b671</a><br><a href="https://baijiahao.baidu.com/s?id=1616368344109675728&amp;wfr=spider&amp;for=pc" target="_blank" rel="noopener">https://baijiahao.baidu.com/s?id=1616368344109675728&amp;wfr=spider&amp;for=pc</a><br><a href="https://www.jianshu.com/p/7e1166eb412a" target="_blank" rel="noopener">https://www.jianshu.com/p/7e1166eb412a</a></p><hr><h1 id="SEO"><a href="#SEO" class="headerlink" title="SEO"></a>SEO</h1><p>之前在知乎上碰巧看到一篇别人是如何推广自己的博客的文章，里面就提到了SEO这个概念。我当时也很好奇，百度之后才发现它完全不同于CEO、CTO等概念。SEO（Search Engine Optimization），汉译为搜索引擎优化。它是一种方式，即利用搜索引擎的规则提高网站在有关搜索引擎内的自然排名。通俗的讲就是post的内容更容易被搜索引擎搜索到或者收录，且在搜索结果列表中显示靠前。<br>看了一圈，SEO的办法真的是多种多样，下面我就简单记录一部分我试过的方法。</p><hr><h1 id="sitemap"><a href="#sitemap" class="headerlink" title="sitemap"></a>sitemap</h1><p>首先需要安装sitemap站点地图自动生成插件。<br>windows下打开git bash，输入安装命令：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-generator-sitemap --save</span><br><span class="line">npm install hexo-generator-baidu-sitemap --save</span><br></pre></td></tr></table></figure><p></p><p>然后在站点配置文件_config.yml中找到如下对应的位置（一般默认有，没有的话可以添加），修改如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 自动生成sitemap</span><br><span class="line">sitemap:</span><br><span class="line">  path: sitemap.xml</span><br><span class="line">baidusitemap:</span><br><span class="line">  path: baidusitemap.xml</span><br></pre></td></tr></table></figure><p></p><p>特别要注意的是，上面的path一定要缩进，否则在hexo generate时会无法编译导致报错。（似乎有一些版本的hexo不存在这样的问题，关于版本可以使用<code>hexo version</code>命令查看）<br>这样以后每次generate后都会在public目录下面生成sitemap.xml和baidusitemap.xml两个文件，即你的站点地图。也可以deploy后直接在域名后面加上这两个文件名查看你的站点地图。<br>在百度站长平台中，有sitemap提交的选项，由于我当初提交的网站协议前缀是http，因此xml文件所在的https前缀的链接不属于我提交的网站，而我的github page和coding page都设置了强制https访问。这个问题以后有机会再做解决，不存在这个问题的可以试试提交sitemap。</p><hr><h1 id="优化url"><a href="#优化url" class="headerlink" title="优化url"></a>优化url</h1><p>同样在站点配置文件下面，可以找到站点的url设置。<br>如果你尚未更改过，你会发现默认的url是<code>http://yoursite.com</code>，我在这里吃了不少亏，之前苹果上add to favorites、RSS订阅后点开的链接以及copyright的链接都会直接跳转到yoursite而非我的博文链接。<br>SEO搜索引擎优化认为，网站的最佳结构是用户从首页点击三次就可以到达任何一个页面，但是我们使用hexo编译的站点默认打开文章的url是：sitename/year/mounth/day/title四层的结构，这样的url结构很不利于SEO，爬虫就会经常爬不到我们的文章，于是，我们可以将url直接改成sitename/title的形式，并且title最好是用英文（中文的url会出现好多乱码，我这方面还有待改进）。<br>基于以上原因，我在根目录的站点配置文件下修改url设置如下（注释中是默认的）：<br><img src="/hexo20191101212014/优化url.png" title="优化url"><br>如此，再次添加RSS订阅，就可以跟yoursite这个鬼地方say goodbye啦。<br>对permalink的修改将会是你的站点的一次巨大的变动，会造成大量的死链。死链会造成搜索引擎对网站的评分降低并有可能会降权。我们可以直接百度搜索“site：url”（url即你的站点网址）查看已经被搜索引擎收录的网址。如下图所示，目前我已被收录了四个，其中前两个经此番调整已成为死链。<br><img src="/hexo20191101212014/查看被收录的网页.png" title="查看被收录的网页"><br><img src="/hexo20191101212014/死链.png" title="死链"><br>这时我们可以在百度站长平台中提交死链，由于死链文件制作稍较复杂，我们可以选择规则提交的方式提交死链（处理死链过程较长，我提交的死链目前还在处理中）。<br>很重要的是，我们需要在自己的所有博文中修改链接，我使用了VScode的搜索关键字符功能对所有markdown文件进行了修改，效率相对较高。此外，如果使用了leancloud等辅助评论评分平台，那么也需要修改对应的url与新的相匹配，否则会造成原来数据的丢弃，还是挺可惜的。</p><hr><h1 id="压缩文件"><a href="#压缩文件" class="headerlink" title="压缩文件"></a>压缩文件</h1><p>关于压缩的方法，网上有很多，可以选择简易的应用。我选择的是用hexo-neat，安装插件后在站点配置文件添加如下设置，效果不错。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># hexo-neat</span><br><span class="line"># 博文压缩</span><br><span class="line">neat_enable: true</span><br><span class="line"># 压缩html</span><br><span class="line">neat_html:</span><br><span class="line">  enable: true</span><br><span class="line">  exclude:</span><br><span class="line"># 压缩css  </span><br><span class="line">neat_css:</span><br><span class="line">  enable: true</span><br><span class="line">  exclude:</span><br><span class="line">    - &apos;**/*.min.css&apos;</span><br><span class="line"># 压缩js</span><br><span class="line">neat_js:</span><br><span class="line">  enable: true</span><br><span class="line">  mangle: true</span><br><span class="line">  output:</span><br><span class="line">  compress:</span><br><span class="line">  exclude:</span><br><span class="line">    - &apos;**/*.min.js&apos;</span><br><span class="line">    - &apos;**/jquery.fancybox.pack.js&apos;</span><br><span class="line">    - &apos;**/index.js&apos;</span><br></pre></td></tr></table></figure><p></p><p>添加完成之后，每次generate你就会在git bash终端看到neat压缩的反馈信息。<br>另外也有和很多网友使用的是gulp压缩，设置也很简便且有效。<br>压缩网站文件不仅可以提高访问加载的速度，同时减少了大量空白符，对SEO也是有不小的帮助的，推荐尝试。</p><hr><h1 id="主动推送"><a href="#主动推送" class="headerlink" title="主动推送"></a>主动推送</h1><p>首先在根目录下安装插件<code>npm install hexo-baidu-url-submit --save</code>。<br>在根目录站点配置文件中新增如下字段：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">baidu_url_submit:</span><br><span class="line">  count: 100 # 提交最新的一个链接</span><br><span class="line">  host: gsy00517.github.io # 在百度站长平台中注册的域名</span><br><span class="line">  token: lY..........Fk # 请注意这是您的秘钥，所以请不要把博客源代码发布在公众仓库里!</span><br><span class="line">  path: baidu_urls.txt # 文本文档的地址，新链接会保存在此文本文档里</span><br></pre></td></tr></table></figure><p></p><p>域名和秘钥可以在站长工具平台的连接提交中的接口调用地址中找到，即对应host与token后面的字段。<br>再把主题配置文件中的deploy修改如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Deployment</span><br><span class="line">## Docs: https://hexo.io/docs/deployment.html</span><br><span class="line">deploy:</span><br><span class="line">- type: git</span><br><span class="line">  repo: </span><br><span class="line">    github: git@github.com:Gsy00517/Gsy00517.github.io.git</span><br><span class="line">    coding: git@git.dev.tencent.com:gsy00517/gsy00517.git</span><br><span class="line">  branch: master</span><br><span class="line">- type: baidu_url_submitter</span><br></pre></td></tr></table></figure><p></p><blockquote><p>注意：必须严格按照上述格式，否则无法deploy。</p></blockquote><p>这样以后每次执行<code>hexo d</code>，新的链接就会主动推送给百度了。</p><hr><h1 id="自动推送"><a href="#自动推送" class="headerlink" title="自动推送"></a>自动推送</h1><p>自动推送是百度搜索资源平台为提高站点新增网页发现速度推出的工具，安装自动推送JS代码的网页，在页面被访问时，页面URL将立即被推送给百度。详情可以查看百度的<a href="https://ziyuan.baidu.com/college/courseinfo?id=267&page=2#h2_article_title18" target="_blank">站长工具平台使用帮助</a>。<br>在blog\themes\next\source\js\src目录下，创建名为bai.js的文件，并根据百度提供的<a href="https://ziyuan.baidu.com/college/courseinfo?id=267&page=2#h2_article_title19" target="_blank">自动推送功能方法</a>添加以下代码：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;script&gt;</span><br><span class="line">(function()&#123;</span><br><span class="line">    var bp = document.createElement(&apos;script&apos;);</span><br><span class="line">    var curProtocol = window.location.protocol.split(&apos;:&apos;)[0];</span><br><span class="line">    if (curProtocol === &apos;https&apos;) &#123;</span><br><span class="line">        bp.src = &apos;https://zz.bdstatic.com/linksubmit/push.js&apos;;</span><br><span class="line">    &#125;</span><br><span class="line">    else &#123;</span><br><span class="line">        bp.src = &apos;http://push.zhanzhang.baidu.com/push.js&apos;;</span><br><span class="line">    &#125;</span><br><span class="line">    var s = document.getElementsByTagName(&quot;script&quot;)[0];</span><br><span class="line">    s.parentNode.insertBefore(bp, s);</span><br><span class="line">&#125;)();</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure><p></p><p>此外，还可以blog\scaffolds目录下的模板文件post.md的分隔线之后添加这么一行：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/bai.js&quot;&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure><p></p><p>这样以后每次创建新的文章就会自动在文末添加这行代码，即在生成的模板中包含这行代码。<br>如此，只要访问你的这个页面，它就会自动向百度推送你的这个网页。<br>在优化的过程中，我发现我的post模板也被改变了（原因目前未知），从原本的：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">title: &#123;&#123; title &#125;&#125;</span><br><span class="line">date: &#123;&#123; date &#125;&#125;</span><br><span class="line">tags:</span><br><span class="line">copyright: true</span><br><span class="line">top:</span><br></pre></td></tr></table></figure><p></p><p>变成了：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">noteId: &quot;9bfafbb............dd5a3&quot;</span><br><span class="line">tags: []</span><br><span class="line">title:</span><br><span class="line">  [object Object]: null</span><br><span class="line">date:</span><br><span class="line">  [object Object]: null</span><br><span class="line">copyright: true</span><br><span class="line">top: null</span><br><span class="line"></span><br><span class="line">---</span><br></pre></td></tr></table></figure><p></p><p>更奇怪的是，我无法删除noteId并恢复到原来的样式，每次更改保存之后又会自动给我换回来，为了方便使用，我将其修改为：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">noteId: &quot;55c6d..............d6fcf&quot;</span><br><span class="line">title:</span><br><span class="line">  &#123;&#123; title &#125;&#125;</span><br><span class="line">date:</span><br><span class="line">  &#123;&#123; date &#125;&#125;</span><br><span class="line">copyright: true</span><br><span class="line">top:</span><br><span class="line">categories:</span><br><span class="line">tags:</span><br><span class="line">---</span><br></pre></td></tr></table></figure><p></p><p>这样就可以直接提取文章标题和创建时间了。<br>对于noteId的作用，网上也找不到相关信息，可能是类似于网站的ID标识的一个代号吧，我对它之后的改进以及用法可见后文。</p><hr><h1 id="使用noteId改进url"><a href="#使用noteId改进url" class="headerlink" title="使用noteId改进url"></a>使用noteId改进url</h1><p>今天看了几个url中含有noteId的网站，立马想到其实noteId其实可以用来替代url的中文等符号从而消除乱码，这更方便了爬虫的抓取。于是，我把站点配置文件下的url设置修改如下：<br><img src="/hexo20191101212014/修改url设置.png" title="修改url设置"><br>同时我把模板文件post.md修改为：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">noteId: &apos;prefix+time remember to change!!!&apos;</span><br><span class="line">title: </span><br><span class="line">  &#123;&#123; title &#125;&#125;</span><br><span class="line">date: </span><br><span class="line">  &#123;&#123; date &#125;&#125;</span><br><span class="line">copyright: true</span><br><span class="line">top:</span><br><span class="line">categories:</span><br><span class="line">tags:</span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">&lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/bai.js&quot;&gt;&lt;/script&gt;</span><br></pre></td></tr></table></figure><p></p><p>这就把我的博文网址修改成了“关键词+创建时间”的形式，当然要手动更改。<br>同样的，以上的操作也带来了巨大的麻烦。我需要给之前没有生成noteId的博文一一加上noteId，同时也免不了对外部辅助平台和网站内链的大幅度修改。<br>对于检查网站死链，我推荐一个挺实用的轻量工具<a href="https://xenus-link-sleuth.en.softonic.com/" target="_blank">Xenu</a>，下载安装之后，选择file，然后check URL，输入网站地址，即可检查站内所有的连接中是否存在死链。下面是我仅修改了url设置而未更改内链时检测的情况，其中红色的就是死链。<br><img src="/hexo20191101212014/检测死链.png" title="检测死链"></p><hr><h1 id="添加robots文件"><a href="#添加robots文件" class="headerlink" title="添加robots文件"></a>添加robots文件</h1><p>Robots协议（也称为爬虫协议、机器人协议等）的全称是“网络爬虫排除标准”（Robots Exclusion Protocol），网站可以通过Robots协议告诉搜索引擎哪些页面可以抓取，哪些页面不能抓取。<br>robots.txt是搜索引擎蜘蛛访问网站时要查看的第一个文件，并且会根据robots.txt文件的内容来爬行网站。在某种意义上说，它的一个任务就是指导蜘蛛爬行，减少搜索引擎蜘蛛的工作量。<br>当搜索引擎蜘蛛访问网站时，它会首先检查该站点根目录下是否存在robots.txt文件，如果该文件存在，搜索引擎蜘蛛就会按照该文件中的内容来确定爬行的范围；如果该文件不存在，则所有的搜索引擎蜘蛛将能够访问网站上所有没有被口令保护的页面。<br>通常搜索引擎对网站派出的蜘蛛是有配额的，多大规模的网站放出多少蜘蛛。如果我们不配置robots文件，那么蜘蛛来到网站以后会无目的地爬行，造成的一个结果就是，需要它爬行的目录，没有爬行到，不需要爬行的，也就是我们不想被收录的内容却被爬行并放出快照。所以robots文件对于SEO具有重要的意义。<br>如果网站中没有robots.txt文件，则网站中的程序脚本、样式表等一些和网站内容无关的文件或目录即使被搜索引擎蜘蛛爬行，也不会增加网站的收录率和权重，只会浪费服务器资源。此外，搜索引擎派出的蜘蛛资源也是有限的，我们要做的应该是尽量让蜘蛛爬行网站重点文件、目录，最大限度的节约蜘蛛资源。<br>在站点根目录的source文件下添加robots.txt文件，加入如下内容：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">User-agent: * Allow: /</span><br><span class="line">Allow: /archives/</span><br><span class="line">Disallow: /categories/</span><br><span class="line">Disallow: /tags/</span><br><span class="line">Disallow: /vendors/</span><br><span class="line">Disallow: /js/</span><br><span class="line">Disallow: /css/</span><br><span class="line">Disallow: /fonts/</span><br><span class="line">Disallow: /vendors/</span><br><span class="line">Disallow: /fancybox/</span><br><span class="line"></span><br><span class="line">Sitemap: https://gsy00517.github.io/sitemap.xml</span><br><span class="line">Sitemap: https://gsy00517.github.io/baidusitemap.xml</span><br></pre></td></tr></table></figure><p></p><p>注意sitemap中要修改成自己的url。<br>另外，可以在站长工具平台检测robots文件。<br><img src="/hexo20191101212014/检测robots.png" title="检测robots"></p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在&lt;a href=&quot;https://gsy00517.github.io/toefl20191019150438/&quot; target=&quot;_blan
      
    
    </summary>
    
    
      <category term="操作与使用" scheme="https://gsy00517.github.io/categories/%E6%93%8D%E4%BD%9C%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="hexo" scheme="https://gsy00517.github.io/tags/hexo/"/>
    
      <category term="配置优化" scheme="https://gsy00517.github.io/tags/%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96/"/>
    
      <category term="SEO" scheme="https://gsy00517.github.io/tags/SEO/"/>
    
  </entry>
  
  <entry>
    <title>machine learning笔记：机器学习的几个常见算法及其优缺点</title>
    <link href="https://gsy00517.github.io/machine-learning20191101192042/"/>
    <id>https://gsy00517.github.io/machine-learning20191101192042/</id>
    <published>2019-11-01T11:20:42.000Z</published>
    <updated>2019-11-02T01:11:46.037Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>接触机器学习也有一段较长的时间了，不敢说自己全部掌握甚至精通，但是期间也了解或者尝试了许多机器学习的算法。这次就结合参考资料和我自己的感受小结一下几种机器学习的常见算法及其优点和缺点。</p><hr><h1 id="决策树算法"><a href="#决策树算法" class="headerlink" title="决策树算法"></a>决策树算法</h1><p>学过数据结构中的树应该对这个算法不会感到困惑，下面就简单介绍一下其优缺点。</p><ol><li><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><ul><li>易于理解和解释，可以可视化分析，容易提取出规则。</li><li>可以同时处理标称型和数值型数据。</li><li>测试数据集时，运行速度比较快。</li><li>决策树可以很好的扩展到大型数据库中，同时它的大小独立于数据库大小。</li></ul></li><li><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul><li>对缺失数据处理比较困难。</li><li>容易出现过拟合问题，容易受到例外的干扰，对测试集非常不友好。</li><li>忽略数据集中属性的相互关联。</li><li>ID3算法计算信息增益时结果偏向数值比较多的特征。</li></ul></li><li><h2 id="改进措施"><a href="#改进措施" class="headerlink" title="改进措施"></a>改进措施</h2><ul><li>对决策树进行剪枝。可以采用交叉验证法和加入正则化的方法。较为理想的决策树是叶子节点数少且深度较小。</li><li>使用基于决策树的combination算法，如bagging算法，randomforest算法，可以解决过拟合的问题。</li></ul></li><li><h2 id="常见算法"><a href="#常见算法" class="headerlink" title="常见算法"></a>常见算法</h2><ol><li><h3 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h3>ID3算法是以信息论为基础，以信息熵和信息增益度为衡量标准，从而实现对数据的归纳分类。ID3算法计算每个属性的信息增益，并选取具有最高增益的属性作为给定的测试属性。C4.5算法核心思想是ID3算法，是ID3算法的改进，改进方面有：</li></ol><ul><li>用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足。</li><li>在树构造过程中进行剪枝。</li><li>能处理非离散的数据。</li><li>能处理不完整的数据。<h4 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h4></li><li>产生的分类规则易于理解，准确率较高。<h4 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h4></li><li>在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效。</li><li>C4.5只适合于能够驻留于内存的数据集，当训练集大得无法在内存容纳时程序无法运行。</li></ul><ol><li><h3 id="CART分类与回归树"><a href="#CART分类与回归树" class="headerlink" title="CART分类与回归树"></a>CART分类与回归树</h3>这是一种决策树分类方法，采用基于最小距离的基尼指数估计函数，用来决定由该子数据集生成的决策树的拓展形。如果目标变量是标称的，称为分类树；如果目标变量是连续的，称为回归树。分类树是使用树结构算法将数据分成离散类的方法。<h4 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h4></li></ol><ul><li>非常灵活，可以允许有部分错分成本，还可指定先验概率分布，可使用自动的成本复杂性剪枝来得到归纳性更强的树。</li><li>在面对诸如存在缺失值、变量数多等问题时CART显得非常稳健。<br>下面对决策树的各种算法做一个小结：<br><table border="1"><tr><td>算法</td><td>支持模型</td><td>树结构</td><td>特征选择</td></tr><tr><td>ID3</td><td>分类</td><td>多叉树</td><td>信息增益</td></tr><tr><td>C4.5</td><td>分类</td><td>多叉树</td><td>信息增益比</td></tr><tr><td>CART</td><td>分类、回归</td><td>二叉树</td><td>基尼系数、均方差</td></tr></table><blockquote><p>补充：<br>信息熵：表示随机变量的不确定性，熵越大，不确定性越大。这与物理中的熵性质类似。<br>信息增益：即不确定性减小的幅度。信息增益=信息熵（前）-信息熵（后）。在构造决策树的时候往往选择信息增益大的特征优先作为节点分类标准。<br>信息增益比：由于仅根据信息增益构建决策树，那么三叉树以及多叉树比二叉树的效果一般来说分类效果要好，然而这很有可能会导致过拟合的问题。因此定义信息增益比=惩罚参数*信息增益。当特征个数较多时，惩罚参数较小；当特征个数较少时，惩罚参数较大，从而使信息增益比较大，进而克服信息增益偏向于选取取值较多的特征的问题。总的来说，信息增益比相对于信息增益更客观。<br>基尼系数：表示集合的不确定性，基尼系数越大，则表示不平等程度越高。</p></blockquote></li></ul></li></ol><hr><h1 id="分类算法"><a href="#分类算法" class="headerlink" title="分类算法"></a>分类算法</h1><ol><li><h2 id="KNN算法"><a href="#KNN算法" class="headerlink" title="KNN算法"></a>KNN算法</h2><ol><li><h3 id="优点-3"><a href="#优点-3" class="headerlink" title="优点"></a>优点</h3><ul><li>KNN是一种在线技术，新数据可以直接加入数据集而不必进行重新训练。</li><li>KNN理论简单，容易实现。实际上，KNN没有训练过程，或者说，它的训练过程就是导入数据集。</li></ul></li><li><h3 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h3><ul><li>KNN对于样本容量大的数据集计算量比较大，极易引发维度灾难。<img src="/machine-learning20191101192042/维度灾难.png" title="维度灾难"></li><li>样本不平衡时，预测偏差比较大。如：某一类的样本比较少，而其它类样本比较多。</li><li>KNN每一次分类都会重新进行一次全局运算，耗时久。</li><li>在CV领域，KNN已经被完全弃用。这是因为它不适合用来表示图像之间的视觉感知差异，如下图所示，这是CS231n中提到的一个例子，后三张图片经过不同的变换，结果与第一张原图的L2距离居然是一样的，而显然对我们而言这三张图是有很大区别的，在实际应用中往往应该区分开。<img src="/machine-learning20191101192042/不适合表征图像差异.png" title="不适合表征图像差异"></li></ul></li><li><h3 id="应用领域"><a href="#应用领域" class="headerlink" title="应用领域"></a>应用领域</h3><ul><li>文本分类。</li><li>模式识别。</li><li>聚类分析。</li><li>多分类领域。</li></ul></li></ol></li><li><h2 id="支持向量机（SVM）"><a href="#支持向量机（SVM）" class="headerlink" title="支持向量机（SVM）"></a>支持向量机（SVM）</h2>支持向量机是一种基于分类边界的方法。其基本原理是（以二维数据为例）：如果训练数据分布在二维平面上的点，它们按照其分类聚集在不同的区域。基于分类边界的分类算法的目标是：通过训练，找到这些分类之间的边界（直线的称为线性划分，曲线的称为非线性划分）。对于多维数据（如N维），可以将它们视为N维空间中的点，而分类边界就是N维空间中的面，称为超面（超面比N维空间少一维）。线性分类器使用超平面类型的边界，非线性分类器使用超曲面。<br>支持向量机的原理是将低维空间的点映射到高维空间，使它们成为线性可分，再使用线性划分的原理来判断分类边界。在高维空间中是一种线性划分，而在原有的数据空间中，是一种非线性划分。<ol><li><h3 id="优点-4"><a href="#优点-4" class="headerlink" title="优点"></a>优点</h3><ul><li>解决小样本下机器学习问题，相对于其他训练分类算法不需要过多样本。</li><li>解决非线性问题。擅长应付线性不可分，主要用松弛变量（惩罚变量）和核函数来实现。</li><li>无局部极小值问题。（相对于神经网络等算法）</li><li>引入了核函数，可以很好的处理高维数据集。</li><li>泛化能力比较强。结构风险最小，指分类器对问题真实模型的逼近与真实解之间的累计误差。</li></ul></li><li><h3 id="缺点-3"><a href="#缺点-3" class="headerlink" title="缺点"></a>缺点</h3><ul><li>对于核函数的高维映射解释力不强，尤其是径向基函数。</li><li>对缺失数据敏感。</li></ul></li><li><h3 id="应用领域："><a href="#应用领域：" class="headerlink" title="应用领域："></a>应用领域：</h3><ul><li>文本分类。</li><li>图像识别。</li><li>主要二分类领域。</li></ul></li></ol></li><li><h2 id="朴素贝叶斯算法"><a href="#朴素贝叶斯算法" class="headerlink" title="朴素贝叶斯算法"></a>朴素贝叶斯算法</h2>朴素贝叶斯，即naive bayes。说白了就是要“sometimes naive”。<ol><li><h3 id="优点-5"><a href="#优点-5" class="headerlink" title="优点"></a>优点</h3><ul><li>对大数量训练和查询时具有较高的速度。即使使用超大规模的训练集，针对每个项目通常也只会有相对较少的特征数，并且对项目的训练和分类也仅仅是特征概率的数学运算而已。</li><li>支持增量式运算。即可以实时的对新增的样本进行训练。</li><li>朴素贝叶斯对结果解释容易理解。</li></ul></li><li><h3 id="缺点-4"><a href="#缺点-4" class="headerlink" title="缺点"></a>缺点</h3><ul><li>由于使用了样本属性独立性的假设，所以如果样本属性有关联时其效果不好。</li></ul></li><li><h3 id="应用领域-1"><a href="#应用领域-1" class="headerlink" title="应用领域"></a>应用领域</h3><ul><li>文本分类。</li><li>欺诈检测。</li></ul></li></ol></li><li><h2 id="Logistic回归算法"><a href="#Logistic回归算法" class="headerlink" title="Logistic回归算法"></a>Logistic回归算法</h2><ol><li><h3 id="优点-6"><a href="#优点-6" class="headerlink" title="优点"></a>优点</h3><ul><li>计算代价不高，易于理解和实现。</li></ul></li><li><h3 id="缺点-5"><a href="#缺点-5" class="headerlink" title="缺点"></a>缺点</h3><ul><li>容易产生欠拟合。</li><li>分类精度不高。</li></ul></li><li><h3 id="应用领域-2"><a href="#应用领域-2" class="headerlink" title="应用领域"></a>应用领域</h3><ul><li>用于二分类领域，可以得出概率值，适用于根据分类概率排名的领域，如搜索排名等。</li><li>Logistic回归的扩展softmax可以应用于多分类领域，如手写字识别等。</li></ul></li></ol></li></ol><hr><h1 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h1><ol><li><h2 id="K-means算法"><a href="#K-means算法" class="headerlink" title="K-means算法"></a>K-means算法</h2>K-means算法，即K均值算法，是一个简单的聚类算法，把n的对象根据他们的属性分为k个分割，k小于n。算法的核心就是要优化失真函数J，使其收敛到局部最小值但不是全局最小值。它比较适合凸数据集，即任意两个数据点之间的连线都在数据集内部。<ol><li><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><ol><li>随机选择k个随机的点（称为聚类中心）。</li><li>对数据集中的每个数据点，按照距离k个中心的距离，将其与最近的中心点关联起来，与同一中心点关联的点聚成一类。</li><li>计算每一组的均值，将该组所关联的中心点移到平均值的位置。</li><li>重复第2、3两步，直到中心点不再变化。</li></ol></li><li><h3 id="优点-7"><a href="#优点-7" class="headerlink" title="优点"></a>优点</h3><ul><li>算法速度很快。</li></ul></li><li><h3 id="缺点-6"><a href="#缺点-6" class="headerlink" title="缺点"></a>缺点</h3><ul><li>分组的数目k是一个输入超参数，不合适的k可能返回较差的结果。</li></ul></li></ol></li><li><h2 id="EM最大期望算法"><a href="#EM最大期望算法" class="headerlink" title="EM最大期望算法"></a>EM最大期望算法</h2>EM算法是基于模型的聚类方法，是在概率模型中寻找参数最大似然估计的算法，其中概率模型依赖于无法观测的隐藏变量。E步估计隐含变量，M步估计其他参数，交替将极值推向最大。<br>EM算法比K-means算法计算复杂，收敛也较慢，不适于大规模数据集和高维数据，但比K-means算法计算结果稳定、准确。EM经常用在机器学习和计算机视觉的数据集聚（Data Clustering）领域。</li></ol><hr><h1 id="集成算法（AdaBoost）"><a href="#集成算法（AdaBoost）" class="headerlink" title="集成算法（AdaBoost）"></a>集成算法（AdaBoost）</h1><p>俗话说的好“三个臭皮匠，顶个诸葛亮”，集成算法就是将多个弱分类器集成在一起，构建一个强分类器。事实上，它可能不属于算法，而更像一种优化手段。</p><ol><li><h2 id="优点-8"><a href="#优点-8" class="headerlink" title="优点"></a>优点</h2><ul><li>很好的利用了弱分类器进行级联。</li><li>可以将不同的分类算法作为弱分类器。</li><li>AdaBoost具有很高的精度。</li><li>相对于bagging算法和randomforest算法，AdaBoost充分考虑的每个分类器的权重。</li></ul></li><li><h2 id="缺点-7"><a href="#缺点-7" class="headerlink" title="缺点"></a>缺点</h2><ul><li>AdaBoost迭代次数也就是弱分类器数目不太好设定，可以使用交叉验证来进行确定。</li><li>数据不平衡导致分类精度下降。</li><li>训练比较耗时，每次重新选择当前分类器最好切分点。</li></ul></li><li><h2 id="应用领域-3"><a href="#应用领域-3" class="headerlink" title="应用领域"></a>应用领域</h2><ul><li>模式识别。</li><li>计算机视觉领域。</li><li>二分类和多分类场景。</li></ul></li></ol><hr><h1 id="神经网络算法"><a href="#神经网络算法" class="headerlink" title="神经网络算法"></a>神经网络算法</h1><ol><li><h2 id="优点-9"><a href="#优点-9" class="headerlink" title="优点"></a>优点</h2><ul><li>分类准确度高，学习能力极强。</li><li>对噪声数据鲁棒性和容错性较强。</li><li>有联想能力，能逼近任意非线性关系。</li></ul></li><li><h2 id="缺点-8"><a href="#缺点-8" class="headerlink" title="缺点"></a>缺点</h2><ul><li>神经网络参数较多，权值和阈值。</li><li>黑盒过程，不能观察中间的结果，甚至无法完全理解其是怎么达到效果的。</li><li>学习过程比较长，有可能陷入局部极小值。</li></ul></li><li><h2 id="应用领域-4"><a href="#应用领域-4" class="headerlink" title="应用领域"></a>应用领域</h2><ul><li>计算机视觉。</li><li>自然语言处理。</li><li>语音识别等。</li></ul></li></ol><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;接触机器学习也有一段较长的时间了，不敢说自己全部掌握甚至精通，但是期间也了解或者尝试了许多机器学习的算法。这次就结合参考资料和我自己的感受小结一
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://gsy00517.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="机器学习" scheme="https://gsy00517.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>toefl笔记：首考考托福——记一次裸考经历</title>
    <link href="https://gsy00517.github.io/toefl20191019150438/"/>
    <id>https://gsy00517.github.io/toefl20191019150438/</id>
    <published>2019-10-19T07:04:38.000Z</published>
    <updated>2019-11-02T02:23:07.434Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>今天上午终于把自己开学以来耿耿于怀的托福考完了。目前来看是铁定要二战了，因此下午抽空把这次考试的经历总结一下，方便再战的时候可以吸取经验和教训。</p><hr><h1 id="前期"><a href="#前期" class="headerlink" title="前期"></a>前期</h1><p>大一下学期的时候去听了一个学姐的出国分享会，当然是新东方支持的，讲座已结束就被新东方的老师搞了一波传销。当时也不知道托福的有效期是两年，头脑一热就报了班和十月份的托福。不过后来想想可能暑研和暑校也用得上，或许不亏。<br>于是我抽了个周末去新东方校区做了一个入班小测，很幸运的是我的分能进入强化班，毕竟高中的底子还可以。然而很坑的是，我从同学那得知去年同期的同一个班报名费比我少了将近一千（我报的强化班4400rmb），简直坐地起价啊！可能时间比较早校方不是很担心没人报。<br>然后到了暑假，我开始零零散散地准备。在家做了一套听力一套阅读，心态就崩了，怎么这么难！感觉就是跟四六级不在一个档次上。<br><img src="/toefl20191019150438/啥.JPG" title="啥"><br>于是三分钟热度就被浇没了，之后就只是背单词了，打算等八月上了课听了老师的解题方法再强化练习。<br>到了八月中旬，开始上课了，听了几节课明白题型之后，感觉托福或许也没有想象得那么可怕，熟悉就好。那段时间回去后断断续续刷了几套TPO的阅读和听力部分。<br>然后开学一周，很快就到了国庆。根据我的原计划，身为拖延症重度患者的我打算在国庆力挽狂澜，为此我早早地准备好了新东方的《7天搞定托福高频核心词》，当时觉得时间充裕，计划合理，未来充满希望。然而…<br><img src="/toefl20191019150438/都是假的.jpg" title="都是假的"><br>等到国庆结束，我也明白了一个道理：不能被事物的表面现象所迷惑。不过，乐观的我依然觉得剩下的两周足以完成复习。<br>However，国庆上来劈头盖脸砸过来的课程和任务让我分身乏术。周三晚上的实验课，我做到十一点才回寝室，这更是对我的致命一击。因为回寝太晚，没时间更换被子，导致挨冻一晚上（武汉的天气太怪了）。最后，又是喉咙痛，又是犯鼻炎，那时就感觉托福基本要凉。<br>考前第二天，我又刷了一套新托福的阅读和听力，成绩不是特别理想。由于新东方的TPO加载速度感人，也可能是学校网络的问题，总之直到考试之前，我只在小站刷过三套TPO，在新东方刷过两套老TPO和一套新TPO。<br><img src="/toefl20191019150438/校园网.JPG" title="校园网"><br>甚至直到写这篇文章的标题之前，我都不知道托福的英文拼写是“TOEFL”（之前一直觉得是“TOFEL”）。<br>考试前一天，病情加重，我也就不刷题了，把上课的笔记和题型又好好熟悉了一下就早点休息了。</p><hr><h1 id="考前"><a href="#考前" class="headerlink" title="考前"></a>考前</h1><p>考前问了新东方替我报名的老师，她说要打印确认信。不知道为什么我无法下载确认信成pdf格式的，最后屏幕截图打算打印，早上去考场的时候却忘记了。不过还好最后发现根本不需要确认信。<br>早上提早一个小时出寝室，结果发现找不到租八戒了，不知道为什么周六大家起这么早。最后租了辆摩拜拖着病体艰难地骑到了考场。<br>到了考试的楼下，有一个小姐姐热心地给我指路，不过我马上就发现她别有目的。她让我填一个貌似是培训机构的表格，善良易上当的我稀里糊涂地填了，本来想写个假的电话，结果感冒头很晕也没多想就如实写了，反正我平时也不怎么接陌生电话。<br>坐电梯到了考试的楼层，碰到我们学院一个经常见到的学长在做志愿者。他总是活跃在各种场合，好像是英语协会的，总之看到他也是开心了一小下。之后就是看序号，签到，领钥匙，去存背包。<br>在储物室的时候，一边的考试人员一直重复说“A考场的人可以把水拿出来”，我没听太懂。由于之前问过她我鼻炎犯了可不可以带餐巾纸（她说考场会提供），就不想再问第二次了。之前看别人的考试经历，说中途休息时可以出来喝水吃零食，还可以看写作模板，我以为是可以回到储物室的，后来才发现不能。<br>放完东西，我本来想再看会英语进入一下状态，结果过安检之后就只能一直在里边等了。<br>我们来到一个签承诺书的房间，大家都一排排坐在一种比较矮的长凳上，我拿了一张承诺书和一支笔就往后坐了。其实还可以拿个写字的时候用来垫的板子，我没注意，不过好多人和我一样都是在腿上或者趴凳子上写的。写承诺书的时候我没仔细看黑板上的要求，写错了一次，只好挺无奈地找工作人员换了一张。<br>不一会人就好多了，我发现这次考托福的女生比较多，大约是男生的两倍，这在我们学校很不常见啦。考试的也有大人，在我观察是不是还有培训机构的老师的时候，我的隔壁也是实验班的一个朋友也来考试了。他在C考场，那个考场更大。我的A考场人最少，相对来说环境要理想一些。不过不同考场的同学还是在同一个房间等待的。我继续观察，发现还是有几个大二面孔的，和几个人说了几句，发现还是有不少首考的人的。</p><hr><h1 id="入场"><a href="#入场" class="headerlink" title="入场"></a>入场</h1><p>过了一会有一个男老师进来说一些有关考试的注意事项，说完没多久大家就到隔壁的考试教室刷脸入场了。<br>考场的教室和等候的教室一样，也是黄色的日光灯，看着也挺舒适。入场顺序是按照姓氏的首字母顺序的，我进去的比较早。尽管A考场大概也就二三十个人，但整个入场过程还是挺久的。<br>考官把我领到座位上，虽然是随机抽的但好像我的考位还是我的序号。为我把身份证插在旁边的卡槽里之后，考官又为我输了激活码进入考试界面，然后没说什么就走了。<br>考试的隔间挺好，靠桌子往里坐一点就完全看不到旁边了。首先是确认姓名的界面，然而考官走了我也没处问，担心确认了就直接开始考试了因此久久没敢点。由于别人还在入场，因此我不敢太早开始考试。我回头看了一眼，发现是我进候考室以来就注意到的那个男生。虽然没问过他，但看上去他这次绝对不是一战了。<br>过了一会，我听到有人点鼠标的声音，于是我也鼓足勇气开始点。前面大概有七八的页面都是只需continue的direction界面，而且这个界面是不会自动跳转的，我在这里停留了很久。<br>终于，大概第十个人入场的时候，我听到有人开始试音了。意外的是，第一个开始试音的人居然真的在介绍他生活的城市。哈哈哈看来也是首考的，不知道待会整个考场一齐开始诠释人类的本质的时候，他有什么感想。这里我暗暗庆幸自己报了班。<br>当大家都在诠释人类的本质时，我心里觉得还是挺可乐的。不过就在这时，我听到前面提到的那位久经沙场的老哥也开始复读了，于是我又点了一个continue。<br>每个continue我的拖好久才点，不过入场真的是挺久的。大概有十个人完成试音之后，我才看到了describe the city you live in，心想这个时间还是可以的。</p><hr><h1 id="阅读"><a href="#阅读" class="headerlink" title="阅读"></a>阅读</h1><p>直到考试，我才知道review的用法，点击之后，会出现一个表格，可以看到哪些题已经answered了。<br>阅读第一篇是关于研究者根据化石推断远古的自然环境，第二篇是什么记不太清了，好像也是历史相关的，第三篇是北美西海岸土著人的一些文化，还有配图。没有遇到加试。<br>总的来说，考场里效率还是比寝室要好一些的。我大概还有40分钟时做完了第一篇，到最后一篇时时间还有20多分钟，相对来说还是比较宽裕的。</p><hr><h1 id="听力"><a href="#听力" class="headerlink" title="听力"></a>听力</h1><p>接下来就是听力了，我的听力是加试，有3个section。第一个section的对话我考虑太久，导致最后答lecture三道题要在一分钟之内答完。当时也只能以这个section只有50%的概率计入成绩来安慰自己。<br>第二个section做得还行，一些笔记还是没记到要点上，还是得多练。遗憾的是，我听力有好几篇都没听懂听力开头“you will hear part of a lecture in a ……gy class”中学科具体是什么，如果能听懂的话肯定是有一定帮助的，词汇量还不够啊！<br><img src="/toefl20191019150438/我太难了.JPG" title="我太难了"><br>到了第三个section，我之前在考试教室门外抽的餐巾纸用完了，我只能忍着做题，结果第三个section的lecture的conversation中的男老师似乎有异国口音，说得很不清楚，在lecture部分我也走了一会神。同样的，我发现我不是很善于掌握1个conversation+1个lecture情况下的时间，lecture的时间又分配得不多。当时也只能又以这个section只有50%的概率计入成绩来安慰自己，好吧其实两个section都凉了。<br>考试前两天对自己的listening还是最自信的，现在看来还是得花真功夫才行。</p><hr><h1 id="休息"><a href="#休息" class="headerlink" title="休息"></a>休息</h1><p>终于休息了，我出门的时候拿到张纸条，上面提醒我11：04返场。我本来想喝口热水缓解一下我喉咙的疼痛，却被告知不能回储物室了。我这时候看到别的同学放在楼梯口的一个大桌子上的水和零食，心里真的拔凉拔凉的。我5块钱买的士力架啊！我的口语写作模板啊！不过好像大多数人都没怎么吃东西，要是我不生病的话应该也没什么问题。<br>考场外面的钟不是很准，我一直担心里面开始口语了我还没进去，后来发现开始第二部分的考试也是需要考官输入验证码的，因此完全不必担心。<br>什么都没带，我那十分钟也就上了个厕所并且补充了餐巾纸。</p><hr><h1 id="口语"><a href="#口语" class="headerlink" title="口语"></a>口语</h1><p>之前开始的晚，因此我休息的时间也差不多在大家的中间。口语部分一开始的continue就比较少了，又试了一次音。这回就没有人真正介绍自己的城市了，大家又当了一回复读机。可能由于感冒造成鼻音太重的问题，我试音的音量偏低，得说得用点劲才行。<br>我在这里也停顿得有点久，因为待会等大家都开始说了，我就可以偷偷混投入其中以掩盖我拙劣的口语哈哈。事实上，和大家一起说真的能说得更开更自信，当大部分人说完之后，我们考场里有一个女生还在说，我明显地听到她顿了一下，然后声音顿时小了很多。<br>之前超牛的老哥老早就进去了（他很早就完成了听力），我进去之后本想偷听他在说什么，因为口语题都一样，结果…天呐竟然跟不上他的语速！还好这时候有一个水平不高但的确可以帮到我的吞吞吐吐的小哥开始讲了，我听到他在说work什么的，自己在脑子里构思了一下便也开始答题了。<br>然而，我的提前构思反倒先入为主了。当题目放出来时，我花了好久才读清题目，因为跟我想的太不一样了。以后还是不能太期望于听到别人的答案。最后，第一部分比较凉。<br>其实整个口语都比较凉，因为我感冒鼻音简直太重了，就像蒙着几个口罩一样，特别是其中有个录音我还咳嗽了几声。<br><img src="/toefl20191019150438/啊啊啊啊啊.gif" title="啊啊啊啊啊"></p><hr><h1 id="写作"><a href="#写作" class="headerlink" title="写作"></a>写作</h1><p>最后两部分考试感觉时间飞快，既然口语凉了，也听说写作给分还可以，我就放飞自我开始写了。<br>在我听听力的时候，就听到劈里啪啦的打字声了。一直对自己打字速度很有自信的我还是小惊讶了一下。<br>两篇作文都不是很难，我第二篇大概只写了三百词出头一些，细节还是写的有点少，都是论述的，这点下回要改进。两篇作文都是到点自动保存提交的，没有整体检查拼写，打字速度还是得练，盲打还是得加强。考场的机械键盘相对来说比较扁平，跟笔记本手感还是比较相近的。</p><hr><h1 id="考完"><a href="#考完" class="headerlink" title="考完"></a>考完</h1><p>最后还有一个report成绩还是cancel的选项，考官明确说过这个不能提问，于是我看的很仔细。还好我的水平还是无压力看懂了，砸了两千块当然要report啦！出考场后还是有点不放心特地查了一下，发现还是有网友选cancel的，不过好像可以付额外的费用解决。<br>出考场才知道已经十二点半了，由于中途没补充零食，肚子也是饿得咕咕叫（写大作文的时候开始明显感到饿）。从储物柜拿手机的时候，不小心带了出来，掉在地上了，心里一惊，还好只在钢化膜上留下一条线，当时也觉得无所谓了。<br>考完也挺平静的，感觉托福考试也就这样，只可惜这次时运不济，命途多舛。以后考托福一定要在学期初考，并且好好准备，关键是要注意身体的健康！<br>早上起来的时候百度了一下自己的博客，发现已经被李彦宏爸爸的百度收录了，可以直接百度到我的博客和文章，也是今天比较开心的一件事吧，以后会好好做SEO的。</p><hr><h1 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h1><p>出成绩了，更新一下。<br>10月19号上午考完的试，31号凌晨3：51终于刷新的成绩。查询页面显示的是“2019年10月23日的MyBest Scores”，不知道是不是23号就批好了成绩。考完后一直关注贴吧和公众号，似乎我那周是最后一次最多两周出成绩的考试，以后托福的成绩好像都会考后10天就出结果。雅思更狠，马上跟着改成了6天出成绩，它们是不是也在竞争呢…<br>查分的时候还是很忐忑的，没想到这次首考的成绩能到90+，虽然完全不够，但还是比我想象得要好一些的。口语果然离20还是差了一点，或许有生病的影响，但的确能体现我的水平，还是得加强练习！别人口中的提分项——写作，我也没有取得高分，看来还是不能大意，平时需要熟能生巧。但愿二战能够取得一定的进步吧！<br>今天去听了我们学校的海外交流项目介绍的讲座，大体上的语言成绩要求是CET4&gt;550，CET6&gt;500，TOEFL&gt;80，IELTS&gt;6.0，否则要电话面试，但这些基本都是相对来说比较中规中矩的科研项目或者学分项目，还是得努力提高英语水平啊！</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;今天上午终于把自己开学以来耿耿于怀的托福考完了。目前来看是铁定要二战了，因此下午抽空把这次考试的经历总结一下，方便再战的时候可以吸取经验和教训。
      
    
    </summary>
    
    
      <category term="英语" scheme="https://gsy00517.github.io/categories/%E8%8B%B1%E8%AF%AD/"/>
    
    
      <category term="个人经历" scheme="https://gsy00517.github.io/tags/%E4%B8%AA%E4%BA%BA%E7%BB%8F%E5%8E%86/"/>
    
      <category term="托福" scheme="https://gsy00517.github.io/tags/%E6%89%98%E7%A6%8F/"/>
    
  </entry>
  
  <entry>
    <title>artificial intelligence笔记：吴恩达——阅读论文的建议</title>
    <link href="https://gsy00517.github.io/artificial-intelligence20191007232512/"/>
    <id>https://gsy00517.github.io/artificial-intelligence20191007232512/</id>
    <published>2019-10-07T15:25:12.000Z</published>
    <updated>2019-11-02T02:21:05.458Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>接触科研，读paper是一件很头疼的事情。本文就来写一下吴恩达对于阅读ML、DL相关方面论文的建议，方便参考。</p><hr><h1 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h1><p>首先要说明的是，这里的建议不是我想出来的，仅仅是对吴恩达提供的建议做搬运及整理。<br>如果你读到这里，应该也知道这个领域的先驱+巨佬Andrew Ng的大名。吴恩达（Andrew Ng），著名的美籍华裔计算机科学家，曾担任百度首席科学家，任教于Stanford，大家刚入门的时候想必都了解过或者看过由吴恩达老师讲授的斯坦福的经典课程CS229机器学习、CS230深度学习，此外，Andrew Ng还特地在网易云上为中国学生提供了中文字幕的课程（Andrew Ng英语说得比中文溜好多了哈哈）。另外，他还是著名教育平台Coursera的创始人，那里的课程更新鲜更优质，而且还可以锻炼英语能力，旁听即可。<br><img src="/artificial-intelligence20191007232512/啊！.jpg" title="啊！"><br>呃放错了，不是上面那张，是这张。<br><img src="/artificial-intelligence20191007232512/吴恩达.jpg" title="吴恩达"><br>对于如何阅读论文，Andrew Ng的建议是：<br>不要从头读到尾。相反，需要多次遍历论文。<br>具体有如下几个注意点：</p><ol><li><h2 id="阅读文章标题、摘要和图"><a href="#阅读文章标题、摘要和图" class="headerlink" title="阅读文章标题、摘要和图"></a>阅读文章标题、摘要和图</h2>通过阅读文章标题、摘要、关键网络架构图，或许还有实验部分，你将能够对论文的概念有一个大致的了解。在深度学习中，有很多研究论文都是将整篇论文总结成一两个图形，而不需要费力地通读全文。尤其是在描述网络架构的时候，作者一般会采用比较通用的格式，读多了就会熟悉起来，比如下面DenseNet的结构：<img src="/artificial-intelligence20191007232512/DenseNet.jpg" title="DenseNet"></li><li><h2 id="读介绍、结论、图，略过其他"><a href="#读介绍、结论、图，略过其他" class="headerlink" title="读介绍、结论、图，略过其他"></a>读介绍、结论、图，略过其他</h2>介绍、结论和摘要是作者试图仔细总结自己工作的地方，以便向审稿人阐明为什么他们的论文应该被接受发表。<br>此外，略过相关的工作部分（如果可能的话），这部分的目的是突出其他人所做的工作，这些工作在某种程度上与作者的工作有关。因此，阅读它可能是有用的，但如果不熟悉这个主题，有时会很难理解。<img src="/artificial-intelligence20191007232512/大佬也不懂.JPG" title="大佬也不懂"></li><li><h2 id="通读全文，但跳过数学部分"><a href="#通读全文，但跳过数学部分" class="headerlink" title="通读全文，但跳过数学部分"></a>通读全文，但跳过数学部分</h2>这里我说一下我对于数学部分的处理：一般我会把重要的公式等略读一遍，然后参照着CSDN博客等网站上其他网友的解释与详解进行理解。<img src="/artificial-intelligence20191007232512/先用再说.PNG" title="先用再说"></li><li><h2 id="通读全文，但略过没有意义的部分"><a href="#通读全文，但略过没有意义的部分" class="headerlink" title="通读全文，但略过没有意义的部分"></a>通读全文，但略过没有意义的部分</h2>Andrew Ng还解释说，当你阅读论文时（即使是最有影响力的论文），你可能也会发现有些部分没什么用，或者没什么意义。因此，如果你读了一篇论文，其中一些内容没有意义（这并不罕见），那么你可以先略读。除非你想要掌握它，那就花更多的时间。确实，当我在阅读ILSVRC、COCO等顶级比赛许多获奖模型的论文时，其中都有对比赛情况的详细结果介绍，我觉得这些部分一定程度上是可以扫读和跳读的。</li></ol><hr><h1 id="分享"><a href="#分享" class="headerlink" title="分享"></a>分享</h1><p>关于论文，我之前也做过一些分享，详情可以看看我之前的文章。<br>在<a href="https://gsy00517.github.io/deep-learning20190915113859/" target="_blank">deep-learning笔记：开启深度学习热潮——AlexNet</a>一文中，我提到了刚开始阅读英文论文的比较有效的方法。<br>在<a href="https://gsy00517.github.io/deep-learning20191001184216/" target="_blank">deep-learning笔记：使网络能够更深——ResNet简介与pytorch实现</a>一文中，我也提供了许多经典模型论文的英文版、中文版、中英对照的链接。<br>最后要说明的是，本篇文章中Andrew Ng的建议有部分摘自公众号Datawhale的推送文章。我关注了不少这方面的公众号，删选了几个比较优质的，在今后也会一一放到博客中推荐。<br><img src="/artificial-intelligence20191007232512/Datawhale.JPG" title="Datawhale"></p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;接触科研，读paper是一件很头疼的事情。本文就来写一下吴恩达对于阅读ML、DL相关方面论文的建议，方便参考。&lt;/p&gt;&lt;hr&gt;&lt;h1 id=&quot;建
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://gsy00517.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="机器学习" scheme="https://gsy00517.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://gsy00517.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文分享" scheme="https://gsy00517.github.io/tags/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>欢迎到访：写在前面</title>
    <link href="https://gsy00517.github.io/preface20191007202443/"/>
    <id>https://gsy00517.github.io/preface20191007202443/</id>
    <published>2019-10-07T12:24:43.000Z</published>
    <updated>2019-11-02T02:20:43.969Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>不知不觉，建站已有不少日子了，无论是内容还是界面，都逐渐丰富了起来。觉得有必要补充一篇类似于导言的文字，今天抽出点时间写一下，日后继续完善。</p><hr><h1 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h1><p>我来自浙江，就读于华科，目前是一名电子信息工程专业的大二本科生。从大学开始真正比较全面地接触信息技术，一年下来，在课余接触并尝试过的方面主要有编程语言python与R、linux操作系统、前端设计、机器学习与深度学习。我的博客也主要围绕这几个方面展开。<br>入门没多久，许多理解也还比较浅薄，博客内容主要是一些干货的搬运分享并结合自己积累的一些理解与经验，会有不足与疏漏，如果大家能给予指导，我将非常感激！今后我会尽量陆续加入更多深层次的内容。<br>对于这个博客网站，可以把它看作一个技术博客，而我更多的把它看成一个自己的空间，因此偶尔也会加入一些学习生活的元素，请别见怪！</p><hr><h1 id="关于博客"><a href="#关于博客" class="headerlink" title="关于博客"></a>关于博客</h1><p>为了提高访问速度，我对我的博客进行了github+coding双线部署，url如下：<br>github page：<a href="https://gsy00517.github.io/">https://gsy00517.github.io/</a><br>coding page：<a href="http://gsy00517.coding.me/" target="_blank" rel="noopener">http://gsy00517.coding.me/</a><br>大家可以择优访问，事实上我并没有感到github的速度比coding慢。此外，由于我是同一个源文件双线部署，因此选择了把所有功能优先应用在github page上（比如文章打分、文章链接），但其实coding page也没有太大的区别。<br>由于我的文章主要是按时间顺序由新到老排列的，多了之后不方便查找和浏览，因此我新增了<a href="https://gsy00517.github.io/tags/" target="_blank">标签</a>和<a href="https://gsy00517.github.io/categories/" target="_blank">分类</a>，或许可以帮助你更快地查看想看的内容。此外，也推荐使用我页面上的搜索功能利用关键词查找，非常便捷。</p><blockquote><p>注：PC体验更佳~</p></blockquote><hr><h1 id="关于订阅"><a href="#关于订阅" class="headerlink" title="关于订阅"></a>关于订阅</h1><p>首先，我想说的是，如果你觉得我写的内容，或者方向对你有一点用处的话，非常欢迎收藏或订阅我的博客！如果你也在写博客的话，我们可以互相关注！<br>在侧栏，你可能会发现这样一个图标。点击之后，你会进入一个看不懂的atom.xml文件。<br><img src="/preface20191007202443/RSS.png" title="RSS"><br>其实，看不懂是正常的，因为这个是给电脑看的。一个便捷的办法就是使用chrome的扩展程序添加feed，然后打开网页时，就可以直接点击浏览器右上角的图标（会显示加号）进行订阅。这样以后每次更新了新的博文，你就可以收到提醒。<br><img src="/preface20191007202443/扩展程序.png" title="扩展程序"><br><img src="/preface20191007202443/消息提醒.png" title="消息提醒"><br>此外还可以像收藏其他网站一样进行收藏，这里不详述了。<br>欢迎大家常来踩踩，也欢迎大家留下评论。评论很简单，无需登录任何账号直接评论即可~<br>我目前也还在学习的过程中，欢迎大家和我交流，也欢迎各种批评与建议，我会努力改进！</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;不知不觉，建站已有不少日子了，无论是内容还是界面，都逐渐丰富了起来。觉得有必要补充一篇类似于导言的文字，今天抽出点时间写一下，日后继续完善。&lt;/
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>calculus笔记：分部积分表格法</title>
    <link href="https://gsy00517.github.io/calculus20191007184856/"/>
    <id>https://gsy00517.github.io/calculus20191007184856/</id>
    <published>2019-10-07T10:48:56.000Z</published>
    <updated>2019-11-02T02:21:10.307Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>假期里想着不能让b站收藏夹里的学习资源一直吃灰，于是又刷了一遍b站的收藏夹。碰巧就看到了自己之前收藏的一种积分方法，那么这篇文章就来搬运一下这种方法的计算流程。</p><hr><h1 id="表格法"><a href="#表格法" class="headerlink" title="表格法"></a>表格法</h1><p>事实上，这种方法说白了还是分部积分法，但使用起来却要方便好多。我们直接看例子：<br>求解$ \int \left ( x^{2}+x \right )e^{x}dx $。</p><ol><li>画一个两行的表格。把多项式部分写在第一行，然后把剩余的部分写在第二行。<table border="1"><tr><td>$ x^{2}+x\ $</td><td></td></tr><tr><td>$ e^{x}\ $</td><td></td></tr></table></li><li>接下来，我们对第一行求导，直到导数为零为止。对第二行积分，直到与第一行的0对齐为止。<table border="1"><tr><td>$ x^{2}+x\ $</td><td>$ 2x+1\ $</td><td>2</td><td>0</td></tr><tr><td>$ e^{x}\ $</td><td>$ e^{x}\ $</td><td>$ e^{x}\ $</td><td>$ e^{x}\ $</td></tr></table></li><li>第三步就是交叉相乘，在本题即为第一行第一列与第二行第二列相乘，第一行第二列与第二行第三列相乘，第一行第三列与第二行第四列相乘。要注意的是，这里的交叉相乘还需要带符号，依次为正负正负正…以此类推。最后，将相乘结果相加，整理即可得到最终的解。<script type="math/tex;mode=display">+\left ( \left ( x^{2}+x \right )*e^{x} \right )-\left ( \left ( 2x+1 \right )*e^{x} \right )+\left ( 2*e^{x} \right )=\left ( x^{2}-x+1 \right )*e^{x}+C\</script><blockquote><p>注意：别忘了加上常数C。</p></blockquote></li></ol><p>下面再来看一个例子熟悉一下：<br>求解$ \int xsinxdx $。<br>画表格：<br><table border="1"><tr><td>$ x\ $</td><td>$ 1\ $</td><td>$ 0\ $</td></tr><tr><td>$ sinx\ $</td><td>$ -cosx\ $</td><td>$ -sinx\ $</td></tr></table><br>求解：</p><script type="math/tex;mode=display">+\left ( x*\left ( -cosx \right ) \right )-\left ( 1*\left ( -sinx \right ) \right )=-xcosx+sinx+C\</script><p>其实b站上还是有挺多这样的干货的，此生无悔入b站！<br><img src="/calculus20191007184856/b站大学.png" title="b站大学"></p><hr><h1 id="其它运算终止情况"><a href="#其它运算终止情况" class="headerlink" title="其它运算终止情况"></a>其它运算终止情况</h1><p>看完上面的部分，细心的你肯定会想到以上的方法并不普适，仅仅适用于导数能求导至零及含有多项式因式的情况。因此，为了能更灵活地运用分部积分表格法，下面补充其它两种运算可以终止的情况。</p><ol><li><h2 id="第一行出现零元素"><a href="#第一行出现零元素" class="headerlink" title="第一行出现零元素"></a>第一行出现零元素</h2>这就是上面所说的含多项式的情况，也一并列写在这里，方便总览归纳。</li><li><h2 id="某列函数的乘积（或它的常数倍）等于第一列"><a href="#某列函数的乘积（或它的常数倍）等于第一列" class="headerlink" title="某列函数的乘积（或它的常数倍）等于第一列"></a>某列函数的乘积（或它的常数倍）等于第一列</h2>按照分部积分的一般做法，当出现之后的某一项恰好是原来积分或者是原来积分的常数倍时，计算进入循环。这时就可以把两者移到等式的同一侧，计算出结果，这在表格法的分部积分中也是类似的。<br>来看看例子：求解$ \int e^{3x}sin2xdx $。<br><table border="1"><tr><td>$ e^{3x}\ $</td><td>$ 3e^{3x}\ $</td><td>$ 9e^{3x}\ $</td></tr><tr><td>$ sin2x\ $</td><td>$ -\frac{cos2x}{2}\ $</td><td>$ -\frac{sin2x}{4}\ $</td></tr></table><br>可见，第三列的乘积和第一列的乘积相差一个常数（这里是$ -\frac{9}{4} $），因此仿照之前的方法交叉相乘列出积分：<script type="math/tex;mode=display">\int e^{3x}sin2xdx=e^{3x}(-\frac{cos2x}{2})-3e^{3x}(-\frac{sin2x}{4})+9(-\frac{1}{4})\int e^{3x}sin2xdx\</script>移项化简可得：<script type="math/tex;mode=display">\int e^{3x}sin2xdx=\frac{1}{13}e^{3x}(3sin2x-2cos2x)+C\</script>即为所求。</li><li><h2 id="某列的两个函数乘积（记为-f-x-）是一个容易计算的积分"><a href="#某列的两个函数乘积（记为-f-x-）是一个容易计算的积分" class="headerlink" title="某列的两个函数乘积（记为$ f(x) $）是一个容易计算的积分"></a>某列的两个函数乘积（记为$ f(x) $）是一个容易计算的积分</h2>这种情况下，先把之前的项用之前的方法类似列出，再在结果后加上不定积分$ (-1)^{k-1}\int f(x)dx $。<br>来看例子：求解$ \int x^{2}arctanxdx $。<br><table border="1"><tr><td>$ arctanx\ $</td><td>$ \frac{1}{1+x^{2}}\ $</td></tr><tr><td>$ x^{2}\ $</td><td>$ \frac{1}{3}x^{3}\ $</td></tr></table><br>可得解：<script type="math/tex;mode=display">\int x^{2}arctanxdx=\frac{1}{3}x^{3}arctanx-\frac{1}{3}\int \frac{x^{3}}{1+x^{2}}dx=\frac{1}{3}\left \{ x^{3}arctanx-\frac{1}{2}[x^{2}-ln(1+x^{2})] \right \}+C\</script>另外，当表中的第一行的某列出现多项之和，而再求导无法改变该函数或者该函数中某一项的属性，则终止表格，后再重新组合，另建表格求解。这种情况一般不会出现在题目中，如遇到再做补充。</li></ol><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;假期里想着不能让b站收藏夹里的学习资源一直吃灰，于是又刷了一遍b站的收藏夹。碰巧就看到了自己之前收藏的一种积分方法，那么这篇文章就来搬运一下这种
      
    
    </summary>
    
    
      <category term="知识点与小技巧" scheme="https://gsy00517.github.io/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%8E%E5%B0%8F%E6%8A%80%E5%B7%A7/"/>
    
    
      <category term="微积分" scheme="https://gsy00517.github.io/tags/%E5%BE%AE%E7%A7%AF%E5%88%86/"/>
    
  </entry>
  
  <entry>
    <title>game笔记：海贼王燃烧之血键盘操作</title>
    <link href="https://gsy00517.github.io/game20191007172952/"/>
    <id>https://gsy00517.github.io/game20191007172952/</id>
    <published>2019-10-07T09:29:52.000Z</published>
    <updated>2019-11-02T02:21:59.773Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>这是一篇关于海贼王也关于游戏的文章，出于对海贼王狂热的喜爱，我决定还是在博客里添一篇这样的文章，感兴趣可以看看。</p><hr><h1 id="画展"><a href="#画展" class="headerlink" title="画展"></a>画展</h1><p>国庆期间，我留在了武汉。幸运的是，海贼王官方在大陆的首次巡展“路飞来了”正好此时也在武汉开展。作为一名海贼铁粉，我当然是毫不犹豫地买了票。其实根据我博客网站的icon以及我目前的个人头像，应该很容易看出我对海贼王的热爱哈哈。<br><img src="/game20191007172952/看展.JPG" title="看展"><br>去的时候快接近饭点了，人还是不少，都是真爱啊~不过像我这样我单身一人的占比不大，但也有。让我惊讶的是当我看着日文的原稿是竟能直接反应出中文，果然那么多年来全套漫画没白买。期间跟一位貌似是艺术生的小哥聊得挺开的，只可惜最后没留联系方式，有缘再见吧。<br>整个展看下来还是挺震撼的，尤其是刚进去的时候，激动地鸡皮疙瘩都起来了。不过跟我在东京塔下面的海贼王主题乐园激动得哭出来还是有一定差距的。看完展之后我买了几张原稿的复刻版，花了不少钱，但觉得挺值，珍藏了。我是一个漫画党，除了剧场版或特别篇之外我看的都是漫画（不过是通过动画入坑的，星空卫视司法岛，一代人的记忆哈哈）。说实话，尾田构思之精巧，漫画史上无人能及，感兴趣可以看看知乎上关于尾田构思的讨论，漫画真的埋了很多神一般的线索，这是动画里办不到的，细细看很有意思。<br><img src="/game20191007172952/哈哈哈路飞.JPG" title="哈哈哈路飞"></p><hr><h1 id="燃烧之血"><a href="#燃烧之血" class="headerlink" title="燃烧之血"></a>燃烧之血</h1><p>看完展，我心中对于海贼王的热血再一次得到激发，回学校就打开燃烧之血，回到海贼世界过把瘾。<br>海贼王燃烧之血（One Piece：Burning Blood）是16年发行的一款海贼王题材的格斗游戏，个人觉得其中的自然系元素化以及霸气设定真的太棒了！另外各种招式都还原得很全很细致，简直就是一边玩一边享受精彩的画面。文末提供了一些图，可以欣赏一下，真的很赞。<br>由于steam版价格原因（加上全部DLC需两三百rmb）以及原本这游戏好像是在游戏机上的（PC版是移植的），导致PC键盘操作方式的教程不是很全，因此本篇文章主要就是对该款游戏的按键操作做一个补充。</p><hr><h1 id="按键操作"><a href="#按键操作" class="headerlink" title="按键操作"></a>按键操作</h1><p>十几个小时玩下来，基本的按键摸得比较熟了，其实键盘操作也有键盘的优势，熟练就好。<br>首先是很普适的移动方式：<br>前进 W<br>后退 S<br>左行 A<br>右行 D<br>下面是一些基本的战斗操作：<br>攻击 K<br>重击 O<br>跳跃 L<br>防御 ；（分号键）<br>往后换人 E<br>往前换人 I<br>突破极限状态 右ctrl<br>必杀技（突破极限状态下） 右ctrl<br>如果要使用招式，那么按下Q，在战斗界面的左侧就会出现招式列表，即三个招式的名称及按键操作，按住Q不松，再配合对应按键，就可以使出对应的招式。<br>招式一 （招式列表情况下） K<br>招式二 （招式列表情况下） O<br>招式三 （招式列表情况下） ；<br>一般情况下，长按对应键不松可以延迟招式的释放时间（比如在对手倒地时可以尝试）。此外，一些招式延迟附带蓄力效果，可以打出更强的攻击（附带破防效果）。<br>接下来是一些组合按键的操作：<br>破防 K+L<br>重击破防 O+；<br>侧步闪躲 W、S、A、D+；<br>范围攻击 S+K<br>范围重击 S+O<br>跳跃攻击 L+K<br>跳跃重击 L+O<br>有些角色还拥有特殊的衍生技能，需通过一定的按键组合释放，这里举两个例子，别的可以参考收藏图鉴：<br>艾斯 神火•不知火 L+O<br>白胡子 垂直跳跃攻击 L+O<br>接下来就是非常有特色的能力啦，按住P键就可以开启自然系能力者的元素化，可以轻松躲掉普攻并适时反击。如果有霸气的话，按住P也可开启霸气，在期间进行攻击就可以造成更大伤害，也不用惧怕自然系了。此外，一些角色开启能力时还可以实现特定的能力，作为海贼迷真的感动到哭，下面举几个例子：<br>女帝 快速后闪 P+L<br>黄猿 瞬移 P+L+方向<br>大熊 瞬移 P+L<br>白胡子 双震 P+招式一<br><img src="/game20191007172952/双震.png" title="双震"><br>白胡子的双震是我最喜欢的技能，真的非常有打击感和冲击力，上图截自b站up主的操作教程，我的许多操作都是从那学来的，他在b站和爱奇艺上都有很详细的连招教程，同时配音也很逗，感兴趣的话可以去观摩一下。</p><hr><h1 id="角色特点"><a href="#角色特点" class="headerlink" title="角色特点"></a>角色特点</h1><p>这里补充一些目前我发现的角色的特点，也是只有海贼迷才懂的，可以说这游戏做得真的赞，后续我发现更多的话会继续补充。<br>1.众所周知，路飞无法被女帝石化。<br>2.山治对抗女性角色时，只能对女性示爱，因此只有挨打的份。</p><hr><h1 id="画面欣赏"><a href="#画面欣赏" class="headerlink" title="画面欣赏"></a>画面欣赏</h1><p>静态无声的画面比起动态有声的还是差多了，但依旧不影响其魅力，看着就觉得很兴奋啦~<br><img src="/game20191007172952/弟弟打哥哥了.jpg" title="弟弟打哥哥了"><br><img src="/game20191007172952/嘿嘿打不着.jpg" title="嘿嘿打不着"><br><img src="/game20191007172952/荒浪白线.jpg" title="荒浪白线"><br><img src="/game20191007172952/room.jpg" title="room"><br><img src="/game20191007172952/元素化.jpg" title="元素化"><br><img src="/game20191007172952/橡皮子弹.jpg" title="橡皮子弹"><br><img src="/game20191007172952/沙岚.jpg" title="沙岚"><br><img src="/game20191007172952/老沙.jpg" title="老沙"><br><img src="/game20191007172952/龙爪.jpg" title="龙爪"><br><img src="/game20191007172952/雷鸟.jpg" title="雷鸟"><br><img src="/game20191007172952/防护屏障.jpg" title="防护屏障"><br><img src="/game20191007172952/冲击屏障.jpg" title="冲击屏障"><br><img src="/game20191007172952/火枪.jpg" title="火枪"><br>当然，游戏仅是起娱乐作用，劳逸结合是关键。如果你也热爱海贼王的话，欢迎和我交流！</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;这是一篇关于海贼王也关于游戏的文章，出于对海贼王狂热的喜爱，我决定还是在博客里添一篇这样的文章，感兴趣可以看看。&lt;/p&gt;&lt;hr&gt;&lt;h1 id=&quot;
      
    
    </summary>
    
    
      <category term="游戏" scheme="https://gsy00517.github.io/categories/%E6%B8%B8%E6%88%8F/"/>
    
    
      <category term="海贼王" scheme="https://gsy00517.github.io/tags/%E6%B5%B7%E8%B4%BC%E7%8E%8B/"/>
    
  </entry>
  
  <entry>
    <title>hexo笔记：ssh与https以及双线部署的一些注意点</title>
    <link href="https://gsy00517.github.io/hexo20191006232704/"/>
    <id>https://gsy00517.github.io/hexo20191006232704/</id>
    <published>2019-10-06T15:27:04.000Z</published>
    <updated>2019-11-02T03:18:21.658Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>不久前，我对本博客网站做了一些优化，其中包括将网站同时部署到github和coding上。关于双线部署如何具体操作，网上有许多较为详尽的教程可以参考，如果有问题的话可以参考多篇不同的教程找出原因解决。在这篇文章中，我主要想讲讲我这期间遇到的一些小事项。</p><hr><h1 id="github与coding"><a href="#github与coding" class="headerlink" title="github与coding"></a>github与coding</h1><p>考虑到每次打开博客的加载速度问题，我前几天尝试了把博客部署到coding上，实现了coding+github双线部署。coding现已经被腾讯云收购，可以直接用微信登录。<br>部署完成后，为了看一看效果，我使用了<a href="http://tool.chinaz.com/" target="_blank">站长工具</a>分别对coding和github上的网站速度进行了测试。测试结果如下：<br><img src="/hexo20191006232704/github.png" title="github"><br><img src="/hexo20191006232704/coding.png" title="coding"><br>可见，部署在coding上确实能提高一点速度。不过事实上，在实际使用中，并没有感到coding更快，搜索之后发现似乎是coding的服务器也不在内地而在香港的原因。这里附上我的两个链接，可以看看效果，择优访问：<br>github page：<a href="https://gsy00517.github.io/">https://gsy00517.github.io/</a><br>coding page：<a href="https://gsy00517.coding.me/" target="_blank" rel="noopener">https://gsy00517.coding.me/</a></p><hr><h1 id="ssh与https"><a href="#ssh与https" class="headerlink" title="ssh与https"></a>ssh与https</h1><p>在网上的一个教程中，作者提到使用ssh比https更加稳定，尝试后暂时没有发现明显的区别，但是另一个直观的改变就是在push代码时，使用ssh url就不需要输入账号和密码。下面是我在hexo配置文件中的设置，也就是位于站点根目录下的_config.yml文件，其中后面注释中的<code>https://github.com/Gsy00517/Gsy00517.github.io.git</code>是原本的https url。<br><img src="/hexo20191006232704/使用ssh.png" title="使用ssh"><br>上面对应的ssh url一般可以从平台上直接复制获取，也可以参照我的格式进行设置。<br><img src="/hexo20191006232704/平台提供.png" title="平台提供"><br>这里简要说一说ssh与https的区别。<br>一般默认情况下使用的是https，除了需要在fetch和push时使用密码之外，使用https的配置比较方便。然而，使用ssh url却需要先配置和添加好ssh key，并且你必须是这个项目的拥有或者管理者，而https就没有这些要求。其实，配置ssh key也并没有那么繁琐，而且这是一劳永逸的，所以推荐还是使用ssh。<br>要注意的是，ssh key保存的默认位置或许会不同于网上的教程，不过可以自行更改。我的默认地址是在用户文件夹下的AppData\Roaming\SPB_16.6的ssh文件夹中。AppData文件夹默认是隐藏的，可以通过查看隐藏的项目打开。此外，如果需要经常清理temp文件的话，不妨取消这个文件夹的隐藏，这在释放windows空间中还是挺有效的，可以参见<a href="https://gsy00517.github.io/windows20190914091023/" target="_blank">windows笔记：释放空间</a>。<br><img src="/hexo20191006232704/SSHkey所在.png" title="SSHkey所在"><br>key所在的文件是上图所示的第二个publisher文件，然而似乎无法直接用office打开，选择打开方式为记事本即可。<br>当然，如果实在找不到key所在的文件，也可以直接使用文件资源管理器的搜索功能查找名为<code>.ssh</code>的文件夹即可。</p><blockquote><p>注：http与https的区别在于，http是明文传输的，而https是使用ssl加密的，更加安全。若要将连接提交百度站点验证，就需要使用https协议，这个在github和coding都有强制https访问的选项。</p></blockquote><hr><h1 id="双线部署注意事项"><a href="#双线部署注意事项" class="headerlink" title="双线部署注意事项"></a>双线部署注意事项</h1><ol><li><h2 id="LeanCloud"><a href="#LeanCloud" class="headerlink" title="LeanCloud"></a>LeanCloud</h2>这里主要针对hexo博客双线部署后可能会出现的几个问题说明一下注意点。<br>首先，如果之前使用的是LeanCloud来接受记录评论和统计阅读量的，那么为了共享数据，必须在LeanCloud控制台设置的安全中心中，添加新增的web安全域名，保存后即可解决问题。<img src="/hexo20191006232704/添加域名.png" title="添加域名"></li><li><h2 id="Widget"><a href="#Widget" class="headerlink" title="Widget"></a>Widget</h2>如果使用的是基于Widget的评分系统，那么必须更改Widget设置中的domain。我是免费使用Widget，只能同时添加一个domain。我继续使用github page的域名，因此只能在我的github page中看到评分系统。<img src="/hexo20191006232704/欢迎来评.png" title="欢迎来评"></li><li><h2 id="文内链接"><a href="#文内链接" class="headerlink" title="文内链接"></a>文内链接</h2>因为双线部署用的依旧还是同一份本地源码文件，因此在博文中提供的链接依旧是一致的。这里我也将继续使用github page的链接，也就是文内推荐的我本人的博文链接依旧还是指向github page的。事实上，这并无任何影响。</li></ol><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;不久前，我对本博客网站做了一些优化，其中包括将网站同时部署到github和coding上。关于双线部署如何具体操作，网上有许多较为详尽的教程可以
      
    
    </summary>
    
    
      <category term="操作与使用" scheme="https://gsy00517.github.io/categories/%E6%93%8D%E4%BD%9C%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="hexo" scheme="https://gsy00517.github.io/tags/hexo/"/>
    
      <category term="配置优化" scheme="https://gsy00517.github.io/tags/%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>deep learning笔记：使网络能够更深——ResNet简介与pytorch实现</title>
    <link href="https://gsy00517.github.io/deep-learning20191001184216/"/>
    <id>https://gsy00517.github.io/deep-learning20191001184216/</id>
    <published>2019-10-01T10:42:16.000Z</published>
    <updated>2019-11-02T02:21:37.312Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>之前我用pytorch把ResNet18实现了一下，但由于上周准备国家奖学金答辩没有时间来写我实现的过程与总结。今天是祖国70周年华诞，借着这股喜庆劲，把这篇文章补上。</p><p>本文参考自：<a href="https://blog.csdn.net/weixin_43624538/article/details/85049699" target="_blank" rel="noopener">https://blog.csdn.net/weixin_43624538/article/details/85049699</a><br><a href="https://blog.csdn.net/u013289254/article/details/98785869" target="_blank" rel="noopener">https://blog.csdn.net/u013289254/article/details/98785869</a></p><hr><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>ResNet残差网络是由何凯明等四名微软研究院的华人提出的，当初看到论文标题下面的中国名字还是挺高兴的。文章引入部分，作者就探讨了深度神经网络的优化是否就只是叠加层数、增加深度那么简单。显然这是不可能的，增加深度带来的首要问题就是梯度爆炸、消散的问题，这是由于随着层数的增多，在网络中反向传播的梯度会随着连乘变得不稳定，从而变得特别大或者特别小。其中以梯度消散更为常见。值得注意的是，论文中还提到深度更深的网络反而出现准确率下降并不是由过拟合所引起的。<br>为了解决这个问题，研究者们做出了很多思考与尝试，其中的代表有relu激活函数的使用，Batch Normalization的使用等。关于这两种方法，可以参考网上的资料以及我的博文<a href="https://gsy00517.github.io/deep-learning20190915113859/" target="_blank">deep-learning笔记：开启深度学习热潮——AlexNet</a>和<a href="https://gsy00517.github.io/deep-learning20191001151454/" target="_blank">deep-learning笔记：学习率衰减与批归一化</a>。<br>对于上面这个问题，ResNet作出的贡献是引入skip/identity connection。如下所示就是两个基本的残差模块。<br><img src="/deep-learning20191001184216/基本残差模块.png" title="基本残差模块"><br>上面这个block可表示为：$ F(X)=H(X)-x $。在这里，X为浅层输出，H(x)为深层的输出。当浅层的X代表的特征已经足够成熟，即当任何对于特征X的改变都会让loss变大时，F(X)会自动趋向于学习成为0，X则从恒等映射的路径继续传递。<br>这样，我们就可以在不增加计算成本的情况下使得在前向传递过程中，如果浅层的输出已经足够成熟（optimal），那么就让深层网络后面的层仅实现恒等映射的作用。<br>当X与F（X）通道数目不同时，作者尝试了两种identity mapping的方式。一种即对X缺失的通道直接补零从而使其能够对齐，这种方式比较简单直接，无需额外的参数；另一种则是通过使用1x1的conv来映射从而使通道也能达成一致。</p><hr><h1 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h1><p>老规矩，这里还是先呈上我用黄色荧光高亮出我认为比较重要的要点的论文原文，这里我只有<a href="1512.03385.pdf" target="_blank">英文版</a>。<br>如果需要没有被我标注过的原文，可以直接搜索，这里我仅提供一次，可以<a href="https://arxiv.org/abs/1512.03385" target="_blank">点击这里</a>下载。<br>不过，虽然没有pdf中文版，但其实深度学习CV方向一些比较经典的论文的英文、中文、中英对照都可以到<a href="https://github.com/SnailTyan/deep-learning-papers-translation" target="_blank">Deep Learning Papers Translation</a>上看到，非常方便。</p><hr><h1 id="自己实现"><a href="#自己实现" class="headerlink" title="自己实现"></a>自己实现</h1><p>在论文中，作者提到了如下几个ResNet的版本的结构。<br><img src="/deep-learning20191001184216/各版本ResNet.png" title="各版本ResNet"><br>这里我实现的是ResNet18。<br>由于这不是我第一次使用pytorch进行实现，一些基本的使用操作我就不加注释了，想看注释来理解的话可以参考我之前VGG的实现。<br>由于残差的引入，导致ResNet的结构比较复杂，而论文中并没有非常详细的阐述，在研究官方源码之后，我对它的结构才有了完整的了解，这里我画出来以便参考。<br><img src="/deep-learning20191001184216/基本结构.JPG" title="基本结构"><br>ResNet18的每一layer包括了两个这样的basic block，其中1x1的卷积核仅在X与F（X）通道数目不一致时进行操作，在我的代码中，我定义shortcut函数来对应一切通道一致、无需处理的情况。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(ResNet, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels = <span class="number">3</span>, out_channels = <span class="number">64</span>, kernel_size = <span class="number">7</span>, stride = <span class="number">2</span>, padding = <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.max = nn.MaxPool2d(kernel_size = <span class="number">3</span>, stride = <span class="number">2</span>, padding = <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(<span class="number">128</span>)</span><br><span class="line">        self.bn4 = nn.BatchNorm2d(<span class="number">256</span>)</span><br><span class="line">        self.bn5 = nn.BatchNorm2d(<span class="number">512</span>)</span><br><span class="line">        </span><br><span class="line">        self.shortcut = nn.Sequential()</span><br><span class="line">        self.shortcut3 = nn.Sequential(nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size = <span class="number">1</span>, stride = <span class="number">2</span>, bias = <span class="literal">False</span>), nn.BatchNorm2d(<span class="number">128</span>)) </span><br><span class="line">        self.shortcut4 = nn.Sequential(nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size = <span class="number">1</span>, stride = <span class="number">2</span>, bias = <span class="literal">False</span>), nn.BatchNorm2d(<span class="number">256</span>))</span><br><span class="line">        self.shortcut5 = nn.Sequential(nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size = <span class="number">1</span>, stride = <span class="number">2</span>, bias = <span class="literal">False</span>), nn.BatchNorm2d(<span class="number">512</span>))</span><br><span class="line">        </span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels = <span class="number">64</span>, out_channels = <span class="number">64</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">1</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv3_1 = nn.Conv2d(in_channels = <span class="number">64</span>, out_channels = <span class="number">128</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">2</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        self.conv3_2 = nn.Conv2d(in_channels = <span class="number">128</span>, out_channels = <span class="number">128</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">1</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv4_1 = nn.Conv2d(in_channels = <span class="number">128</span>, out_channels = <span class="number">256</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">2</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        self.conv4_2 = nn.Conv2d(in_channels = <span class="number">256</span>, out_channels = <span class="number">256</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">1</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv5_1 = nn.Conv2d(in_channels = <span class="number">256</span>, out_channels = <span class="number">512</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">2</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        self.conv5_2 = nn.Conv2d(in_channels = <span class="number">512</span>, out_channels = <span class="number">512</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">1</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        self.avg = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        self.fc = nn.Linear(<span class="number">512</span>, <span class="number">1000</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        x1 = self.max(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#layer1</span></span><br><span class="line">        x = F.relu(self.bn2(self.conv2(x1)))</span><br><span class="line">        x = self.bn2(self.conv2(x))</span><br><span class="line">        x += self.shortcut(x1)</span><br><span class="line">        x2 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.bn2(self.conv2(x2)))</span><br><span class="line">        x = self.bn2(self.conv2(x))</span><br><span class="line">        x += self.shortcut(x2)</span><br><span class="line">        x3 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#layer2</span></span><br><span class="line">        x = F.relu(self.bn3(self.conv3_1(x3)))</span><br><span class="line">        x = self.bn3(self.conv3_2(x))</span><br><span class="line">        x += self.shortcut3(x3)</span><br><span class="line">        x4 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.bn3(self.conv3_2(x4)))</span><br><span class="line">        x = self.bn3(self.conv3_2(x))</span><br><span class="line">        x += self.shortcut(x4)</span><br><span class="line">        x5 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#layer3</span></span><br><span class="line">        x = F.relu(self.bn4(self.conv4_1(x5)))</span><br><span class="line">        x = self.bn4(self.conv4_2(x))</span><br><span class="line">        x += self.shortcut4(x5)</span><br><span class="line">        x6 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.bn4(self.conv4_2(x6)))</span><br><span class="line">        x = self.bn4(self.conv4_2(x))</span><br><span class="line">        x += self.shortcut(x6)</span><br><span class="line">        x7 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#layer4</span></span><br><span class="line">        x = F.relu(self.bn5(self.conv5_1(x7)))</span><br><span class="line">        x = self.bn5(self.conv5_2(x))</span><br><span class="line">        x += self.shortcut5(x7)</span><br><span class="line">        x8 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.bn5(self.conv5_2(x8)))</span><br><span class="line">        x = self.bn5(self.conv5_2(x))</span><br><span class="line">        x += self.shortcut(x8)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#ending</span></span><br><span class="line">        x = self.avg(x)</span><br><span class="line">        </span><br><span class="line">        x = x.view(<span class="number">-1</span>, self.num_flat_features(x))</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        </span><br><span class="line">        x = F.softmax(x, dim = <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:]</span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line">        </span><br><span class="line">net = ResNet()</span><br></pre></td></tr></table></figure><p></p><p>同样的，我们可以随机生成一个张量来进行验证：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">input = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">48</span>, <span class="number">48</span>)</span><br><span class="line">out = net(input)</span><br><span class="line">print(out)</span><br></pre></td></tr></table></figure><p></p><p>如果可以顺利地输出，那么模型基本上是没有问题的。</p><hr><h1 id="出现的问题"><a href="#出现的问题" class="headerlink" title="出现的问题"></a>出现的问题</h1><p>在这里我还是想把自己踩的一些简单的坑记下来，引以为戒。</p><ol><li><h2 id="softmax输出全为1"><a href="#softmax输出全为1" class="headerlink" title="softmax输出全为1"></a>softmax输出全为1</h2><p>当我使用F.softmax之后，出现了这样的一个问题：</p><img src="/deep-learning20191001184216/输出全为1.png" title="输出全为1"><p>查找资料后发现，我错误的把对每一行softmax当作了对每一列softmax。因为这个softmax语句是我从之前的自己做的一道kaggle题目写的代码中ctrl+C+V过来的，复制过来的是<code>x = F.softmax(x, dim = 0)</code>，在这里，dim = 0意味着我对张量的每一列进行softmax，这是因为我之前的场景中需要处理的张量是一维的，也就是tensor（）里面只有一对“[]”，此时它默认只有一列，我对列进行softmax自然就没有问题。<br>而放到这里，我再对列进行softmax时，每列上就只有一个元素。那么结果就都是1即100%了。解决的方法就是把dim设为1。<br>下面我在用一组代码直观地展示一下softmax的用法与区别。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">x1= torch.Tensor( [ [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">y11= F.softmax(x1, dim = <span class="number">0</span>) <span class="comment">#对每一列进行softmax</span></span><br><span class="line">y12 = F.softmax(x1, dim = <span class="number">1</span>) <span class="comment">#对每一行进行softmax</span></span><br><span class="line">x2 = torch.Tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">y2 = F.softmax(x2, dim = <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>我们输出每个结果，可以看到：</p><img src="/deep-learning20191001184216/结果.png" title="结果"></li><li><h2 id="bias"><a href="#bias" class="headerlink" title="bias"></a>bias</h2>或许你可以发现，在我的代码中，每个卷积层中都设置了<code>bias = False</code>，这是我在参考官方源码之后补上的。那么，这个bias是什么，又有什么用呢？<br>我们在学深度学习的时候，最早接触到的神经网络应该是感知器，它的结构如下图所示。 <img src="/deep-learning20191001184216/感知器.jpg" title="感知器"> 要想激活这个感知器，就必须使<code>x1 * w1 + x2 * w2 + ... + xn * wn &gt; T</code>（T为一个阈值），而T越大，想激活这个感知器的难度越大。<br>考虑样本较多的情况，我不可能手动选择一个阈值，使得模型整体表现最佳，因此我们不如使得T变成可学习的，这样一来，T会自动学习到一个数，使得模型的整体表现最佳。当把T移动到左边，它就成了bias偏置，<code>x1 * w1 + x2 * w2 + ... + xn * wn - T &gt; 0</code>。显然，偏置的大小控制着激活这个感知器的难易程度。<br>在比感知器高级的神经网络中，也是如此。<br>但倘若我们要在卷积后面加上归一化操作，那么bias的作用就无法体现了。<br>我们以ResNet卷积层后的BN层为例。<br>可参考我的上一篇博文，BN处理过程中有这样一步： <img src="/deep-learning20191001184216/归一化.png" title="归一化"> 对于分子而言，无论有没有bias，对结果都没有影响；而对于下面分母而言，因为是方差操作，所以也没有影响。因此，在ResNet中，因为每次卷积之后都要进行BN操作，那就不需要启用bias，否则非但不起作用，还会消耗一定的显卡内存。</li></ol><hr><h1 id="官方源码"><a href="#官方源码" class="headerlink" title="官方源码"></a>官方源码</h1><p>如果你此时对ResNet的结构已经有了比较清晰的理解，那么可以尝试着来理解一下官方源码的思路。其实我觉得先看像我这样直观的代码实现再看官方源码更有助理解且更高效。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> .utils <span class="keyword">import</span> load_state_dict_from_url</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">__all__ = [<span class="string">'ResNet'</span>, <span class="string">'resnet18'</span>, <span class="string">'resnet34'</span>, <span class="string">'resnet50'</span>, <span class="string">'resnet101'</span>,</span><br><span class="line">           <span class="string">'resnet152'</span>, <span class="string">'resnext50_32x4d'</span>, <span class="string">'resnext101_32x8d'</span>,</span><br><span class="line">           <span class="string">'wide_resnet50_2'</span>, <span class="string">'wide_resnet101_2'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_urls = &#123;</span><br><span class="line">    <span class="string">'resnet18'</span>: <span class="string">'https://download.pytorch.org/models/resnet18-5c106cde.pth'</span>,</span><br><span class="line">    <span class="string">'resnet34'</span>: <span class="string">'https://download.pytorch.org/models/resnet34-333f7ec4.pth'</span>,</span><br><span class="line">    <span class="string">'resnet50'</span>: <span class="string">'https://download.pytorch.org/models/resnet50-19c8e357.pth'</span>,</span><br><span class="line">    <span class="string">'resnet101'</span>: <span class="string">'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'</span>,</span><br><span class="line">    <span class="string">'resnet152'</span>: <span class="string">'https://download.pytorch.org/models/resnet152-b121ed2d.pth'</span>,</span><br><span class="line">    <span class="string">'resnext50_32x4d'</span>: <span class="string">'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth'</span>,</span><br><span class="line">    <span class="string">'resnext101_32x8d'</span>: <span class="string">'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth'</span>,</span><br><span class="line">    <span class="string">'wide_resnet50_2'</span>: <span class="string">'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth'</span>,</span><br><span class="line">    <span class="string">'wide_resnet101_2'</span>: <span class="string">'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth'</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv3x3</span><span class="params">(in_planes, out_planes, stride=<span class="number">1</span>, groups=<span class="number">1</span>, dilation=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""3x3 convolution with padding"""</span></span><br><span class="line">    <span class="keyword">return</span> nn.Conv2d(in_planes, out_planes, kernel_size=<span class="number">3</span>, stride=stride,</span><br><span class="line">                     padding=dilation, groups=groups, bias=<span class="literal">False</span>, dilation=dilation)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv1x1</span><span class="params">(in_planes, out_planes, stride=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""1x1 convolution"""</span></span><br><span class="line">    <span class="keyword">return</span> nn.Conv2d(in_planes, out_planes, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicBlock</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line">    __constants__ = [<span class="string">'downsample'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inplanes, planes, stride=<span class="number">1</span>, downsample=None, groups=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 base_width=<span class="number">64</span>, dilation=<span class="number">1</span>, norm_layer=None)</span>:</span></span><br><span class="line">        super(BasicBlock, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm2d</span><br><span class="line">        <span class="keyword">if</span> groups != <span class="number">1</span> <span class="keyword">or</span> base_width != <span class="number">64</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'BasicBlock only supports groups=1 and base_width=64'</span>)</span><br><span class="line">        <span class="keyword">if</span> dilation &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError(<span class="string">"Dilation &gt; 1 not supported in BasicBlock"</span>)</span><br><span class="line">        <span class="comment"># Both self.conv1 and self.downsample layers downsample the input when stride != 1</span></span><br><span class="line">        self.conv1 = conv3x3(inplanes, planes, stride)</span><br><span class="line">        self.bn1 = norm_layer(planes)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(planes, planes)</span><br><span class="line">        self.bn2 = norm_layer(planes)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        identity = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bottleneck</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inplanes, planes, stride=<span class="number">1</span>, downsample=None, groups=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 base_width=<span class="number">64</span>, dilation=<span class="number">1</span>, norm_layer=None)</span>:</span></span><br><span class="line">        super(Bottleneck, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm2d</span><br><span class="line">        width = int(planes * (base_width / <span class="number">64.</span>)) * groups</span><br><span class="line">        <span class="comment"># Both self.conv2 and self.downsample layers downsample the input when stride != 1</span></span><br><span class="line">        self.conv1 = conv1x1(inplanes, width)</span><br><span class="line">        self.bn1 = norm_layer(width)</span><br><span class="line">        self.conv2 = conv3x3(width, width, stride, groups, dilation)</span><br><span class="line">        self.bn2 = norm_layer(width)</span><br><span class="line">        self.conv3 = conv1x1(width, planes * self.expansion)</span><br><span class="line">        self.bn3 = norm_layer(planes * self.expansion)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        identity = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, block, layers, num_classes=<span class="number">1000</span>, zero_init_residual=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                 groups=<span class="number">1</span>, width_per_group=<span class="number">64</span>, replace_stride_with_dilation=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 norm_layer=None)</span>:</span></span><br><span class="line">        super(ResNet, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm2d</span><br><span class="line">        self._norm_layer = norm_layer</span><br><span class="line"></span><br><span class="line">        self.inplanes = <span class="number">64</span></span><br><span class="line">        self.dilation = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> replace_stride_with_dilation <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># each element in the tuple indicates if we should replace</span></span><br><span class="line">            <span class="comment"># the 2x2 stride with a dilated convolution instead</span></span><br><span class="line">            replace_stride_with_dilation = [<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>]</span><br><span class="line">        <span class="keyword">if</span> len(replace_stride_with_dilation) != <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"replace_stride_with_dilation should be None "</span></span><br><span class="line">                             <span class="string">"or a 3-element tuple, got &#123;&#125;"</span>.format(replace_stride_with_dilation))</span><br><span class="line">        self.groups = groups</span><br><span class="line">        self.base_width = width_per_group</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, self.inplanes, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>,</span><br><span class="line">                               bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = norm_layer(self.inplanes)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.layer1 = self._make_layer(block, <span class="number">64</span>, layers[<span class="number">0</span>])</span><br><span class="line">        self.layer2 = self._make_layer(block, <span class="number">128</span>, layers[<span class="number">1</span>], stride=<span class="number">2</span>,</span><br><span class="line">                                       dilate=replace_stride_with_dilation[<span class="number">0</span>])</span><br><span class="line">        self.layer3 = self._make_layer(block, <span class="number">256</span>, layers[<span class="number">2</span>], stride=<span class="number">2</span>,</span><br><span class="line">                                       dilate=replace_stride_with_dilation[<span class="number">1</span>])</span><br><span class="line">        self.layer4 = self._make_layer(block, <span class="number">512</span>, layers[<span class="number">3</span>], stride=<span class="number">2</span>,</span><br><span class="line">                                       dilate=replace_stride_with_dilation[<span class="number">2</span>])</span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.fc = nn.Linear(<span class="number">512</span> * block.expansion, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> isinstance(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">'fan_out'</span>, nonlinearity=<span class="string">'relu'</span>)</span><br><span class="line">            <span class="keyword">elif</span> isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):</span><br><span class="line">                nn.init.constant_(m.weight, <span class="number">1</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Zero-initialize the last BN in each residual branch,</span></span><br><span class="line">        <span class="comment"># so that the residual branch starts with zeros, and each residual block behaves like an identity.</span></span><br><span class="line">        <span class="comment"># This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677</span></span><br><span class="line">        <span class="keyword">if</span> zero_init_residual:</span><br><span class="line">            <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">                <span class="keyword">if</span> isinstance(m, Bottleneck):</span><br><span class="line">                    nn.init.constant_(m.bn3.weight, <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">elif</span> isinstance(m, BasicBlock):</span><br><span class="line">                    nn.init.constant_(m.bn2.weight, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_layer</span><span class="params">(self, block, planes, blocks, stride=<span class="number">1</span>, dilate=False)</span>:</span></span><br><span class="line">        norm_layer = self._norm_layer</span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line">        previous_dilation = self.dilation</span><br><span class="line">        <span class="keyword">if</span> dilate:</span><br><span class="line">            self.dilation *= stride</span><br><span class="line">            stride = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.inplanes != planes * block.expansion:</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                conv1x1(self.inplanes, planes * block.expansion, stride),</span><br><span class="line">                norm_layer(planes * block.expansion),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,</span><br><span class="line">                            self.base_width, previous_dilation, norm_layer))</span><br><span class="line">        self.inplanes = planes * block.expansion</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1</span>, blocks):</span><br><span class="line">            layers.append(block(self.inplanes, planes, groups=self.groups,</span><br><span class="line">                                base_width=self.base_width, dilation=self.dilation,</span><br><span class="line">                                norm_layer=norm_layer))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.maxpool(x)</span><br><span class="line"></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        x = self.layer4(x)</span><br><span class="line"></span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_resnet</span><span class="params">(arch, block, layers, pretrained, progress, **kwargs)</span>:</span></span><br><span class="line">    model = ResNet(block, layers, **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        state_dict = load_state_dict_from_url(model_urls[arch],</span><br><span class="line">                                              progress=progress)</span><br><span class="line">        model.load_state_dict(state_dict)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet18</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNet-18 model from</span></span><br><span class="line"><span class="string">    `"Deep Residual Learning for Image Recognition" &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnet18'</span>, BasicBlock, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], pretrained, progress,</span><br><span class="line">                   **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet34</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNet-34 model from</span></span><br><span class="line"><span class="string">    `"Deep Residual Learning for Image Recognition" &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnet34'</span>, BasicBlock, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], pretrained, progress,</span><br><span class="line">                   **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet50</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNet-50 model from</span></span><br><span class="line"><span class="string">    `"Deep Residual Learning for Image Recognition" &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnet50'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], pretrained, progress,</span><br><span class="line">                   **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet101</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNet-101 model from</span></span><br><span class="line"><span class="string">    `"Deep Residual Learning for Image Recognition" &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnet101'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>], pretrained, progress,</span><br><span class="line">                   **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet152</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNet-152 model from</span></span><br><span class="line"><span class="string">    `"Deep Residual Learning for Image Recognition" &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnet152'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">8</span>, <span class="number">36</span>, <span class="number">3</span>], pretrained, progress,</span><br><span class="line">                   **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnext50_32x4d</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNeXt-50 32x4d model from</span></span><br><span class="line"><span class="string">    `"Aggregated Residual Transformation for Deep Neural Networks" &lt;https://arxiv.org/pdf/1611.05431.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    kwargs[<span class="string">'groups'</span>] = <span class="number">32</span></span><br><span class="line">    kwargs[<span class="string">'width_per_group'</span>] = <span class="number">4</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnext50_32x4d'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>],</span><br><span class="line">                   pretrained, progress, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnext101_32x8d</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNeXt-101 32x8d model from</span></span><br><span class="line"><span class="string">    `"Aggregated Residual Transformation for Deep Neural Networks" &lt;https://arxiv.org/pdf/1611.05431.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    kwargs[<span class="string">'groups'</span>] = <span class="number">32</span></span><br><span class="line">    kwargs[<span class="string">'width_per_group'</span>] = <span class="number">8</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnext101_32x8d'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>],</span><br><span class="line">                   pretrained, progress, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wide_resnet50_2</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""Wide ResNet-50-2 model from</span></span><br><span class="line"><span class="string">    `"Wide Residual Networks" &lt;https://arxiv.org/pdf/1605.07146.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The model is the same as ResNet except for the bottleneck number of channels</span></span><br><span class="line"><span class="string">    which is twice larger in every block. The number of channels in outer 1x1</span></span><br><span class="line"><span class="string">    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048</span></span><br><span class="line"><span class="string">    channels, and in Wide ResNet-50-2 has 2048-1024-2048.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    kwargs[<span class="string">'width_per_group'</span>] = <span class="number">64</span> * <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'wide_resnet50_2'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>],</span><br><span class="line">                   pretrained, progress, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wide_resnet101_2</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""Wide ResNet-101-2 model from</span></span><br><span class="line"><span class="string">    `"Wide Residual Networks" &lt;https://arxiv.org/pdf/1605.07146.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The model is the same as ResNet except for the bottleneck number of channels</span></span><br><span class="line"><span class="string">    which is twice larger in every block. The number of channels in outer 1x1</span></span><br><span class="line"><span class="string">    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048</span></span><br><span class="line"><span class="string">    channels, and in Wide ResNet-50-2 has 2048-1024-2048.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    kwargs[<span class="string">'width_per_group'</span>] = <span class="number">64</span> * <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'wide_resnet101_2'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>],</span><br><span class="line">                   pretrained, progress, **kwargs)</span><br></pre></td></tr></table></figure><p></p><hr><h1 id="pth文件"><a href="#pth文件" class="headerlink" title="pth文件"></a>pth文件</h1><p>在阅读官方源码时，我们会注意到官方提供了一系列版本的model_urls，其中，每一个url都是以.pth结尾的。<br>当我下载了对应的文件之后，并不知道如何处理，于是我通过搜索，简单的了解了pth文件的概念与使用方法。<br>简单来说，pth文件就是一个表示Python的模块搜索路径（module search path）的文本文件，在xxx.pth文件里面，会书写一些路径，一行一个。如果我们将xxx.pth文件放在特定位置，则可以让python在加载模块时，读取xxx.pth中指定的路径。<br>下面我使用pytorch对pth文件进行加载操作。<br>首先，我把<a href="https://download.pytorch.org/models/resnet18-5c106cde.pth" target="_blank">ResNet18对应的pth文件</a>下载到桌面。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line"><span class="comment"># pretrained = True就可以使用预训练的模型</span></span><br><span class="line">net = models.resnet18(pretrained = <span class="literal">False</span>)</span><br><span class="line"><span class="comment">#注意，根据model的不同，这里models.xxx的内容也是不同的，比如models.squeezenet1_1</span></span><br><span class="line"></span><br><span class="line">pthfile = <span class="string">r'C:\Users\sheny\Desktop\resnet18-5c106cde.pth'</span><span class="comment">#pth文件所在路径</span></span><br><span class="line">net.load_state_dict(torch.load(pthfile))</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure><p></p><p>输出结果如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">ResNet(</span><br><span class="line">  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)</span><br><span class="line">  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">  (relu): ReLU(inplace=True)</span><br><span class="line">  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">  (layer1): Sequential(</span><br><span class="line">    (0): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    )</span><br><span class="line">    (1): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer2): Sequential(</span><br><span class="line">    (0): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)</span><br><span class="line">        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer3): Sequential(</span><br><span class="line">    (0): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)</span><br><span class="line">        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer4): Sequential(</span><br><span class="line">    (0): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)</span><br><span class="line">        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))</span><br><span class="line">  (fc): Linear(in_features=512, out_features=1000, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p></p><p>这样你就可以看到很详尽的参数设置了。<br>我们还可以加载所有的参数。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">pthfile = <span class="string">r'C:\Users\sheny\Desktop\resnet18-5c106cde.pth'</span></span><br><span class="line"></span><br><span class="line">net = torch.load(pthfile)</span><br><span class="line"></span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure><p></p><p>输出如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">OrderedDict([(&apos;conv1.weight&apos;, Parameter containing:</span><br><span class="line">tensor([[[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  ...,  5.6615e-02,</span><br><span class="line">            1.7083e-02, -1.2694e-02],</span><br><span class="line">          [ 1.1083e-02,  9.5276e-03, -1.0993e-01,  ..., -2.7124e-01,</span><br><span class="line">           -1.2907e-01,  3.7424e-03],</span><br><span class="line">          [-6.9434e-03,  5.9089e-02,  2.9548e-01,  ...,  5.1972e-01,</span><br><span class="line">            2.5632e-01,  6.3573e-02],</span><br><span class="line">          ...,</span><br></pre></td></tr></table></figure><p></p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;之前我用pytorch把ResNet18实现了一下，但由于上周准备国家奖学金答辩没有时间来写我实现的过程与总结。今天是祖国70周年华诞，借着这股
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://gsy00517.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="深度学习" scheme="https://gsy00517.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文分享" scheme="https://gsy00517.github.io/tags/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
      <category term="代码实现" scheme="https://gsy00517.github.io/tags/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    
      <category term="pytorch" scheme="https://gsy00517.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>deep learning笔记：学习率衰减与批归一化</title>
    <link href="https://gsy00517.github.io/deep-learning20191001151454/"/>
    <id>https://gsy00517.github.io/deep-learning20191001151454/</id>
    <published>2019-10-01T07:14:54.000Z</published>
    <updated>2019-11-02T02:21:42.488Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>一段时间之前，在一个深度学习交流群里看到一个群友发问：为什么他的训练误差最后疯狂上下抖动而不是一直降低。<br><img src="/deep-learning20191001151454/群友疑惑.PNG" title="群友疑惑"><br>作为一个入门小白，我当时也很疑惑。但后来我结合所学，仔细思考之后，发现这是一个挺容易犯的错误。</p><p>本文参考自：<a href="https://blog.csdn.net/bestrivern/article/details/86301619" target="_blank" rel="noopener">https://blog.csdn.net/bestrivern/article/details/86301619</a><br><a href="https://www.jianshu.com/p/9643cba47655" target="_blank" rel="noopener">https://www.jianshu.com/p/9643cba47655</a><br><a href="https://www.cnblogs.com/eilearn/p/9780696.html" target="_blank" rel="noopener">https://www.cnblogs.com/eilearn/p/9780696.html</a><br><a href="https://blog.csdn.net/donkey_1993/article/details/81871132" target="_blank" rel="noopener">https://blog.csdn.net/donkey_1993/article/details/81871132</a></p><hr><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>事实上，这是一个在机器学习中就有可能遇到的问题，当学习速率α设置得过大时，往往在模型训练的后期难以达到最优解，而是在最优解附近来回抖动。还有可能反而使损失函数越来越大，甚至达到无穷，如下图所示。<br><img src="/deep-learning20191001151454/损失函数.png" title="损失函数"><br>而在深度学习中，假设我们使用mini-batch梯度下降法，由于mini-batch的数量不大，大概64或者128个样本，在迭代过程中会有噪声。这个时候使用固定的学习率导致的结果就是虽然下降朝向最小值，但不会精确地收敛，只会在附近不断地波动（蓝色线）。<br><img src="/deep-learning20191001151454/不会真正收敛.png" title="不会真正收敛"><br>但如果慢慢减少学习率，在初期，学习还是相对较快地，但随着学习率的变小，步伐也会变慢变小，所以最后当开始收敛时，你的曲线（绿色线）会在最小值附近的一个较小区域之内摆动，而不是在训练过程中，大幅度地在最小值附近摆动。<br><img src="/deep-learning20191001151454/大幅度波动变小范围摆动.png" title="大幅度波动变小范围摆动"><br>对于这个问题，我目前收集了有下面这些解决办法。</p><hr><h1 id="直接修改学习率"><a href="#直接修改学习率" class="headerlink" title="直接修改学习率"></a>直接修改学习率</h1><p>在吴恩达的机器学习课程中，他介绍了一种人为选择学习率的规则：每三倍选择一个学习率。<br>比如：我们首先选择了0.1为学习率，那么当这个学习率过大时，我们修改成0.3。倘若还是偏大，我们继续改为0.01、0.003、0.001…以此类推，当学习率偏小是也是以三倍增加并尝试检验，最终选出比较合适的学习率。<br>但这种方法只适用于模型数量小的情况，且这种方法终究还是固定的学习率，依旧无法很好地权衡从而达到前期快速下降与后期稳定收敛的目的。</p><hr><h1 id="学习率动态衰减"><a href="#学习率动态衰减" class="headerlink" title="学习率动态衰减"></a>学习率动态衰减</h1><p>学习率衰减的本质在于，在学习初期，你能承受并且需要较大的步伐，但当开始收敛的时候，小一些的学习率能让你步伐小一些，从而更稳定地达到精确的最优解。<br>为此，我们另外增添衰减率超参数，构建函数使学习率能够在训练的过程中动态衰减。</p><script type="math/tex;mode=display">\alpha = \frac{1}{1+decayrate*epochnum}*\alpha _{0}\</script><p>其中decay rate称为衰减率，epoch num是代数，$ \alpha _{0} $是初始学习率。<br>此外还有下面这些构造方法：<br>指数衰减：$ \alpha =0.95^{epochnum}*\alpha _{0} $<br>其他常用方法：</p><script type="math/tex;mode=display">\alpha =\frac{k}{\sqrt{epochnum}}*\alpha _{0}\</script><script type="math/tex;mode=display">\alpha =\frac{k}{\sqrt{t}}\alpha _{0}\</script><p>其中k为mini-batch的数字。</p><hr><h1 id="几种衰减方法的实现"><a href="#几种衰减方法的实现" class="headerlink" title="几种衰减方法的实现"></a>几种衰减方法的实现</h1><p>在pytorch中，学习率调整主要有两种方式：<br>1.直接修改optimizer中的lr参数。<br>2.利用lr_scheduler()提供的几种衰减函数。<br>下面提供几种实现方法：<br>准备（对下列通用）：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成一个简单全连接神经网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(net, self).__init__()</span><br><span class="line">        self.fc = nn.Linear(<span class="number">1</span>, <span class="number">10</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.fc(x)</span><br></pre></td></tr></table></figure><p></p><ol><li><h2 id="手动阶梯式衰减"><a href="#手动阶梯式衰减" class="headerlink" title="手动阶梯式衰减"></a>手动阶梯式衰减</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model = net()</span><br><span class="line">LR = <span class="number">0.01</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr = LR)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">5</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">for</span> p <span class="keyword">in</span> optimizer.param_groups:</span><br><span class="line">            p[<span class="string">'lr'</span>] *= <span class="number">0.9</span></span><br></pre></td></tr></table></figure><p>这里是每过5个epoch就进行一次衰减。</p><img src="/deep-learning20191001151454/手动阶梯式衰减.png" title="手动阶梯式衰减"></li><li><h2 id="lambda自定义衰减"><a href="#lambda自定义衰减" class="headerlink" title="lambda自定义衰减"></a>lambda自定义衰减</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np </span><br><span class="line">model = net()</span><br><span class="line">LR = <span class="number">0.01</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr = LR)</span><br><span class="line">lambda1 = <span class="keyword">lambda</span> epoch: np.sin(epoch) / epoch</span><br><span class="line">scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda1)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    scheduler.step()</span><br></pre></td></tr></table></figure><p>lr_lambda会接收到一个int参数：epoch，然后根据epoch计算出对应的lr。如果设置多个lambda函数的话，会分别作用于optimizer中的不同的params_group。</p><img src="/deep-learning20191001151454/lambda自定义衰减.png" title="lambda自定义衰减"></li><li><h2 id="StepLR阶梯式衰减"><a href="#StepLR阶梯式衰减" class="headerlink" title="StepLR阶梯式衰减"></a>StepLR阶梯式衰减</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = net()</span><br><span class="line">LR = <span class="number">0.01</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr = LR)</span><br><span class="line">scheduler = lr_scheduler.StepLR(optimizer, step_size = <span class="number">5</span>, gamma = <span class="number">0.8</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    scheduler.step()</span><br></pre></td></tr></table></figure><p>每个epoch，lr会自动乘以gamma。</p><img src="/deep-learning20191001151454/StepLR阶梯式衰减.png" title="StepLR阶梯式衰减"></li><li><h2 id="三段式衰减"><a href="#三段式衰减" class="headerlink" title="三段式衰减"></a>三段式衰减</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = net()</span><br><span class="line">LR = <span class="number">0.01</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr = LR)</span><br><span class="line">scheduler = lr_scheduler.MultiStepLR(optimizer, milestones = [<span class="number">20</span>,<span class="number">80</span>], gamma = <span class="number">0.9</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    scheduler.step()</span><br></pre></td></tr></table></figure><p>这种方法就是，当epoch进入milestones范围内即乘以gamma，离开milestones范围之后再乘以gamma。<br>这种衰减方式也是在学术论文中最常见的方式，一般手动调整也会采用这种方法。</p><img src="/deep-learning20191001151454/三段式衰减.png" title="三段式衰减"></li><li><h2 id="连续衰减"><a href="#连续衰减" class="headerlink" title="连续衰减"></a>连续衰减</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = net()</span><br><span class="line">LR = <span class="number">0.01</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr = LR)</span><br><span class="line">scheduler = lr_scheduler.ExponentialLR(optimizer, gamma = <span class="number">0.9</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    scheduler.step()</span><br></pre></td></tr></table></figure><p>这种方法就是在每个epoch中lr都乘以gamma，从而达到连续衰减的效果。</p><img src="/deep-learning20191001151454/连续衰减.png" title="连续衰减"></li><li><h2 id="余弦式调整"><a href="#余弦式调整" class="headerlink" title="余弦式调整"></a>余弦式调整</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = net()</span><br><span class="line">LR = <span class="number">0.01</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr = LR)</span><br><span class="line">scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max = <span class="number">20</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    scheduler.step()</span><br></pre></td></tr></table></figure><p>这里的T_max对应1/2个cos周期所对应的epoch数值。</p><img src="/deep-learning20191001151454/余弦式调整.png" title="余弦式调整"></li><li><h2 id="基于loss和accuracy"><a href="#基于loss和accuracy" class="headerlink" title="基于loss和accuracy"></a>基于loss和accuracy</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model = net()</span><br><span class="line">LR = <span class="number">0.01</span></span><br><span class="line">optimizer = Adam(model.parameters(), lr = LR)</span><br><span class="line">scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode = <span class="string">'min'</span>, factor = <span class="number">0.1</span>, patience = <span class="number">10</span>, verbose = <span class="literal">False</span>, threshold = <span class="number">0.0001</span>, threshold_mode = <span class="string">'rel'</span>, cooldown = <span class="number">0</span>, min_lr = <span class="number">0</span>, eps = <span class="number">1e-08</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">100</span>):</span><br><span class="line">    scheduler.step()</span><br></pre></td></tr></table></figure><p>当发现loss不再降低或者accuracy不再提高之后，就降低学习率。</p><blockquote><p>注：上面代码中各参数意义如下：<br>mode：’min’模式检测metric是否不再减小，’max’模式检测metric是否不再增大；<br>factor：触发条件后lr*=factor；<br>patience：不再减小（或增大）的累计次数；<br>verbose：触发条件后print；<br>threshold：只关注超过阈值的显著变化；<br>threshold_mode：有rel和abs两种阈值计算模式，rel规则：max模式下如果超过best(1+threshold)为显著，min模式下如果低于best(1-threshold)为显著；abs规则：max模式下如果超过best+threshold为显著，min模式下如果低于best-threshold为显著；<br>cooldown：触发一次条件后，等待一定epoch再进行检测，避免lr下降过速；<br>min_lr：最小的允许lr；<br>eps：如果新旧lr之间的差异小与1e-8，则忽略此次更新。</p></blockquote></li></ol><p>这里非常感谢facebook的员工给我们提供了如此多的选择与便利！</p><hr><h1 id="批归一化（Batch-Normalization）"><a href="#批归一化（Batch-Normalization）" class="headerlink" title="批归一化（Batch Normalization）"></a>批归一化（Batch Normalization）</h1><p>除了对学习率进行调整之外，Batch Normalization也可以有效地解决之前的问题。<br>我是在学习ResNet的时候第一次遇到批归一化这个概念的。随着深度神经网络深度的加深，训练越来越困难，收敛越来越慢。为此，很多论文都尝试解决这个问题，比如ReLU激活函数，再比如Residual Network，而BN本质上也是解释并从某个不同的角度来解决这个问题的。<br>通过使用Batch Normalization，我们可以加快网络的收敛速度，这样我们就可以使用较大的学习率来训练网络了。此外，BN还提高了网络的泛化能力。<br>BN的基本思想其实相当直观：<br>首先，因为深层神经网络在做非线性变换前的激活输入值（就是x=WU+B，U是输入）随着网络深度加深或者在训练过程中，其分布逐渐发生偏移或者变动，之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近（对于Sigmoid函数来说，意味着激活输入值WU+B是大的负值或正值），这就导致了反向传播时低层神经网络的梯度消失，这是训练深层神经网络收敛越来越慢的本质原因。<br>事实上，神经网络学习过程本质上是为了学习数据的分布，而BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0、方差为1的标准正态分布，其实就是把越来越偏的分布强制拉回比较标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，从而让梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，因此通过BN能大大加快训练速度。<br>下面来看看BN的具体操作过程：<br><img src="/deep-learning20191001151454/BN操作过程.png" title="BN操作过程"><br>即以下四个步骤：<br>1.计算样本均值。<br>2.计算样本方差。<br>3.对样本数据进行标准化处理。<br>4.进行平移和缩放处理。这里引入了γ和β两个参数。通过训练可学习重构的γ和β这两个参数，让我们的网络可以学习恢复出原始网络所要学习的特征分布。<br>下面是BN层的训练流程：<br><img src="/deep-learning20191001151454/BN训练流程.png" title="BN训练流程"><br>这里的详细过程如下：<br>输入：待进入激活函数的变量。<br>输出：<br>1.这里的K，在卷积网络中可以看作是卷积核个数，如网络中第n层有64个卷积核，就需要计算64次。</p><blockquote><p>注意：在正向传播时，会使用γ与β使得BN层输出与输入一样。</p></blockquote><p>2.在反向传播时利用γ与β求得梯度从而改变训练权值（变量）。<br>3.通过不断迭代直到训练结束，求得关于不同层的γ与β。<br>4.不断遍历训练集中的图片，取出每个batch_size中的γ与β，最后统计每层BN的γ与β各自的和除以图片数量得到平均值，并对其做无偏估计直作为每一层的E[x]与Var[x]。<br>5.在预测的正向传播时，对测试数据求取γ与β，并使用该层的E[x]与Var[x]，通过图中11：所表示的公式计算BN层输出。</p><blockquote><p>注意：在预测时，BN层的输出已经被改变，因此BN层在预测中的作用体现在此处。</p></blockquote><p>上面输入的是待进入激活函数的变量，在残差网络ResNet中，的确也是先经过BN层再用relu函数做非线性处理的。那么，为什么BN层一般用在线性层和卷积层的后面，而不是放在非线性单元即激活函数之后呢？<br>因为非线性单元的输出分布形状会在训练过程中变化，归一化无法消除他的方差偏移。相反的，全连接和卷积层的输出一般是一个对称、非稀疏的一个分布，更加类似高斯分布，对他们进行归一化会产生更加稳定的分布。<br>比如，我们对一个高斯分布的数据relu激活，那么小于0的直接就被抑制了，这样得到的结果很难是高斯分布了，这时候再添加一个BN层就很难达到所需的效果。</p><hr><h1 id="批归一化实现"><a href="#批归一化实现" class="headerlink" title="批归一化实现"></a>批归一化实现</h1><p>这里还是使用pytorch进行实现。<br>准备（对下列通用）：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br></pre></td></tr></table></figure><p></p><ol><li><h2 id="2d或3d输入"><a href="#2d或3d输入" class="headerlink" title="2d或3d输入"></a>2d或3d输入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加了可学习的仿射变换参数</span></span><br><span class="line">m = nn.BatchNorm1d(<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 未添加可学习的仿射变换参数</span></span><br><span class="line">m = nn.BatchNorm1d(<span class="number">100</span>, affine = <span class="literal">False</span>)</span><br><span class="line">input = torch.autograd.Variable(torch.randn(<span class="number">20</span>, <span class="number">100</span>))</span><br><span class="line">output = m(input)</span><br></pre></td></tr></table></figure><p>我们查看m，可以看到有如下形式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)</span><br></pre></td></tr></table></figure><p>这里解释一下涉及到的参数：<br>num_features：来自期望输入的特征数，该期望输入的大小为：<code>batch_size * num_features(* width)</code><br>eps：为保证数值稳定性（分母不能趋近或取0），给分母加上的值，默认为1e-5。<br>momentum：计算动态均值和动态方差并进行移动平均所使用的动量，默认为0.1。<br>affine：一个布尔值，当设为true时，就给该层添加可学习的仿射变换参数。仿射变换将在后文做简单介绍。<br>BatchNorm1d可以有两种输入输出：<br>1.输入（N，C），输出（N，C）。<br>2.输入（N，C，L），输出（N，C，L）。</p></li><li><h2 id="3d或4d输入"><a href="#3d或4d输入" class="headerlink" title="3d或4d输入"></a>3d或4d输入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">m = nn.BatchNorm2d(<span class="number">100</span>)</span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">m = nn.BatchNorm2d(<span class="number">100</span>, affine = <span class="literal">False</span>)</span><br><span class="line">input = torch.autograd.Variable(torch.randn(<span class="number">20</span>, <span class="number">100</span>, <span class="number">35</span>, <span class="number">45</span>))</span><br><span class="line">output = m(input)</span><br></pre></td></tr></table></figure><p>BatchNorm2d也可以有两种输入输出：<br>1.输入（N，C，L），输出（N，C，L）。<br>2.输入（N，C，H，W），输出（N，C，H，W）。</p></li><li><h2 id="4d或5d输入"><a href="#4d或5d输入" class="headerlink" title="4d或5d输入"></a>4d或5d输入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m = nn.BatchNorm3d(<span class="number">100</span>)</span><br><span class="line"><span class="comment">#或者</span></span><br><span class="line">m = nn.BatchNorm3d(<span class="number">100</span>, affine=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>BatchNorm3d同样支持两种输入输出：<br>1.输入（N，C，H，W），输出（N，C，H，W）。<br>2.输入（N，C，D，H，W），输出（N，C，D，H，W）。</p></li></ol><hr><h1 id="仿射变换"><a href="#仿射变换" class="headerlink" title="仿射变换"></a>仿射变换</h1><p>这里我简单介绍一下仿射变换的概念，仿射变换（Affine Transformation或Affine Map）是一种二维坐标（x, y）到二维坐标（u, v）的变换，它是另外两种简单变换的叠加，一是线性变换，二是平移变换。同时，仿射变换保持了二维图形的“平直性”、“平行性”和“共线比例不变性”，非共线的三对对应点确定一个唯一的仿射变换。</p><blockquote><p>补充：<br>共线性：若几个点变换前在一条线上，则仿射变换后仍然在一条线上。<br>平行性：若两条线变换前平行，则变换后仍然平行。<br>共线比例不变性：变换前一条线上两条线段的比例，在变换后比例不变。</p></blockquote><p>在二维图像变换中，它的一般表达如下：<br><img src="/deep-learning20191001151454/仿射变换.png" title="仿射变换"><br>可以视为线性变换R和平移变换T的叠加。<br>另外，仿射变换可以通过一系列的原子变换的复合来实现，包括平移，缩放，翻转，旋转和剪切。因此我们可以将几种简单的变换矩阵相乘来实现仿射变换。</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;一段时间之前，在一个深度学习交流群里看到一个群友发问：为什么他的训练误差最后疯狂上下抖动而不是一直降低。&lt;br&gt;&lt;img src=&quot;/deep-
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://gsy00517.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="深度学习" scheme="https://gsy00517.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="代码实现" scheme="https://gsy00517.github.io/tags/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    
      <category term="pytorch" scheme="https://gsy00517.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>windows笔记：一些快捷的操作</title>
    <link href="https://gsy00517.github.io/windows20191001130531/"/>
    <id>https://gsy00517.github.io/windows20191001130531/</id>
    <published>2019-10-01T05:05:31.000Z</published>
    <updated>2019-11-02T03:18:03.811Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>之前在网上看到一个windows系统下的上帝模式，很好奇，尝试之后感觉不错，这里介绍一下创建的方法。除此之外附上一些类似的快捷操作。</p><hr><h1 id="上帝模式"><a href="#上帝模式" class="headerlink" title="上帝模式"></a>上帝模式</h1><p>上帝模式，即”God Mode”，或称为“完全控制面板”。它是windows系统中隐藏的一个简单的文件夹窗口，包含了几乎所有windows系统的设置，如控制面板的功能、界面个性化、辅助功能选项等控制设置，用户只需通过这一个窗口就能实现所有的操控，而不必再去为调整一个小小的系统设置细想半天究竟该在什么地方去打开设置。打开上帝模式后你将会看到如下界面：<br><img src="/windows20191001130531/上帝模式.png" title="上帝模式"><br>好吧我承认和想象中的上帝模式不太一样，不过下面我还是介绍一下这个略显简陋的上帝模式是怎么设置的。</p><ol><li><h2 id="方式一：添加桌面快捷方式"><a href="#方式一：添加桌面快捷方式" class="headerlink" title="方式一：添加桌面快捷方式"></a>方式一：添加桌面快捷方式</h2><ol><li>首先在桌面新建一个文件夹。</li><li>将新建的文件夹命名为：<code>GodMode.{ED7BA470-8E54-465E-825C-99712043E01C}</code>。</li><li>重命名完成后，你将看到一个类似于控制面板但没有名称的图标，双击打开，就可以看到之前所展示的上帝模式的界面了。<img src="/windows20191001130531/快捷方式.png" title="快捷方式"></li></ol></li><li><h2 id="方式二：添加到快捷菜单"><a href="#方式二：添加到快捷菜单" class="headerlink" title="方式二：添加到快捷菜单"></a>方式二：添加到快捷菜单</h2><ol><li>win+R运行，输入regedit打开注册表编辑器，允许更改。<img src="/windows20191001130531/注册表编辑器.png" title="注册表编辑器"></li><li>依次展开路径至HKEY_CLASSES_ROOT\DesktopBackground\Shell。<img src="/windows20191001130531/路径.jpg" title="路径"></li><li>点击shell后在右侧窗口鼠标右击，选择新建项。<img src="/windows20191001130531/新建项.jpg" title="新建项"></li><li>把新建的项重命名为“上帝模式”。<img src="/windows20191001130531/重命名上帝模式.jpg" title="重命名上帝模式"></li><li>点击上帝模式后，双击右侧窗口中的默认，在数值数据处输入上帝模式，点击确定。<img src="/windows20191001130531/输入上帝模式.jpg" title="输入上帝模式"></li><li>右击上帝模式，选择新建项。<img src="/windows20191001130531/再新建项.jpg" title="再新建项"></li><li>把新建的项重命名为“command”。</li><li>点击command后，双击右侧窗口中的默认，在数值数据处输入：<code>explorer shell:::{ED7BA470-8E54-465E-825C-99712043E01C}</code>，确定。<img src="/windows20191001130531/输入数值.jpg" title="输入数值"></li><li>这时候在桌面空白处右键打开快捷菜单，就可以看到上帝模式已成功添加。<img src="/windows20191001130531/快捷菜单.png" title="快捷菜单"></li></ol></li></ol><hr><h1 id="类似的操作"><a href="#类似的操作" class="headerlink" title="类似的操作"></a>类似的操作</h1><p>在上面我的快捷菜单中，可以看到还有关机、重启、锁屏等选项。其实它们添加的操作和添加上帝模式的步骤是一样的，只需把命名为“上帝模式”的地方修改成“关机”等文字，并且在上文中的第8步中，用对应的数值数据即可。<br><img src="/windows20191001130531/完成.jpg" title="完成"><br>这里提供四种功能对应的数值数据，其实这些和上面上帝模式的commmand命令都是可以直接在cmd中执行的：<br>关机<code>Shutdown -s -f -t 00</code><br>注销<code>Shutdown -l</code><br>重启<code>Shutdown -r -f -t 00</code><br>锁屏<code>Rundll32 User32.dll,LockWorkStation</code><br>事实上，锁屏功能可以直接使用win+L快捷键达到目的。除此之外，win还可以搭配其他的一些按键完成一些快捷操作，比如win+D可以快速最小化一切窗口回到桌面，想知道win有哪些搭配可以右键左下角的win图标查看。<br><img src="/windows20191001130531/可用快捷键.png" title="可用快捷键"></p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;之前在网上看到一个windows系统下的上帝模式，很好奇，尝试之后感觉不错，这里介绍一下创建的方法。除此之外附上一些类似的快捷操作。&lt;/p&gt;&lt;h
      
    
    </summary>
    
    
      <category term="操作与使用" scheme="https://gsy00517.github.io/categories/%E6%93%8D%E4%BD%9C%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="命令操作" scheme="https://gsy00517.github.io/tags/%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/"/>
    
      <category term="配置优化" scheme="https://gsy00517.github.io/tags/%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96/"/>
    
      <category term="windows" scheme="https://gsy00517.github.io/tags/windows/"/>
    
  </entry>
  
  <entry>
    <title>machine learning笔记：过拟合与欠拟合</title>
    <link href="https://gsy00517.github.io/machine-learning20191001104538/"/>
    <id>https://gsy00517.github.io/machine-learning20191001104538/</id>
    <published>2019-10-01T02:45:38.000Z</published>
    <updated>2019-11-02T02:22:32.296Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>本文介绍在模型评估可能会出现的过拟合与欠拟合两种现象，并对解决方法做一个总结。</p><hr><h1 id="解释"><a href="#解释" class="headerlink" title="解释"></a>解释</h1><p>我们先通过图片来直观地解释这两种现象：<br><img src="/machine-learning20191001104538/欠拟合与过拟合.jpg" title="欠拟合与过拟合"><br>在上图中，右边是过拟合的情况，它指的是模型对于训练数据拟合过度，反映到评估指标上，就是模型在训练集上的表现很好，但在测试集和新数据上的表现较差。这是因为在这种条件下，模型过于复杂，导致把噪声数据的特征也学习到了模型中，导致模型的泛化能力下降，从而在后期的应用过程中很容易输出错误的预测结果。<br>左边是欠拟合的情况，它指的是在训练和预测时的表现都不好，这样的模型没有很好地捕捉到数据地特征，从而不能够很好地拟合数据。<br>相比而言，中间是拟合适当的情况，这种模型在应用中就具有很好的鲁棒性。</p><hr><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><ol><li><h2 id="针对过拟合"><a href="#针对过拟合" class="headerlink" title="针对过拟合"></a>针对过拟合</h2><ol><li><h3 id="获取更多数据。"><a href="#获取更多数据。" class="headerlink" title="获取更多数据。"></a>获取更多数据。</h3>更多的样本可以让模型学到更多有效的特征，从而减小噪声的影响。<br>当然，一般情况下直接增加数据是很困难的，因此我们需要通过一定的规则来扩充训练数据。比如，在图像分类问题上，我们可以使用数据增强的方法，通过对图像的平移、旋转、缩放等方式来扩充数据；更进一步地，可以使用生成式对抗网络来合成大量新的训练数据。</li><li><h3 id="降低模型复杂度。"><a href="#降低模型复杂度。" class="headerlink" title="降低模型复杂度。"></a>降低模型复杂度。</h3>模型复杂度过高是数据量较小时过拟合的主要原因。适当降低模型的复杂度可以避免模型拟合过多的噪声。比如，在神经网络模型中减少网络层数、神经元个数等；在决策树模型中降低树的深度、进行剪枝等。<blockquote><p>注意：网络深度增加引起的准确率退化不一定是过拟合引起的，这是因为深度造成的梯度消失、梯度爆炸等问题，这在ResNet的论文中有讨论，详细可以看我的博文<a href="https://gsy00517.github.io/deep-learning20191001184216/" target="_blank">deep-learning笔记：使网络能够更深——ResNet简介与pytorch实现</a>。</p></blockquote></li><li><h3 id="正则化方法。"><a href="#正则化方法。" class="headerlink" title="正则化方法。"></a>正则化方法。</h3>这里的方法主要是权重正则化法，具体说明可以参考<a href="https://gsy00517.github.io/machine-learning20190915150339/" target="_blank">machine-learning笔记：机器学习中正则化的理解</a>。</li><li><h3 id="集成学习。"><a href="#集成学习。" class="headerlink" title="集成学习。"></a>集成学习。</h3>即把多个模型集成在一起，从而降低单一模型的过拟合风险。主要有Bagging（bootstrap aggregating）和Boosting（adaptive boosting）这两种集成学习方法。</li></ol></li><li><h2 id="针对欠拟合"><a href="#针对欠拟合" class="headerlink" title="针对欠拟合"></a>针对欠拟合</h2>解决欠拟合问题也可以参照解决过拟合问题的思路；<ol><li><h3 id="添加新特征。"><a href="#添加新特征。" class="headerlink" title="添加新特征。"></a>添加新特征。</h3>当特征不足或者现有特征与样本标签的相关性不强时，模型容易出现欠拟合。<br>因此，通过挖掘“上下文特征”、“组合特征”等新的特征，往往能够取得更好的效果。<br>在深度学习中，也有很多模型可以帮助完成特征工程，比如因此分解机、梯度提升决策树、Deep-crossing等都可以成为丰富特征的方法。</li><li><h3 id="增加模型复杂度。"><a href="#增加模型复杂度。" class="headerlink" title="增加模型复杂度。"></a>增加模型复杂度。</h3>当模型过于简单时，增加模型复杂度可以使模型拥有更强的拟合能力。比如，在线性模型中添加高次项，在神经网络模型中增加网络层数、神经元个数等。<br>对于模型的选择，我在文末补充了两种模型选择的准则供参考。</li><li><h3 id="减小正则化系数。"><a href="#减小正则化系数。" class="headerlink" title="减小正则化系数。"></a>减小正则化系数。</h3>正则化是用来防止过拟合的，但当模型出现欠拟合现象时，我们就应该有针对性地减小正则化系数。</li></ol></li></ol><hr><h1 id="模型选择准则"><a href="#模型选择准则" class="headerlink" title="模型选择准则"></a>模型选择准则</h1><p>模型选择的信息准则有很多，我这里介绍我知道的两个比较常用的模型选择准则：</p><ol><li><h2 id="AIC准则"><a href="#AIC准则" class="headerlink" title="AIC准则"></a>AIC准则</h2>赤池信息准则（Akaike Information Criterion，AIC）公式定义如下：<script type="math/tex;mode=display">AIC=2k-2ln(L)\</script>其中k表示模型参数个数（复杂度），L表示经验误差（似然函数）。<br>当需要从一组可供选择的模型中选择最佳模型时，通常选择AIC最小的模型。</li><li><h2 id="BIC准则"><a href="#BIC准则" class="headerlink" title="BIC准则"></a>BIC准则</h2>贝叶斯信息准则（Bayesian Information Criterion，BIC）是对AIC准则的改进，定义如下：<script type="math/tex;mode=display">BIC=kln(n)-2ln(L)\</script>与AIC不同，这里k的系数不再是常数。其中n代表的是样本量（数据量），这样，BIC准则就与样本量相关了。当样本量足够时，过拟合的风险变小，我们就可以允许模型复杂一些。<br>这里再次附上这张直观的图片，方便理解与体会。简析可参考<a href="https://gsy00517.github.io/machine-learning20190915150339/" target="_blank">machine-learning笔记：机器学习中正则化的理解</a>。<img src="/machine-learning20191001104538/复杂度与数据量对性能的影响.jpg" title="复杂度与数据量对性能的影响"></li></ol><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;本文介绍在模型评估可能会出现的过拟合与欠拟合两种现象，并对解决方法做一个总结。&lt;/p&gt;&lt;hr&gt;&lt;h1 id=&quot;解释&quot;&gt;&lt;a href=&quot;#解释&quot;
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://gsy00517.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="机器学习" scheme="https://gsy00517.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="模型评估" scheme="https://gsy00517.github.io/tags/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0/"/>
    
  </entry>
  
  <entry>
    <title>artificial intelligence笔记：人工智能前沿发展情况分享</title>
    <link href="https://gsy00517.github.io/artificial-intelligence20191001101334/"/>
    <id>https://gsy00517.github.io/artificial-intelligence20191001101334/</id>
    <published>2019-10-01T02:13:34.000Z</published>
    <updated>2019-11-02T02:21:00.480Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>这是我在一个相关的群里看到的一个论文，这篇论文比较新，看完之后觉得对目前AI发展状况的了解有一定价值，就放了上来。</p><hr><h1 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h1><p>这里直接提供图片形式的原文：<br><img src="/artificial-intelligence20191001101334/论文全文.JPG" title="论文全文"></p><hr><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>难得有一篇以AI开篇的文章，由于在我不到一年前真正接触AI相关知识时，一直疑惑人工智能、机器学习与深度学习之间的关系。直到看了台大教授李宏毅的课才知道三者之间的包含关系，这里就把课件中的一张图片放上来，一目了然：<br><img src="/artificial-intelligence20191001101334/AI、ML、DL关系.jpg" title="AI、ML、DL关系"><br>最后，再补张和<a href="https://gsy00517.github.io/deep-learning20190914142553/" target="_blank">deep-learning笔记：一篇非常经典的论文——NatureDeepReview</a>文末对应的一张我觉得挺真实的图哈哈。<br><img src="/artificial-intelligence20191001101334/什么是机器学习.jpg" title="什么是机器学习"><br>不得不说，目前丰富的库和各种深度学习框架的确极大地方便了AI的学习与研究，许多轮子都已造好。学会运用这些工具还是很有帮助的！</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;这是我在一个相关的群里看到的一个论文，这篇论文比较新，看完之后觉得对目前AI发展状况的了解有一定价值，就放了上来。&lt;/p&gt;&lt;hr&gt;&lt;h1 id=
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://gsy00517.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="机器学习" scheme="https://gsy00517.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="深度学习" scheme="https://gsy00517.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文分享" scheme="https://gsy00517.github.io/tags/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>machine learning笔记：一个支持向量机的问题</title>
    <link href="https://gsy00517.github.io/machine-learning20191001093428/"/>
    <id>https://gsy00517.github.io/machine-learning20191001093428/</id>
    <published>2019-10-01T01:34:28.000Z</published>
    <updated>2019-11-02T02:22:49.692Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>在学习机器学习理论的过程中，支持向量机（SVM）应该是我们会遇到的第一个对数学要求比较高的概念。理解它的原理要花费了我不少时间，写这篇博文是因为我之前看到的一个有关SVM的问题，其解答需用到SVM的相关数学原理，可以促使我思考。支持向量机的具体原理以及推导网上有大量资源，我也会在文中提供一些供参考。</p><hr><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>支持向量机是一种有监督的学习方法，主要思想是建立一个最优决策超平面，使得该平面两侧距离该平面最近的两类样本之间的距离最大化，从而对分类问题提供良好的泛化能力。<br>这里有个小故事，也是我第一次看SVM课程时老师提到的，可以通过这个小故事大致理解一下SVM在做什么。<br><img src="/machine-learning20191001093428/小故事.JPG" title="小故事"><br>它的优点主要有如下四点：<br>1.相对于其他训练分类算法，SVM不需要过多的样本。<br>2.SVM引入了核函数，可以处理高维的样本。<br>3.结构风险最小。也就是说，分类器对问题真实模型的逼近与真实解之间的累计误差最小。<br>4.由于SVM的非线性，它擅长应付线性不可分的问题。这主要是用松弛变量（惩罚变量）和核函数来实现的。<br>这里我附上我所知的三个SVM的常用软件工具包：<a href="http://svmlight.joachims.org/" target="_blank">SVMLight</a>、<a href="https://www.csie.ntu.edu.tw/~cjlin/libsvm/" target="_blank">LibSVM</a>、<a href="https://www.csie.ntu.edu.tw/~cjlin/liblinear/" target="_blank">Liblinear</a>。</p><hr><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><p>下面就是我在文章开头提到的问题，直接搬运：<br><img src="/machine-learning20191001093428/问题.JPG" title="问题"><br>解析中提到的拉格朗日乘子法和KKT条件，也是我在看到这个问题后才尝试去理解的。能力有限，不能自己很好的解释，这里附上<a href="KKT.pdf" target="_blank">瑞典皇家理工学院（KTH）“统计学习基础”课程的KKT课件</a>，个人觉得讲的很直观且详细了。</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在学习机器学习理论的过程中，支持向量机（SVM）应该是我们会遇到的第一个对数学要求比较高的概念。理解它的原理要花费了我不少时间，写这篇博文是因为
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://gsy00517.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="机器学习" scheme="https://gsy00517.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>database笔记：范式的理解</title>
    <link href="https://gsy00517.github.io/database20190921195840/"/>
    <id>https://gsy00517.github.io/database20190921195840/</id>
    <published>2019-09-21T11:58:40.000Z</published>
    <updated>2019-11-02T02:21:14.921Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>今天终于完成了计算机三级数据库的考试，这也是本学期的第一门考试。听说计算机三级中要属计算机网络最简单，然而出于学到更多有用的知识的目的，我报了数据库。然而事实证明也没学到多少，毕竟这个计算机等级考试是给非计算机专业的人设置的，现在只求能过。不过两三天书看下来，还是有些收获，现在考完了有时间就在这里记一下，方便自己和别人今后有需要看。</p><p>本文参考自：<a href="https://blog.csdn.net/he626shidizai/article/details/90707037" target="_blank" rel="noopener">https://blog.csdn.net/he626shidizai/article/details/90707037</a><br><a href="https://blog.csdn.net/u013011841/article/details/39023859" target="_blank" rel="noopener">https://blog.csdn.net/u013011841/article/details/39023859</a></p><hr><h1 id="范式"><a href="#范式" class="headerlink" title="范式"></a>范式</h1><blockquote><p>注意：本文中的范式指的是数据库范式。</p></blockquote><p>在设计数据库时，为了设计一个良好的逻辑关系，必须要使关系受一定条件的约束，这种约束逐渐成为一种规范，就是我们所说的范式。<br>目前关系数据库有六种范式：第一范式（1NF）、第二范式（2NF）、第三范式（3NF）、巴斯-科德范式（BCNF）、第四范式(4NF）和第五范式（5NF）。要求最低的是1NF，往后依次变得严格。其中最后的5NF又称完美范式。<br>数据库一般只需满足3NF，下面我就介绍一下前三种范式。</p><h1 id="第一范式"><a href="#第一范式" class="headerlink" title="第一范式"></a>第一范式</h1><p>数据库考试官方教程并没有对每个范式的定义进行讲解，另外因为文字定义比较晦涩难懂，我这里通过多方参考，用图片的形式来展示各个约束条件。<br>首先，1NF是所有关系型数据库最基本的要求，它的定义为：符合1NF的关系中的每个属性都不可再分。下图就是一个违反1NF的例子：<br><img src="/database20190921195840/不符1NF-1.png" title="不符1NF-1"><br>修改如下：<br><img src="/database20190921195840/符合1NF-1.png" title="符合1NF-1"><br>上面的情况就符合1NF了。<br>我们还可以把第一范式分成两点来理解：</p><ol><li><h2 id="每个字段都只能存放单一值"><a href="#每个字段都只能存放单一值" class="headerlink" title="每个字段都只能存放单一值"></a>每个字段都只能存放单一值</h2>还是上反例：<img src="/database20190921195840/不符1NF-2.png" title="不符1NF-2"> 上图中，第一行的课程有两个值，这就不符合第一范式了。因此要修改成这样：<img src="/database20190921195840/符合1NF-2.png" title="符合1NF-2"></li><li><h2 id="每笔记录都要能用一个唯一的主键识别"><a href="#每笔记录都要能用一个唯一的主键识别" class="headerlink" title="每笔记录都要能用一个唯一的主键识别"></a>每笔记录都要能用一个唯一的主键识别</h2><img src="/database20190921195840/不符1NF-3.png" title="不符1NF-3"> 这里出现了重复组，同样也不满足1NF，因为缺乏唯一的标识码。因此修改如下：<img src="/database20190921195840/符合1NF-3.png" title="符合1NF-3"></li></ol><h1 id="第二范式"><a href="#第二范式" class="headerlink" title="第二范式"></a>第二范式</h1><p>第二范式是建立在第一范式的基础上的，它的改进在于：消除了非主属性对于码的部分函数依赖。<br>第二范式消除了非主属性对于码的部分函数依赖，也就是说，第二范式中所有非主属性完全依赖于主键，即不能依赖于主键的一部分属性。<br>为了解释明白，还是通过实例的说明：<br><img src="/database20190921195840/不符2NF.png" title="不符2NF"><br>上表中，学号和课程号组合在一起是主键，但是姓名只由学号决定，这就违反了第二范式。同样的，课程名只由课程号决定，这也违反了第二范式。此外，只需要知道学号和课程号就能知道成绩。<br>为了满足第二范式，我们就需要对上表做如下拆分：<br><img src="/database20190921195840/符合2NF.png" title="符合2NF"></p><h1 id="第三范式"><a href="#第三范式" class="headerlink" title="第三范式"></a>第三范式</h1><p>同样的，第三范式建立在第二范式的基础上。不同之处在于，在第二范式的基础之上，第三范式中非主属性都不传递依赖于主键。<br>这是什么意思？还是看图说话：<br><img src="/database20190921195840/不符3NF.png" title="不符3NF"><br>上表中，主键是学号，且已满足第二范式。然而，学校的地址也可以根据学校名称来确定，第三范式就是在这里再做一个分解：<br><img src="/database20190921195840/符合3NF.png" title="符合3NF"></p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;今天终于完成了计算机三级数据库的考试，这也是本学期的第一门考试。听说计算机三级中要属计算机网络最简单，然而出于学到更多有用的知识的目的，我报了数
      
    
    </summary>
    
    
      <category term="知识点与小技巧" scheme="https://gsy00517.github.io/categories/%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%8E%E5%B0%8F%E6%8A%80%E5%B7%A7/"/>
    
    
      <category term="数据库" scheme="https://gsy00517.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>hexo笔记：在linux（ubuntu）下安装使用</title>
    <link href="https://gsy00517.github.io/hexo20190917085649/"/>
    <id>https://gsy00517.github.io/hexo20190917085649/</id>
    <published>2019-09-17T00:56:49.000Z</published>
    <updated>2019-11-02T03:17:39.337Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>之前一直在win10下使用hexo搭建部署博客，方法参见：<a href="https://gsy00517.github.io/hexo20190913153310/" target="_blank">hexo笔记：开始创建个人博客——方法及原因</a>。那么，如果想在linux环境下使用hexo，该如何操作呢？</p><p>本文参考自：<a href="https://blog.csdn.net/y5492853/article/details/79529410" target="_blank" rel="noopener">https://blog.csdn.net/y5492853/article/details/79529410</a></p><hr><h1 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h1><p>由于在更改主题配置文件_config.yml时，长达八百多行的配置文件总是让我找得头晕目眩。由于VScode（好像）没有提供字符的快速查找匹配功能，我之前一直采用一种笨拙的办法，即在文件的空处输入想要查找的字符然后左键选中，这个时候文件中同样的字符也会被选中，这样快速拉动滚动条时就可以比较明显地发现想找的目标字符了。<br>然而对于这种办法，我觉得主要有两大问题：</p><ol><li><h2 id="忘记删除在空白处添加的文字"><a href="#忘记删除在空白处添加的文字" class="headerlink" title="忘记删除在空白处添加的文字"></a>忘记删除在空白处添加的文字</h2>我就犯过这样低级的错误，找到并更改之后没有删除自己添加的字符就直接快乐地ctrl+S了，于是就造成了网站能打开但是一片空白的bug。所以大家没事还是不要随意在主题配置文件中添加文字。</li><li><h2 id="不是长久之计"><a href="#不是长久之计" class="headerlink" title="不是长久之计"></a>不是长久之计</h2>虽然这个八百多行的文件已经让我够呛了，然后或许今后还会遇到更长的文件，那么这种方法就会变得极其低效（而且伤眼睛）。<br>基于这些因素，我脑子里的第一个反映就是vim编辑器中的对文件字符的查找定位的功能（关于vim的使用，等我多多尝试并熟练之后再做小结）。<br>好了，接下来就开始操作吧。</li></ol><hr><h1 id="更正"><a href="#更正" class="headerlink" title="更正"></a>更正</h1><p>最近突然发现VScode自带了搜索功能，可以直接在整个文件夹中搜索关键词。这里所给的快捷键是ctrl+shift+F，但win10用户可能会发现按了之后没有任何反应。事实上，反应还是有的，当你再次打字时，就会发现简体变成了繁体，再次按ctrl+shift+F即可恢复。<br><img src="/hexo20190917085649/搜索.png" title="搜索"><br>直接点击搜索图标即可便捷地进行搜索，为我之前眼瞎没有发现表示无奈，但下面还是写一下怎么安装。</p><hr><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>首先安装node.js。这里就没windows下直接双击exe安装包那么easy啦，打开终端，老老实实输命令：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install nodejs</span><br><span class="line">sudo apt install nodejs-legacy</span><br><span class="line">sudo apt install npm</span><br></pre></td></tr></table></figure><p></p><p>由于ubuntu源中的node.js是旧版本，下面会出现问题，我在后文解释。<br>由于npm服务器在国外可能会影响下载速度，和windows下的步骤一样，我们换成淘宝镜像：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm config set registry https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure><p></p><p>这时候如果我们直接安装hexo，会出现如下错误：<br><img src="/hexo20190917085649/版本过低.png" title="版本过低"><br>因此，我们安装node升级工具n：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm install n -g</span><br></pre></td></tr></table></figure><p></p><p>并且使用<code>sudo n stable</code>升级版本，若看到如下输出，说明升级成功：<br><img src="/hexo20190917085649/升级.png" title="升级"></p><blockquote><p>注意：fetch可能需要花费一点时间，这时候终端不会有任何输出，不要以为出错了，耐心等待即可，不要ctrl+C中止。</p></blockquote><p>最后，我们安装hexo：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo npm install -g hexo</span><br></pre></td></tr></table></figure><p></p><blockquote><p>注：-g表示安装到全局环境。</p></blockquote><p>接下来的初始化操作跟windows下基本一样，可以参照我之前的博文。我继续对原来的博客进行编辑，所以无需初始化一个新的，直接把windows的对应文件夹整个copy过来就行了。</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;之前一直在win10下使用hexo搭建部署博客，方法参见：&lt;a href=&quot;https://gsy00517.github.io/hexo201
      
    
    </summary>
    
    
      <category term="操作与使用" scheme="https://gsy00517.github.io/categories/%E6%93%8D%E4%BD%9C%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="hexo" scheme="https://gsy00517.github.io/tags/hexo/"/>
    
      <category term="ubuntu" scheme="https://gsy00517.github.io/tags/ubuntu/"/>
    
      <category term="安装教程" scheme="https://gsy00517.github.io/tags/%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
  <entry>
    <title>machine learning笔记：机器学习中正则化的理解</title>
    <link href="https://gsy00517.github.io/machine-learning20190915150339/"/>
    <id>https://gsy00517.github.io/machine-learning20190915150339/</id>
    <published>2019-09-15T07:03:39.000Z</published>
    <updated>2019-11-02T02:22:43.291Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>在接触了一些ml的知识后，大家一定会对正则化这个词不陌生，但是我感觉根据这个词的字面意思不能够直接地理解它的概念。因此我打算写一篇文章做个记录，方便以后回忆。</p><hr><h1 id="线性代数中的正则化"><a href="#线性代数中的正则化" class="headerlink" title="线性代数中的正则化"></a>线性代数中的正则化</h1><p>如果直接搜索正则化这个名词，首先得到的一般是代数几何中的一个概念。<br>百度词条对它的解释是：给平面不可约代数曲线以某种形式的全纯参数表示。<br>怎么样？是不是觉得一头雾水。<br>这里我推荐使用谷歌或者维基百科来查询这些专业名词。</p><blockquote><p>对于不能科学上网的朋友，没关系，我这里提供了<a href="http://ac.scmor.com/" target="_blank">谷歌镜像</a>和<a href="https://www.wikiwand.com/" target="_blank">wikiwand</a>，大家可以在上面得到一样的搜索结果。</p></blockquote><p>我们直接到维基百科搜索regularization：<br>里面第一段是这样解释的：In mathematics, statistics, and computer science, particularly in machine learning and inverse problems, regularization is the process of adding information in order to solve an ill-posed problem or to prevent overfitting.<br>这就和我们在机器学习应用中的目的比较相近了。</p><hr><h1 id="机器学习中的正则化"><a href="#机器学习中的正则化" class="headerlink" title="机器学习中的正则化"></a>机器学习中的正则化</h1><p>在机器学习中，正则化是一种为了减小测试误差的行为（有时候会增加训练误差）。<br>我们在构造机器学习模型时，最终目的是让模型在面对新数据的时候，可以有很好的表现。当你用比较复杂的模型比如神经网络去拟合数据时，很容易出现过拟合现象（训练集表现很好，测试集表现较差），这会导致模型的泛化能力下降，这时候，我们就需要使用正则化，来降低模型的复杂度。<br>为了加深印象，我下面简单介绍几种常用的机器学习正则化方法：</p><ol><li><h2 id="早停法（Early-Stopping）"><a href="#早停法（Early-Stopping）" class="headerlink" title="早停法（Early Stopping）"></a>早停法（Early Stopping）</h2>早停法，就是当训练集的误差变好，但是验证集的误差变坏（即泛化效果变差）的时候停止训练。这种方法可以一定程度上有效地防止过拟合，同时这也说明了验证集在机器学习中的重要性。<img src="/machine-learning20190915150339/早停法.png" title="早停法"></li><li><h2 id="权重正则化法"><a href="#权重正则化法" class="headerlink" title="权重正则化法"></a>权重正则化法</h2><p>因为噪声相比于正常信号而言，通常会在某些点出现较大的峰值。所以，只要我们保证权重系数在绝对值意义上足够小，就能够保证噪声不会被过度相应，这也是奥卡姆剃刀原理的表现，即模型不应过度复杂，尤其是当数据量不大的时候。</p><img src="/machine-learning20190915150339/复杂度与数据量对性能的影响.jpg" title="复杂度与数据量对性能的影响"><p>上面是在一个网课上看到的、我觉得可以较好地呈现模型的复杂度与数据量对模型预测表现的影响的一张图片，其中向左的横轴表示数据量大小，向右的横轴表示模型复杂度，竖轴是预测表现。通过这张图，可以很明显地观察到：模型的复杂度提升需要大量的数据作为依托。<br>权重正则化主要有两种：</p><ul><li>L1正则：$ J=J_{0}+\lambda \left | w \right |_{1} $，其中J代表损失函数（也称代价函数），$ \left | w \right |_{1} $代表参数向量w的L1范数。</li><li>L2正则（weight decay）：$ J=J_{0}+\lambda \left | w \right |_{2} $，其中$ \left | w \right |_{2} $代表参数向量w的L2范数。<img src="/machine-learning20190915150339/权重正则化.png" title="权重正则化"> 这里就产生了<strong>Lasso回归</strong>与<strong>岭回归</strong>两大机器学习经典算法。其中Lasso回归是一种压缩估计，可以通过构造惩罚函数得到一个较为精炼的模型，使得它可以压缩一些系数，同时设定一些系数为0，从而达到特征选择的目的。基于Lasso回归这种可以选择特征并降维的特性，它主要有这些适用情况：</li></ul><ol><li>样本量比较小，但指标量非常多的时候（易于过拟合）。</li><li>进行高维统计时。</li><li>需要对特征进行选择时。<br>对于这些回归的详细解释，大家可以到网上搜集相关信息。<blockquote><p>补充：<br>L0范数：向量中非零元素的个数。<br>L1范数：向量中每个元素绝对值的和。<br>L2范数：向量元素绝对值的平方和再平方。</p></blockquote></li></ol><p>下面我再附上一组图，希望能帮助更好地理解权重正则化：<br>首先我们可视化一个损失函数。</p><img src="/machine-learning20190915150339/损失函数.png" title="损失函数"><p>下面我们看一看正则化项的图示，这里使用L1范数作为正则化项。</p><img src="/machine-learning20190915150339/正则化项.png" title="正则化项"><p>接着，我们将上面两者线性组合：</p><img src="/machine-learning20190915150339/叠加.png" title="叠加"><p>我们来看看结果：</p><img src="/machine-learning20190915150339/结果.png" title="结果"><p>可见，正则化项的引入排除了大量原本属于最优解的点，上图的情况中剩下一个唯一的局部最优解。</p></li><li><h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>数据增强可以丰富图像数据集，有效防止过拟合。这种方法在AlexNet中有很好的应用，大家可以看看我的博文<a href="https://gsy00517.github.io/deep-learning20190915113859/" target="_blank">deep-learning笔记：开启深度学习热潮——AlexNet</a>。</p><img src="/machine-learning20190915150339/数据增强.jpg" title="数据增强"></li><li><h2 id="随机失活（dropout）"><a href="#随机失活（dropout）" class="headerlink" title="随机失活（dropout）"></a>随机失活（dropout）</h2>dropout即随机砍掉一部分神经元之间的连接，每次只更新一部分，这可以有效地增加它的鲁棒性，提高泛化能力。这个方法在AlexNet中也有详细的解释，推荐大家去看一下。<img src="/machine-learning20190915150339/dropout神经单元.png" title="dropout神经单元"> <img src="/machine-learning20190915150339/dropout神经网络.png" title="dropout神经网络"> 以上就是比较常规且流行的正则化方式，今后或许会有补充，也欢迎大家提供意见~</li></ol><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在接触了一些ml的知识后，大家一定会对正则化这个词不陌生，但是我感觉根据这个词的字面意思不能够直接地理解它的概念。因此我打算写一篇文章做个记录，
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://gsy00517.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="机器学习" scheme="https://gsy00517.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>deep learning笔记：开启深度学习热潮——AlexNet</title>
    <link href="https://gsy00517.github.io/deep-learning20190915113859/"/>
    <id>https://gsy00517.github.io/deep-learning20190915113859/</id>
    <published>2019-09-15T03:38:59.000Z</published>
    <updated>2019-11-02T02:21:21.559Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>继之前那篇<a href="https://gsy00517.github.io/deep-learning20190915073809/" target="_blank">deep-learning笔记：着眼于深度——VGG简介与pytorch实现</a>，我觉得还是有必要提一下VGG的前辈——具有历史意义的AlexNet，于是就写了这篇文章简要介绍一下。</p><hr><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><img src="/deep-learning20190915113859/AlexNet.jpg" title="AlexNet"><p>ALexNet是第一个运用大型深度卷积神经网络的模型，在ILSVRC中一下子比前一年把错误率降低了10%，这是非常惊人的，也很快引起了注意。于是，自2012年开始，深度学习热潮由此引发。<br><img src="/deep-learning20190915113859/AlexNet突破.jpg" title="AlexNet突破"><br>根据我之前听网课的笔记以及网上的其他文章，我把AlexNet主要的进步归纳如下：</p><ol><li>使用大型深度卷积神经网络。</li><li>分组卷积（groupconvolution）来充分利用GPU。</li><li>随机失活dropout：一种有效的正则化方法。关于正则化，可以看我的博文<a href="https://gsy00517.github.io/machine-learning20190915150339/" target="_blank">machine-learning笔记：机器学习中正则化的理解</a>。</li><li>数据增强data augumentation：增大数据集以减小过拟合问题。</li><li>relu激活函数：即max（0，x），至今还被广泛应用。</li></ol><hr><h1 id="个人思考"><a href="#个人思考" class="headerlink" title="个人思考"></a>个人思考</h1><p>这段时间也看了不少东西，对于如何提升神经网络的性能这个问题，我觉得主要有如下三个方面：</p><ol><li><h2 id="从网络本身入手："><a href="#从网络本身入手：" class="headerlink" title="从网络本身入手："></a>从网络本身入手：</h2><ol><li>增加深度。</li><li>增加宽度。</li><li>减少参数量。</li><li>防止过拟合。</li><li>解决梯度消失的问题。</li></ol></li><li><h2 id="从数据集入手："><a href="#从数据集入手：" class="headerlink" title="从数据集入手："></a>从数据集入手：</h2><ol><li>尽可能使用多的数据。</li></ol></li><li><h2 id="从硬件入手："><a href="#从硬件入手：" class="headerlink" title="从硬件入手："></a>从硬件入手：</h2><ol><li>提升GPU性能。</li><li>充分利用现有的GPU性能。<br>当你阅读完AlexNet的论文，你会发现它在这几个方面都有思考且做出了非常优秀的改进。</li></ol></li></ol><hr><h1 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h1><p>在放论文之前，我还是先贴一张流程图，方便在阅读论文的时候进行对照与理解。<br><img src="/deep-learning20190915113859/AlexNet流程图.png" title="AlexNet流程图"><br>下面奉上宝贵的论文：<br><a href="AlexNet.pdf" target="_blank">论文原版</a><br><a href="AlexNet中文.pdf" target="_blank">论文中文版</a><br>从introduction第一句开始，作者就开始了一段长长的吐槽：<br>Current approaches to object recognition make essential use of machine learning methods…<br>吐槽Yann LeCun大佬的论文被顶会拒收了仅仅因为Yann LeCun使用了神经网络。其实，那段时间之前，由于SVM等机器学习方法的兴起，神经网络是一种被许多ml大佬们看不起的算法模型。<br>在introduction的最后，作者留下了这样一句经典的话：<br>All of our experiments suggest that our results can be improved simply by waiting for faster GPUs and bigger datasets to become available.<br>有没有感觉到一种新世界大门被打开的感觉呢？<br>有关论文别的内容，我暂不多说了，大家可以自己看论文学习与体会。<br>附上推荐重点阅读的章节：3.1 ReLUNonlinearity；3.5 OverallArchitecture；4 ReducingOverfitting。</p><hr><h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>同我写VGG的那篇文章中一样，我在英文原版中用黄颜色高亮了我觉得重要的内容给自己和大家今后参考。<br>另外，我在这里推荐大家还是先尝试阅读英文原版。一方面由于一些公式、符号以及名词的原因，英文原版叙述更精准，中文翻译有缺漏、偏颇之处；另一方面更重要的，接触这些方面的知识仅参考中文是远远不够的。<br>在这里我推荐一个chrome英文pdf阅读插件，大家可以自己到chrome里面搜索安装：<br><img src="/deep-learning20190915113859/搜索插件.png" title="搜索插件"><br><img src="/deep-learning20190915113859/添加完成.png" title="添加完成"><br>有了这个插件，遇到不认识的单词，只需双击单词，就可以看到中文释义，一定程度上可以保证阅读的流畅性。但是如果想从根本上解决问题，只有好好背单词吧（我也在朝这个方向努力…）。<br>另外，iPad的上也有好多强大的app，在这里不一一推荐了。</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;继之前那篇&lt;a href=&quot;https://gsy00517.github.io/deep-learning20190915073809/&quot; t
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://gsy00517.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="深度学习" scheme="https://gsy00517.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文分享" scheme="https://gsy00517.github.io/tags/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>markdown笔记：公式插入和代码高亮</title>
    <link href="https://gsy00517.github.io/markdown20190915095628/"/>
    <id>https://gsy00517.github.io/markdown20190915095628/</id>
    <published>2019-09-15T01:56:28.000Z</published>
    <updated>2019-11-02T02:22:54.817Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>在上一篇文章<a href="https://gsy00517.github.io/deep-learning20190915073809/" target="_blank">deep-learning笔记：着眼于深度——VGG简介与pytorch实现</a>中，我用到了markdown其他的一些使用方法，因此我想在此对之前的一篇文章<a href="https://gsy00517.github.io/markdown20190913211144/" target="_blank">markdown笔记：markdown的基本使用</a>做一些补充。</p><p>本文参考自：<a href="https://www.jianshu.com/p/25f0139637b7" target="_blank" rel="noopener">https://www.jianshu.com/p/25f0139637b7</a><br><a href="https://www.jianshu.com/p/fd97e1f8f699" target="_blank" rel="noopener">https://www.jianshu.com/p/fd97e1f8f699</a><br><a href="https://www.jianshu.com/p/68e6f82d88b7" target="_blank" rel="noopener">https://www.jianshu.com/p/68e6f82d88b7</a><br><a href="https://www.jianshu.com/p/7c02c112d532" target="_blank" rel="noopener">https://www.jianshu.com/p/7c02c112d532</a></p><hr><h1 id="公式插入"><a href="#公式插入" class="headerlink" title="公式插入"></a>公式插入</h1><p>无论是学习ml还是dl，我们总是离不开数学的，于是利用markdown插入数学公式就成了一个的需求。那么怎么在markdown中插入公式呢？<br>markdown中的公式分为两类，即行内公式与行间公式。它们对应的代码如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ \Gamma(z) = \int_0^\infty t^&#123;z-1&#125;e^&#123;-t&#125;dt\,. $</span><br><span class="line">$$\Gamma(z) = \int_0^\infty t^&#123;z-1&#125;e^&#123;-t&#125;dt\,.$$</span><br></pre></td></tr></table></figure><p></p><p>让我们来看一下效果：<br>行内公式：$ \Gamma(z) = \int_0^\infty t^{z-1}e^{-t}dt\,. $<br>行间公式：</p><script type="math/tex;mode=display">\Gamma(z) = \int_0^\infty t^{z-1}e^{-t}dt\,.</script><blockquote><p>注意：使用单个$时，需要在公式两边与$之间空一格，我之前没空就一直转换不成公式的形式。</p></blockquote><p>如果你是使用hexo编写博客，那么默认的设置是无法转义markdown公式的，解决这个问题的配置方法可以参考本文顶部给出的第三个链接。<br>另外要注意，在使用公式时，对应文件需开启mathjax选项。<br><img src="/markdown20190915095628/开启mathjax.png" title="开启mathjax"><br>补充更新：在查看next主题配置文件时，我注意到next好像自带mathjax支持，设置如下，这样就无需在每个文件中添加开启mathjax的选项。<br><img src="/markdown20190915095628/mathjax支持.png" title="mathjax支持"><br>markdown公式的具体语法可以参照本文的第一个链接，你可以在typora中根据它的<a href="http://support.typora.io/Math/" target="_blank">官方文档</a>进行尝试。</p><blockquote><p>注意：在typora中，只需输入$或者$$就可直接进入公式编辑，无需输入一对。</p></blockquote><p>有机会我再对上面提到的语法进行搬运。下面介绍一种更简单省力的方法（也是我在用的方法）：</p><ol><li>打开<a href="https://www.codecogs.com/latex/eqneditor.php" target="_blank">在线LaTex公式编辑器</a></li><li>在上方的框框中输入你想要的公式：<img src="/markdown20190915095628/输入公式.png" title="输入公式"> 你可以在下方的GIF图中随时观察你的输入时候符合预期。</li><li>拷贝下方黄颜色方框中的代码到markdown文件<img src="/markdown20190915095628/拷贝.png" title="拷贝"> 你可以选择去掉前面的“\”和两边的方括号，否则你的公式两侧将会套有方括号，另外你还需要使用上文提到的$来确定公式显示方式。<br>这里我们这样输入：<code>$ x+y=z\ $</code>。<br>得到：$ x+y=z $<br>以上就是使用LaTex给markdown添加公式的方法。<br>你也可以使用黄颜色框中的URL选项来添加代码，格式是<code>![](URL)</code>。<br>例如，输入：<code>![](https://latex.codecogs.com/gif.latex?x&amp;plus;y=z)</code><br>可以看到：<img src="https://latex.codecogs.com/gif.latex?x&plus;y=z" alt><br>这种方法就不需要文章顶部链接三中的配置了，也是一种推荐的方法。</li></ol><hr><h1 id="代码高亮"><a href="#代码高亮" class="headerlink" title="代码高亮"></a>代码高亮</h1><p>markdown中使代码高亮的格式如下：<br>三个反引号+语言名<br>代码…<br>三个反引号<br>例如，输入：<br><img src="/markdown20190915095628/输入.png" title="输入"><br>可以看到：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">"hello world!"</span>)</span><br></pre></td></tr></table></figure><p></p><p>同样的，在typora中，你也不必输入成对的三个反引号。<br>这里我要提醒一个我以前用Rmarkdown时踩过的坑：<br><img src="/markdown20190915095628/坑.png" title="坑"><br>注意！他俩是不一样的！<br><img src="/markdown20190915095628/我们不一样.jpg" title="我们不一样"><br>真正的“`”在这里：<br><img src="/markdown20190915095628/在这.jpg" title="在这"></p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;在上一篇文章&lt;a href=&quot;https://gsy00517.github.io/deep-learning20190915073809/&quot; 
      
    
    </summary>
    
    
      <category term="操作与使用" scheme="https://gsy00517.github.io/categories/%E6%93%8D%E4%BD%9C%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="markdown" scheme="https://gsy00517.github.io/tags/markdown/"/>
    
  </entry>
  
  <entry>
    <title>deep learning笔记：着眼于深度——VGG简介与pytorch实现</title>
    <link href="https://gsy00517.github.io/deep-learning20190915073809/"/>
    <id>https://gsy00517.github.io/deep-learning20190915073809/</id>
    <published>2019-09-14T23:38:09.000Z</published>
    <updated>2019-11-02T02:21:55.474Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>VGG是我第一个自己编程实践的卷积神经网络，也是挺高兴的，下面我就对VGG在这篇文章中做一个分享。</p><p>本文参考自：<a href="https://blog.csdn.net/xiaohuihui1994/article/details/89207534" target="_blank" rel="noopener">https://blog.csdn.net/xiaohuihui1994/article/details/89207534</a><br><a href="https://blog.csdn.net/sinat_33487968/article/details/83584289" target="_blank" rel="noopener">https://blog.csdn.net/sinat_33487968/article/details/83584289</a></p><hr><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>VGG模型在2014年取得了ILSVRC竞赛的第二名，第一名是GoogLeNet。但是VGG在多个迁移学习任务中的表现要优于googLeNet。<br><img src="/deep-learning20190915073809/ILSVRC历年winner表现.jpg" title="ILSVRC历年winner表现"><br>相比之前的神经网路，VGG主要有两大进步：其一是它增加了深度，其二是它使用了小的3x3的卷积核，这可以使它在增加深度的时候一定程度上防止了参数的增长。缺点是它的参数量比较庞大，但这并不意味着它不值得我们仔细研究。下图展示的是VGG的结构。<br><img src="/deep-learning20190915073809/VGG结构.png" title="VGG结构"><br>为了通过对比来对VGG的一些改进进行解释，VGG的作者在论文中提供了多个版本。<br><img src="/deep-learning20190915073809/各版本VGG.png" title="各版本VGG"></p><hr><h1 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h1><p>要详细分析VGG，我可能不能像网上写的那样好，更不可能像论文一样明白。那么我在这里就先附上论文。<br><a href="1409.1556.pdf" target="_blank">论文原版</a><br><a href="VggNet中文.pdf" target="_blank">论文中文版</a><br>我在英文原版中用黄颜色高亮了我觉得比较重要的内容，大家可以参考一下。<br>大家也可以自己到网上进行搜索，这类经典的网络网上有许多介绍与分析。<br>通过论文或者网上的资源对这个网络有一定理解之后，你可以看看我下面的代码实现。</p><hr><h1 id="自己实现"><a href="#自己实现" class="headerlink" title="自己实现"></a>自己实现</h1><p>这里我使用pytorch框架来实现VGG。pytorch是一个相对较新的框架，但热度上升很快。根据网上的介绍，pytorch是一个非常适合于学习与科研的深度学习框架。我尝试了之后，也发现上手很快。<br>在pytorch中，神经网络可以通过torch.nn包来构建。这里我不一一介绍了，大家可以参考<a href="http://pytorch123.com/SecondSection/neural_networks/" target="_blank">pytorch官方中文教程</a>来学习，照着文档自己动手敲一遍之后，基本上就知道了pytorch如何使用了。<br>为了方便直观的理解，我先提供一个VGG16版本的流程图。<br><img src="/deep-learning20190915073809/VGG流程图.png" title="VGG流程图"><br>下面是我实现VGG19版本的代码：<br>首先，我们import所需的包。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br></pre></td></tr></table></figure><p></p><p>接下来，我们定义神经网络。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGG</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, num_classes = <span class="number">1000</span>)</span>:</span> <span class="comment">#imagenet图像库总共1000个类</span></span><br><span class="line">        super(VGG, self).__init__() <span class="comment">#先运行父类nn.Module初始化函数</span></span><br><span class="line">        </span><br><span class="line">        self.conv1_1 = nn.Conv2d(in_channels = <span class="number">3</span>, out_channels = <span class="number">64</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        <span class="comment">#定义图像卷积函数：输入为图像（3个频道，即RGB图）,输出为64张特征图,卷积核为3x3正方形，为保留原空间分辨率，卷积层的空间填充为1 </span></span><br><span class="line">        self.conv1_2 = nn.Conv2d(in_channels = <span class="number">64</span>, out_channels = <span class="number">64</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv2_1 = nn.Conv2d(in_channels = <span class="number">64</span>, out_channels = <span class="number">128</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        self.conv2_2 = nn.Conv2d(in_channels = <span class="number">128</span>, out_channels = <span class="number">128</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv3_1 = nn.Conv2d(in_channels = <span class="number">128</span>, out_channels = <span class="number">256</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        self.conv3_2 = nn.Conv2d(in_channels = <span class="number">256</span>, out_channels = <span class="number">256</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        self.conv3_3 = nn.Conv2d(in_channels = <span class="number">256</span>, out_channels = <span class="number">256</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        self.conv3_4 = nn.Conv2d(in_channels = <span class="number">256</span>, out_channels = <span class="number">256</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv4_1 = nn.Conv2d(in_channels = <span class="number">256</span>, out_channels = <span class="number">512</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        self.conv4_2 = nn.Conv2d(in_channels = <span class="number">512</span>, out_channels = <span class="number">512</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        self.conv4_3 = nn.Conv2d(in_channels = <span class="number">512</span>, out_channels = <span class="number">512</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        self.conv4_4 = nn.Conv2d(in_channels = <span class="number">512</span>, out_channels = <span class="number">512</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv5_1 = nn.Conv2d(in_channels = <span class="number">512</span>, out_channels = <span class="number">512</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        self.conv5_2 = nn.Conv2d(in_channels = <span class="number">512</span>, out_channels = <span class="number">512</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        self.conv5_3 = nn.Conv2d(in_channels = <span class="number">512</span>, out_channels = <span class="number">512</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        self.conv5_4 = nn.Conv2d(in_channels = <span class="number">512</span>, out_channels = <span class="number">512</span>, kernel_size = <span class="number">3</span>, padding = <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.relu = nn.ReLU(inplace = <span class="literal">True</span>) <span class="comment">#inplace=TRUE表示原地操作</span></span><br><span class="line">        self.max = nn.MaxPool2d(kernel_size = <span class="number">2</span>, stride = <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">512</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">4096</span>) <span class="comment">#定义全连接函数1为线性函数:y = Wx + b，并将512*7*7个节点连接到4096个节点上。</span></span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">4096</span>, num_classes)</span><br><span class="line">        <span class="comment">#定义全连接函数3为线性函数:y = Wx + b，并将4096个节点连接到num_classes个节点上，然后可用softmax进行处理。</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#定义该神经网络的向前传播函数，该函数必须定义，一旦定义成功，向后传播函数也会自动生成（autograd）</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        </span><br><span class="line">        x = self.relu(self.conv1_1(x))</span><br><span class="line">        x = self.relu(self.conv1_2(x))</span><br><span class="line">        x = self.max(x) </span><br><span class="line">        <span class="comment">#输入x经过卷积之后，经过激活函数ReLU，循环两次，最后使用2x2的窗口进行最大池化Max pooling，然后更新到x。</span></span><br><span class="line">        </span><br><span class="line">        x = self.relu(self.conv2_1(x))</span><br><span class="line">        x = self.relu(self.conv2_2(x))</span><br><span class="line">        x = self.max(x)</span><br><span class="line">        </span><br><span class="line">        x = self.relu(self.conv3_1(x))</span><br><span class="line">        x = self.relu(self.conv3_2(x))</span><br><span class="line">        x = self.relu(self.conv3_3(x))</span><br><span class="line">        x = self.relu(self.conv3_4(x))</span><br><span class="line">        x = self.max(x)</span><br><span class="line">        </span><br><span class="line">        x = self.relu(self.conv4_1(x))</span><br><span class="line">        x = self.relu(self.conv4_2(x))</span><br><span class="line">        x = self.relu(self.conv4_3(x))</span><br><span class="line">        x = self.relu(self.conv4_4(x))</span><br><span class="line">        x = self.max(x)</span><br><span class="line">        </span><br><span class="line">        x = self.relu(self.conv5_1(x))</span><br><span class="line">        x = self.relu(self.conv5_2(x))</span><br><span class="line">        x = self.relu(self.conv5_3(x))</span><br><span class="line">        x = self.relu(self.conv5_4(x))</span><br><span class="line">        x = self.max(x)</span><br><span class="line">        </span><br><span class="line">        x = x.view(<span class="number">-1</span>, self.num_flat_features(x)) <span class="comment">#view函数将张量x变形成一维的向量形式,总特征数并不改变,为接下来的全连接作准备。</span></span><br><span class="line">        </span><br><span class="line">        x = self.fc1(x) <span class="comment">#输入x经过全连接1，然后更新x</span></span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:]  <span class="comment">#all dimensions except the batch dimension</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line">vgg = VGG()</span><br><span class="line">print(vgg)</span><br></pre></td></tr></table></figure><p></p><p>我们print网络，可以看到输出如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">VGG(</span><br><span class="line">  (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv3_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv4_4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (conv5_4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span><br><span class="line">  (relu): ReLU(inplace=True)</span><br><span class="line">  (max): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span><br><span class="line">  (fc1): Linear(in_features=25088, out_features=4096, bias=True)</span><br><span class="line">  (fc2): Linear(in_features=4096, out_features=4096, bias=True)</span><br><span class="line">  (fc3): Linear(in_features=4096, out_features=1000, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p></p><p>最后我们随机生成一个张量来进行验证。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">input = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>)</span><br><span class="line">out = vgg(input)</span><br><span class="line">print(out)</span><br></pre></td></tr></table></figure><p></p><p>其中(1, 3, 224, 224)表示1个3x224x224的矩阵，这是因为VGG输入的是固定尺寸的224x224的RGB（三通道）图像。<br>如果没有报错，那么就说明你的神经网路可以运行通过了。<br>我们也可以使用torch.nn.functional来实现激活函数与池化层，这样的话，你需要还需要多引入一个包：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F <span class="comment">#新增</span></span><br></pre></td></tr></table></figure><p></p><p>同时，你不需要在init中实例化激活函数与最大池化层，相应的，你需要对forward前馈函数进行更改：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.conv1_1(x))</span><br><span class="line">        x = F.relu(self.conv1_2(x))</span><br><span class="line">        x = F.max_pool2d(x, kernel_size = <span class="number">2</span>, stride = <span class="number">2</span>) </span><br><span class="line">        <span class="comment">#输入x经过卷积之后，经过激活函数ReLU，循环两次，最后使用2x2的窗口进行最大池化Max pooling，然后更新到x。</span></span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.conv2_1(x))</span><br><span class="line">        x = F.relu(self.conv2_2(x))</span><br><span class="line">        x = F.max_pool2d(x, kernel_size = <span class="number">2</span>, stride = <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.conv3_1(x))</span><br><span class="line">        x = F.relu(self.conv3_2(x))</span><br><span class="line">        x = F.relu(self.conv3_3(x))</span><br><span class="line">        x = F.relu(self.conv3_4(x))</span><br><span class="line">        x = F.max_pool2d(x, kernel_size = <span class="number">2</span>, stride = <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.conv4_1(x))</span><br><span class="line">        x = F.relu(self.conv4_2(x))</span><br><span class="line">        x = F.relu(self.conv4_3(x))</span><br><span class="line">        x = F.relu(self.conv4_4(x))</span><br><span class="line">        x = F.max_pool2d(x, kernel_size = <span class="number">2</span>, stride = <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.conv5_1(x))</span><br><span class="line">        x = F.relu(self.conv5_2(x))</span><br><span class="line">        x = F.relu(self.conv5_3(x))</span><br><span class="line">        x = F.relu(self.conv5_4(x))</span><br><span class="line">        x = F.max_pool2d(x, kernel_size = <span class="number">2</span>, stride = <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        x = x.view(<span class="number">-1</span>, self.num_flat_features(x)) <span class="comment">#view函数将张量x变形成一维的向量形式,总特征数并不改变,为接下来的全连接作准备。</span></span><br><span class="line">        </span><br><span class="line">        x = self.fc1(x) <span class="comment">#输入x经过全连接1，然后更新x</span></span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p></p><p>如果你之前运行通过的话，那么这里也是没有问题的。<br>这里我想说明一下torch.nn与torch.nn.functional的区别。<br>这两个包中有许多类似的激活函数与损失函数，但是它们又有如下不同：<br>首先，在定义函数层（继承nn.Module）时，init函数中应该用torch.nn，例如torch.nn.ReLU，torch.nn.Dropout2d，而forward中应该用torch.nn.functionl，例如torch.nn.functional.relu，不过请注意，init里面定义的是标准的网络层。只有torch.nn定义的才会进行训练。torch.nn.functional定义的需要自己手动设置参数。所以通常，激活函数或者卷积之类的都用torch.nn定义。<br>另外，torch.nn是类，必须要先在init中实例化，然后在forward中使用，而torch.nn.functional可以直接在forward中使用。<br>大家还可以通过官方文档<a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/functional/" target="_blank">torch.nn.functional</a>与<a href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-nn/" target="_blank">torch.nn</a>来进一步了解两者的区别。<br>大家或许发现，我的代码中有大量的重复性工作。是的，你将在文章后面的官方实现中看到优化的代码，但是相对来说，我的代码更加直观些，完全是按照网络的结构顺序从上到下编写的，可以方便初学者（including myself）的理解。</p><hr><h1 id="出现的问题"><a href="#出现的问题" class="headerlink" title="出现的问题"></a>出现的问题</h1><p>虽然我的代码比较简单直白，但是过程中并不是一帆风顺的，出现了两次报错：</p><ol><li><h2 id="输入输出不匹配"><a href="#输入输出不匹配" class="headerlink" title="输入输出不匹配"></a>输入输出不匹配</h2>当我第一遍运行时，出现了一个RuntimeError：<img src="/deep-learning20190915073809/报错1.png" title="报错1"> 这是一个超级低级的错误，经学长提醒后我才发现，我两个卷积层之间输出输入的channel数并不匹配：<img src="/deep-learning20190915073809/错误原因.png" title="错误原因"> 唉又是ctrl+C+V惹的祸，改正后的网络可以参见上文。<br>在这里，我想提醒我自己和大家注意一下卷积层输入输出的维度公式：<br>假设输入的宽、高记为W、H。<br>超参数中，卷积核的维度是F，stride步长是S，padding是P。<br>那么输出的宽X与高Y可用如下公式表示：<script type="math/tex;mode=display">X=\frac{W+2P-F}{S}+1\</script><script type="math/tex;mode=display">Y=\frac{H+2P-F}{S}+1\</script>然而，当我在计算ResNet的维度的时候，发现套用这个公式是除不尽的。于是我搜索到了如下规则：<br>1.对卷积层操作，除不尽时，向下取整。<br>2.对池化层操作，除不尽时，向上取整。</li><li><h2 id="没有把张量转化成一维向量"><a href="#没有把张量转化成一维向量" class="headerlink" title="没有把张量转化成一维向量"></a>没有把张量转化成一维向量</h2>上面的问题解决了，结果还有错误：<img src="/deep-learning20190915073809/报错2.png" title="报错2"> 根据报错，可以发现3584x7是等于25088的，结合pytorch官方文档，我意识到我在把张量输入全连接层时，没有把它拍扁成一维。因此，我按照官方文档添加了如下代码：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">x = x.view(<span class="number">-1</span>, self.num_flat_features(x))</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span><span class="params">(self, x)</span>:</span></span><br><span class="line">    size = x.size()[<span class="number">1</span>:]  <span class="comment">#all dimensions except the batch dimension</span></span><br><span class="line">    num_features = <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">        num_features *= s</span><br><span class="line">    <span class="keyword">return</span> num_features</span><br></pre></td></tr></table></figure></li></ol><p>再运行，问题解决。<br>另外，我原本写的代码中，在卷积层之间的对应位置都加上了relu激活函数与池化层。后来我才意识到，由于它们不具有任何需要学习的参数，我可以直接把它们拿出来单独定义：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.relu = nn.ReLU(inplace = <span class="literal">True</span>)</span><br><span class="line">self.max = nn.MaxPool2d(kernel_size = <span class="number">2</span>, stride = <span class="number">2</span>)</span><br></pre></td></tr></table></figure><p></p><p>虽然是一些很低级的坑，但我还是想写下来供我自己和大家今后参考。</p><hr><h1 id="官方源码"><a href="#官方源码" class="headerlink" title="官方源码"></a>官方源码</h1><p>由于VGG的结构设计非常有规律，因此官方源码给出了更简洁的版本：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VGG</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, features, num_classes=<span class="number">1000</span>, init_weights=True)</span>:</span></span><br><span class="line">        super(VGG, self).__init__()</span><br><span class="line">        self.features = features</span><br><span class="line">        self.classifier = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">512</span> * <span class="number">7</span> * <span class="number">7</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, num_classes),</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">if</span> init_weights:</span><br><span class="line">            self._initialize_weights()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.features(x)</span><br><span class="line">        x = x.view(x.size(<span class="number">0</span>), <span class="number">-1</span>)</span><br><span class="line">        x = self.classifier(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_initialize_weights</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> isinstance(m, nn.Conv2d):</span><br><span class="line">                n = m.kernel_size[<span class="number">0</span>] * m.kernel_size[<span class="number">1</span>] * m.out_channels</span><br><span class="line">                m.weight.data.normal_(<span class="number">0</span>, math.sqrt(<span class="number">2.</span> / n))</span><br><span class="line">                <span class="keyword">if</span> m.bias <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">                    m.bias.data.zero_()</span><br><span class="line">            <span class="keyword">elif</span> isinstance(m, nn.BatchNorm2d):</span><br><span class="line">                m.weight.data.fill_(<span class="number">1</span>)</span><br><span class="line">                m.bias.data.zero_()</span><br><span class="line">            <span class="keyword">elif</span> isinstance(m, nn.Linear):</span><br><span class="line">                m.weight.data.normal_(<span class="number">0</span>, <span class="number">0.01</span>)</span><br><span class="line">                m.bias.data.zero_()</span><br></pre></td></tr></table></figure><p></p><p>因为VGG中卷积层的重复性比较高，所以官方使用一个函数来循环产生卷积层：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">make_layers</span><span class="params">(cfg, batch_norm=False)</span>:</span></span><br><span class="line">    layers = []</span><br><span class="line">    in_channels = <span class="number">3</span></span><br><span class="line">    <span class="keyword">for</span> v <span class="keyword">in</span> cfg:</span><br><span class="line">        <span class="keyword">if</span> v == <span class="string">'M'</span>:</span><br><span class="line">            layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conv2d = nn.Conv2d(in_channels, v, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> batch_norm:</span><br><span class="line">                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [conv2d, nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">            in_channels = v</span><br><span class="line">    <span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure><p></p><p>接下来定义各个版本的卷积层（可参考上文中对论文的截图），这里的“M”表示的是最大池化层。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">cfg = &#123;</span><br><span class="line">    <span class="string">'A'</span>: [<span class="number">64</span>, <span class="string">'M'</span>, <span class="number">128</span>, <span class="string">'M'</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>],</span><br><span class="line">    <span class="string">'B'</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">'M'</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">'M'</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>],</span><br><span class="line">    <span class="string">'D'</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">'M'</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">'M'</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>],</span><br><span class="line">    <span class="string">'E'</span>: [<span class="number">64</span>, <span class="number">64</span>, <span class="string">'M'</span>, <span class="number">128</span>, <span class="number">128</span>, <span class="string">'M'</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">'M'</span>],</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg11</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">'A'</span>]), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg11_bn</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">'A'</span>], batch_norm=<span class="literal">True</span>), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg13</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">'B'</span>]), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg13_bn</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">'B'</span>], batch_norm=<span class="literal">True</span>), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg16</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">'D'</span>]), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg16_bn</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">'D'</span>], batch_norm=<span class="literal">True</span>), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg19</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">'E'</span>]), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vgg19_bn</span><span class="params">(**kwargs)</span>:</span></span><br><span class="line">    model = VGG(make_layers(cfg[<span class="string">'E'</span>], batch_norm=<span class="literal">True</span>), **kwargs)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment"># 'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19_bn', 'vgg19'</span></span><br><span class="line">    <span class="comment"># Example</span></span><br><span class="line">    net11 = vgg11()</span><br><span class="line">    print(net11)</span><br></pre></td></tr></table></figure><p></p><p>附上pytorch官方源码<a href="https://github.com/pytorch/vision" target="_blank">链接</a>。可以在vision/torchvision/models/下找到一系列用pytorch实现的经典神经网路模型。<br>好了，以上就是VGG的介绍与实现，如有不足之处欢迎大家补充！</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;VGG是我第一个自己编程实践的卷积神经网络，也是挺高兴的，下面我就对VGG在这篇文章中做一个分享。&lt;/p&gt;&lt;p&gt;本文参考自：&lt;a href=&quot;h
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://gsy00517.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="深度学习" scheme="https://gsy00517.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文分享" scheme="https://gsy00517.github.io/tags/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
      <category term="代码实现" scheme="https://gsy00517.github.io/tags/%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    
      <category term="pytorch" scheme="https://gsy00517.github.io/tags/pytorch/"/>
    
  </entry>
  
  <entry>
    <title>deep learning笔记：一篇非常经典的论文——NatureDeepReview</title>
    <link href="https://gsy00517.github.io/deep-learning20190914142553/"/>
    <id>https://gsy00517.github.io/deep-learning20190914142553/</id>
    <published>2019-09-14T06:25:53.000Z</published>
    <updated>2019-11-02T02:21:47.317Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>这是一篇非常经典的有关深度学习的论文，最近在看一个网课的时候又被提到了，因此特地找了pdf文档放在这里和大家分享。</p><hr><h1 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h1><p>这篇文章首先介绍了深度学习的基本前期储备知识、发展背景，并对机器学习范畴内一个重要方向——监督学习进行完整介绍，然后介绍了反向传播算法和微积分链式法则等深度学习基础内容。<br>文章的接下来重点介绍了卷积神经网络CNN的实现过程、几个非常重要的经典卷积神经网络以及深度卷积神经网络对于视觉任务理解的应用。<br>文章最后探讨了分布表示和语言模型，循环神经网络RNN原理以及对未来的展望和现实的实现。<br>总而言之，我觉得这是一篇值得逐字逐句反复阅读咀嚼的文章，读完这篇文章，大概就相当于打开了深度学习的大门了吧。<br>这篇文章的个人理解与感悟或许我以后会补上，在接触还不深的情况下我不说废话啦，先附上原文，其中黄色高亮部分是一些比较重要的内容，大家有时间的话可以认真看一下。<br>下面附上<a href="NatureDeepReview.pdf" target="_blank">原文链接</a>。<br>最后贴一张我觉得挺搞笑的图。<br><img src="/deep-learning20190914142553/什么是深度学习.jpg" title="什么是深度学习"><br>这张图片还有张兄弟图，可以看看我的另一篇论文分享<a href="https://gsy00517.github.io/artificial-intelligence20191001101334/" target="_blank">artificial-intelligence笔记：人工智能前沿发展情况分享</a>。</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;这是一篇非常经典的有关深度学习的论文，最近在看一个网课的时候又被提到了，因此特地找了pdf文档放在这里和大家分享。&lt;/p&gt;&lt;hr&gt;&lt;h1 id=
      
    
    </summary>
    
    
      <category term="人工智能" scheme="https://gsy00517.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"/>
    
    
      <category term="深度学习" scheme="https://gsy00517.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="论文分享" scheme="https://gsy00517.github.io/tags/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu笔记：重装ubuntu——记一段辛酸血泪史</title>
    <link href="https://gsy00517.github.io/ubuntu20190914100050/"/>
    <id>https://gsy00517.github.io/ubuntu20190914100050/</id>
    <published>2019-09-14T02:00:50.000Z</published>
    <updated>2019-11-02T02:23:20.209Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>这是不久前我踩过的一个巨坑，在这里我想先强调一下：<br><strong>不要升级linux发行版！！！重要的事情说三遍！！！</strong><br><strong>不要升级linux发行版！！！重要的事情说三遍！！！</strong><br><strong>不要升级linux发行版！！！重要的事情说三遍！！！</strong><br>为什么？不要问我为什么。我按系统提示升级ubuntu到18.04LTS后，就再也进不去系统了。不信你可以尝试一下，你将会看到如下界面：<br><img src="/ubuntu20190914100050/一点都不OK！.jpg" title="一点都不OK！"></p><blockquote><p>注：图片来自网络，我就不再为了截图而踩一次坑了。</p></blockquote><p>不仅是图形界面，命令行界面也进不去了（据说可以在重启时选择recovery mode并且狂按回车强行进入界面，但我失败了）。<br>不过如果你真的尝试了并且掉坑里了的话，没关系，你获得了一个很好的重装系统的锻炼机会。下面我们就按步骤锻炼一下。</p><p>本文参考自：<a href="https://blog.csdn.net/Spacegene/article/details/86659349" target="_blank" rel="noopener">https://blog.csdn.net/Spacegene/article/details/86659349</a></p><hr><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><ol><li><h2 id="U盘"><a href="#U盘" class="headerlink" title="U盘"></a>U盘</h2>准备一个2G以上的无用的U盘，或者备份好里面的文件。然后将其格式化。</li><li><h2 id="镜像"><a href="#镜像" class="headerlink" title="镜像"></a>镜像</h2>下载<a href="http://releases.ubuntu.com/16.04/ubuntu-16.04.6-desktop-amd64.iso" target="_blank">ubuntu16.04LTS镜像</a>到本地。</li><li><h2 id="删除分区"><a href="#删除分区" class="headerlink" title="删除分区"></a>删除分区</h2><p>你可以通过控制面板中的创建并格式化硬盘分区来看到你的windows与ubuntu分区的情况。（以下操作都是针对重装，不再重新分区，需要的可以自行上网查找教程）<br>在重新安装ubuntu16.04之前我们需要删除原先Ubuntu的EFI分区及启动引导项，这里推荐直接使用windows下的diskpart来删除。<br>使用win+R输入diskpart打开diskpart.exe，允许其对设备进行更改。</p><img src="/ubuntu20190914100050/diskpart.png" title="diskpart"><p>接下来使用如下命令查看分区，我的笔记本只有一块SSD，两个系统都装在上面，故进入disk 0。</p><img src="/ubuntu20190914100050/查看分区信息.png" title="查看分区信息"><p>其中类型未知的便是分给ubuntu的分区，我这里有一块8G的swap分区和60G的/分区。<br>接下来执行如下命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select partition 7</span><br><span class="line">delete partition override #删除该分区</span><br><span class="line">select partition 8</span><br><span class="line">delete partition override #删除该分区</span><br></pre></td></tr></table></figure><blockquote><p>注意：以上命令是针对我的情况，具体请按照对应ubuntu分区的序号删除。</p></blockquote><p>现在你可以在控制面板中的创建并格式化硬盘分区中看到你删除的分区已经合并成一块未分配的空间，这也意味着你与你原来ubuntu上的数据彻底说再见了。</p></li><li><h2 id="删除ubuntu启动引导项"><a href="#删除ubuntu启动引导项" class="headerlink" title="删除ubuntu启动引导项"></a>删除ubuntu启动引导项</h2>首先下载<a href="https://www.easyuefi.com/index-us.html" target="_blank">EasyUEFI</a>，使用免费试用版即可。<br>下载完成后安装，打开EasyUEFI如图：<img src="/ubuntu20190914100050/EasyUEFI.png" title="EasyUEFI"> 选择管理EFI启动选项Manage EFI Boot Option，然后选择ubuntu启动引导项，点击中间的删除按钮来删除该引导项。<br>现在重新启动，你会发现已经没有让你选择系统的引导界面，而是直接进入windows系统。</li><li><h2 id="制作启动U盘"><a href="#制作启动U盘" class="headerlink" title="制作启动U盘"></a>制作启动U盘</h2>首先我们下载一个免费的U盘制作工具<a href="https://rufus.ie/" target="_blank">rufus</a>。<br>此时插入已经格式化的U盘，打开rufus，一般情况下它会自动选择U盘，你也可以在device选项下手动选择或确认。<br>点击select，选择之前下载好的镜像文件。<br>其他设置保留默认即可，不放心的话可以比对下图：<img src="/ubuntu20190914100050/rufus.png" title="rufus"> 然后start开始制作。如果此时rufus提示需要下载一些其它文件，选择Yes继续即可。<br>没有问题的话制作完的U盘会如图所示：<img src="/ubuntu20190914100050/此时的U盘.png" title="此时的U盘"> 在下面的步骤中，请一直插着U盘不要拔。</li></ol><hr><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>现在重新启动电脑，开机的过程中不停地快按F12进入bios界面（我的是戴尔的电脑，不同电脑按键或有不同，自行百度；如果快按不行的话再次重启试一试长按，因为网上有些教程说的是长按，而我是长按不行而快按可以）。<br>随后选择U盘启动（不同电脑这个界面也可能不一样，具体可以百度，印象中是选择UEFI BOOT中UEFI：U盘名那项）。<br>接下来就进入了紫红色的GNU GRUB界面，选择install ubuntu。<br>随后就是些比较简单的安装过程，基本上可以按默认进行，因为是重装，好像不需要联网安装且有汉化包。<br>接下来是比较重要的部分：<br>进入安装类型installation type界面后，选择其他选项something else，这样我们就可以自己配置ubuntu分区了，点击继续。<br>接下来会进入一个磁盘分区的界面，选中之前清出来的未分配分区（名为“空闲”，也可以通过大小来判断），点击下方+号，新建一个swap分区，大小为8G左右（一般和电脑的内存相当即可，具体还有待研究，不分这个区会有警告）。<br>再次双击空闲分区，挂载点下拉，选择/。<br>在安装启动引导器的设备选项中，选择Windows boot manager。<br>结果可以参考下图：<br><img src="/ubuntu20190914100050/ubuntu分区.jpg" title="ubuntu分区"><br>确认无误后点击现在安装，然后就一路默认直到安装完成。</p><hr><h1 id="后期"><a href="#后期" class="headerlink" title="后期"></a>后期</h1><p>别忘了把U盘格式化回来，可以继续使用，留着做纪念也行，说不定哪天又要重装。<br>下面我展示一下我目前的一部分美化效果，亲测发现这只会牺牲一点点儿CPU，所以并不用担心，大胆地美化就是，可能这也是使用linux发行版不多的几种乐趣之一吧。<br><img src="/ubuntu20190914100050/桌面.png" title="桌面"><br><img src="/ubuntu20190914100050/桌面立方体.png" title="桌面立方体"><br><img src="/ubuntu20190914100050/选择窗口.png" title="选择窗口"><br><img src="/ubuntu20190914100050/移动窗口.png" title="移动窗口"><br><img src="/ubuntu20190914100050/最小化窗口.png" title="最小化窗口"><br>以上就是重装ubuntu的全部内容，由于是基于几天前的回忆可能会有疏漏，欢迎补充！我也会在新问题出现时及时更新。</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;这是不久前我踩过的一个巨坑，在这里我想先强调一下：&lt;br&gt;&lt;strong&gt;不要升级linux发行版！！！重要的事情说三遍！！！&lt;/strong&gt;
      
    
    </summary>
    
    
      <category term="操作与使用" scheme="https://gsy00517.github.io/categories/%E6%93%8D%E4%BD%9C%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="ubuntu" scheme="https://gsy00517.github.io/tags/ubuntu/"/>
    
      <category term="安装教程" scheme="https://gsy00517.github.io/tags/%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"/>
    
      <category term="个人经历" scheme="https://gsy00517.github.io/tags/%E4%B8%AA%E4%BA%BA%E7%BB%8F%E5%8E%86/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu笔记：释放空间</title>
    <link href="https://gsy00517.github.io/ubuntu20190914094853/"/>
    <id>https://gsy00517.github.io/ubuntu20190914094853/</id>
    <published>2019-09-14T01:48:53.000Z</published>
    <updated>2019-11-02T02:23:13.857Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>前一篇讲了如何清理windows下的空间，然而虽然ubuntu中垃圾文件没win10那么多，可是我给ubuntu分配的空间比win10少得多了，于是我又找了些清理ubuntu的方法。</p><hr><h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><ol><li><h2 id="删除apt-get下载的软件包"><a href="#删除apt-get下载的软件包" class="headerlink" title="删除apt-get下载的软件包"></a>删除apt-get下载的软件包</h2>直接在终端执行<code>sudo apt-get autoclean</code></li><li><h2 id="删除缓存的所有软件包"><a href="#删除缓存的所有软件包" class="headerlink" title="删除缓存的所有软件包"></a>删除缓存的所有软件包</h2><code>sudo apt-get clean</code></li><li><h2 id="删除其他软件依赖的但现在已不用的软件包"><a href="#删除其他软件依赖的但现在已不用的软件包" class="headerlink" title="删除其他软件依赖的但现在已不用的软件包"></a>删除其他软件依赖的但现在已不用的软件包</h2><code>sudo apt-get autoremove</code><br>这条命令执行后，软件的配置文件还是会保留的。</li><li><h2 id="清除所有已删除包的残余配置文件"><a href="#清除所有已删除包的残余配置文件" class="headerlink" title="清除所有已删除包的残余配置文件"></a>清除所有已删除包的残余配置文件</h2><code>dpkg -l |grep ^rc|awk &#39;{print $2}&#39; |sudo xargs dpkg -P</code><br>这时候如果出现如下错误，那无需担心，因为已经不存在残余的配置文件了。<img src="/ubuntu20190914094853/已无残余文件.png" title="已无残余文件"> 可以把上面四个命令按顺序执行一遍，就完成了对ubuntu系统的空间释放。</li></ol><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;前一篇讲了如何清理windows下的空间，然而虽然ubuntu中垃圾文件没win10那么多，可是我给ubuntu分配的空间比win10少得多了，
      
    
    </summary>
    
    
      <category term="操作与使用" scheme="https://gsy00517.github.io/categories/%E6%93%8D%E4%BD%9C%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="命令操作" scheme="https://gsy00517.github.io/tags/%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/"/>
    
      <category term="ubuntu" scheme="https://gsy00517.github.io/tags/ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>windows笔记：释放空间</title>
    <link href="https://gsy00517.github.io/windows20190914091023/"/>
    <id>https://gsy00517.github.io/windows20190914091023/</id>
    <published>2019-09-14T01:10:23.000Z</published>
    <updated>2019-11-02T02:23:25.720Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>暑假里想跑CVPR中的代码，发现作者提供的环境配置都是基于linux终端的，这样windows的git bash就满足不了我了。二话不说我花了两天时间装了个ubuntu+windows双系统，好不容易装好了，却发现我的硬盘空间已经岌岌可危（理论上要留内存的三倍左右可以保证系统顺畅运行，我的内存是8G，也就是说我C盘应空出20G左右为宜）。于是我就找了些释放空间的办法，分享在这里。</p><p>本文参考自：<a href="http://www.udaxia.com/wtjd/9147.html" target="_blank" rel="noopener">http://www.udaxia.com/wtjd/9147.html</a></p><hr><h1 id="利用磁盘属性进行清理"><a href="#利用磁盘属性进行清理" class="headerlink" title="利用磁盘属性进行清理"></a>利用磁盘属性进行清理</h1><p>这是最稳的方法，但释放的空间也相对较少，不过还是有效的。选择“此电脑”，右键C盘，属性，然后就可以在常规下面看到磁盘清理。一般按默认选择的进行清理，当然全点上勾也无所谓。<br><img src="/windows20190914091023/磁盘清理.png" title="磁盘清理"></p><blockquote><p>注意：千万不能选择压缩此驱动器以节约磁盘空间！</p></blockquote><p>另外在工具下面你可以看到一个优化的选项，一般系统会定期自动执行优化，如果你是强迫症，时时刻刻都容不得一点冗余的话，可以手动优化。<br><img src="/windows20190914091023/优化.png" title="优化"><br>据我们数据结构的老师说，由于数据在存储时大多是稀疏矩阵，存在许多的空间浪费，而磁盘碎片整理优化的就是这个。</p><hr><h1 id="清理系统文件"><a href="#清理系统文件" class="headerlink" title="清理系统文件"></a>清理系统文件</h1><p>在前面的磁盘清理界面中我们还可以看到清理系统文件这一选项，可以选择它进行进一步清理，这里面有一项是以前的windows安装文件，如果不打算回退的话清理无妨。<br><img src="/windows20190914091023/清理系统文件.png" title="清理系统文件"><br>有可能你还会注意到一个名为“系统错误内存转储文件”的选项，这个也可以大胆清除，对一般使用者（基本不需排查系统问题）这个文件完全没有任何作用。<br><img src="/windows20190914091023/系统错误内存转储文件.png" title="系统错误内存转储文件"><br>对于防止系统错误内存转储文件占用空间，还有一劳永逸直接禁止生成的办法，首先打开高级系统设置，来到如图所示选项卡。<br><img src="/windows20190914091023/高级系统设置.png" title="高级系统设置"><br>打开“启动和故障修复”设置窗口，在写入调试信息的下拉列表中选择“无”并确定即可。<br><img src="/windows20190914091023/禁止生成.png" title="禁止生成"><br>当然，如果你觉得你或许用得上系统错误内存转储文件，那么也可以选择这里的小内存转储或者核心内存转储，这样同样也能节省空间。<br>清理系统文件是给windows10瘦身最有效的办法之一，事实上，若无特殊需求，扫描结果中的文件均可以勾选清除。</p><hr><h1 id="删除临时文件"><a href="#删除临时文件" class="headerlink" title="删除临时文件"></a>删除临时文件</h1><p>这里有两个临时文件中的全部文件可以删除，一个是C:\Users\用户名\AppData\Local\Temp目录下的文件，这里是临时文件最多的地方，可以上到几个G；另一个是C:\Windows\Temp，这里文件大小相对较小，可以忽略不计。另外我也找到了一些其他的临时文件，但似乎它们的体积都是0，可能是系统自动清理了。</p><blockquote><p>注意：千万不要误删上一级目录！如果担心删除出错，可先放到回收站，重启之后看有无异常再做决定。亲测上述两个文件夹中的所有文件均可删除。</p></blockquote><hr><h1 id="删除冗余更新"><a href="#删除冗余更新" class="headerlink" title="删除冗余更新"></a>删除冗余更新</h1><p>众所周知，windows系统会自动更新，这也是许多人弃windows的一大原因，然而windows还是要用的，于是我找到了一种可以清理多余的windows更新文件的方法。</p><ol><li>首先右键左下角开始菜单，选择“Windows PowerShell（管理员）”<img src="/windows20190914091023/powershell.png" title="powershell"> 弹出是否允许进行更改选择“是”。</li><li>输入命令<code>dism.exe /Online /Cleanup-Image /AnalyzeComponentStore</code></li><li>这时候会显示“推荐使用组件存储清理：是or否”，因为我前不久清过，所以这里显示为“否”，那么就别清理了。如果显示为“是”，那么进行第四步。<img src="/windows20190914091023/输出.png" title="输出"></li><li>输入命令<code>dism.exe /online /Cleanup-Image /StartComponentCleanup</code><br>这样电脑就会开始清理啦。这个过程会比较长，不要着急和担心，在这期间你可以做些别的事情，比如看看我其他的几篇博客。</li></ol><hr><h1 id="重装系统"><a href="#重装系统" class="headerlink" title="重装系统"></a>重装系统</h1><p>俗话说得好“大力出奇迹”，重装系统无疑是最有效清理空间的一种方法。只要备份好数据，重装其实没有想象的那么困难。我本人这一年多来就重装过3次系统(两次是被迫的…)，其实装了几次就熟练了，我曾看到某linux大牛（忘了是谁）总共重装了19次linux。你可以在我的另一篇博文<a href="https://gsy00517.github.io/ubuntu20190914100050/" target="_blank">ubuntu笔记：重装ubuntu——记一次辛酸血泪史</a>中看到如何在双系统情况下重装ubuntu的过程。</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;暑假里想跑CVPR中的代码，发现作者提供的环境配置都是基于linux终端的，这样windows的git bash就满足不了我了。二话不说我花了两
      
    
    </summary>
    
    
      <category term="操作与使用" scheme="https://gsy00517.github.io/categories/%E6%93%8D%E4%BD%9C%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="命令操作" scheme="https://gsy00517.github.io/tags/%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/"/>
    
      <category term="windows" scheme="https://gsy00517.github.io/tags/windows/"/>
    
  </entry>
  
  <entry>
    <title>html笔记：制作web时的一些小技巧与小问题</title>
    <link href="https://gsy00517.github.io/html20190914080224/"/>
    <id>https://gsy00517.github.io/html20190914080224/</id>
    <published>2019-09-14T00:02:24.000Z</published>
    <updated>2019-11-02T02:22:23.903Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>大一有一段时间，我沉迷于web前端制作网页，比较熟练地掌握了html的语法，还根据需要接触了一些CSS以及js的内容。说白了，html只是一种标记语言（不属于编程语言），但是它简单易学，且很容易获得可视化的效果，对于培养兴趣而言我感觉是很有帮助的。油管up主，现哈佛在读学霸<a href="https://www.youtube.com/channel/UC5Gmg-VtFmnP8qLq8V7Pvtg" target="_blank">John Fish</a>（请科学上网）当初就是从html进入计算机世界的。下面贴一个我自己做的网页，是综合web三大语言编写的，大一的时候把自己需要的网站都放上面了，也有一种归属感吧。<br><img src="/html20190914080224/前端三大语言.jpg" title="前端三大语言"><br><img src="/html20190914080224/大一做的简单网页.png" title="大一做的简单网页"><br><img src="/html20190914080224/打开菜鸟教程.png" title="打开菜鸟教程"><br>主页上那个是python之禅，也是我很喜欢的一段文字，在python环境下import this就可以看到。由于上面的网页是我学web的时候边看书边编的，各种元素都尝试了一下，最后也没有美化一直到现在，所以大佬们勿喷哈。</p><hr><h1 id="小技巧"><a href="#小技巧" class="headerlink" title="小技巧"></a>小技巧</h1><p>我这里强烈推荐使用VScode写前端，它有很多强大的插件，我这里推荐其中一个吧。<br><img src="/html20190914080224/推荐插件.png" title="推荐插件"><br>如介绍所写，使用alt+B快捷键可以直接在默认浏览器下查看你写的网页，而shift+alt+B可以选浏览器查看，因为有些时候microsoft自带的edge浏览器无法实现你编写的效果（巨坑），推荐使用chrome打开浏览。使用这个插件能让你更快捷地预览你编写的效果并进行修改，大大提高了效率。<br>其他的插件网上有很多推荐，也等待着你自己去发现，这里就不一一列出了。<br>还有一个快捷的操作就是快速生成代码块，在VScode中是这样操作的（其他编辑器也应该类似）：</p><ol><li>输入一个！：<img src="/html20190914080224/输入！.png" title="输入！"></li><li>按tab键或者回车：<img src="/html20190914080224/快速生成.png" title="快速生成"> 这样就可以节省很多时间，非常方便。</li></ol><hr><h1 id="小问题"><a href="#小问题" class="headerlink" title="小问题"></a>小问题</h1><p>在我想使用web来打开我本地的txt文件时，我遇到过这样一个问题：打开的中文文档在浏览器中显示为乱码。在尝试其他浏览器后，我发现这不是浏览器的问题。最后我大致找到了两种解决办法：</p><ol><li>一种是找到head下面的meta charset，修改代码如下：<img src="/html20190914080224/解决方法1.png" title="解决方法1"></li><li>另一种是另存为文件时修改一下格式，这里我们修改成“UTF-8”。另外我室友在使用python导入文件的时候也因为格式导致报错，修改成ANSI后即可。<img src="/html20190914080224/解决方法2.png" title="解决方法2"> 希望通过上面两种方法的尝试能让你解决乱码问题，几种编码格式的区别在这里暂不说明，以后有空补上。</li></ol><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;大一有一段时间，我沉迷于web前端制作网页，比较熟练地掌握了html的语法，还根据需要接触了一些CSS以及js的内容。说白了，html只是一种标
      
    
    </summary>
    
    
      <category term="编程及环境" scheme="https://gsy00517.github.io/categories/%E7%BC%96%E7%A8%8B%E5%8F%8A%E7%8E%AF%E5%A2%83/"/>
    
    
      <category term="前端" scheme="https://gsy00517.github.io/tags/%E5%89%8D%E7%AB%AF/"/>
    
  </entry>
  
  <entry>
    <title>anaconda笔记：conda的各种命令行操作</title>
    <link href="https://gsy00517.github.io/anaconda20190913231748/"/>
    <id>https://gsy00517.github.io/anaconda20190913231748/</id>
    <published>2019-09-13T15:17:48.000Z</published>
    <updated>2019-11-02T02:20:50.487Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>anaconda是一个开源的包、环境管理器，可以比较有效地配置多个虚拟环境，当python入门到一定程度时，安装anaconda是很必要的。前段时间室友学习python的时候问到过我一些相关的问题，我就在这里简单写一些我知道的以及我搜集到的知识。</p><hr><h1 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h1><p>安装anaconda过程中一个很重要的步骤就是配置环境变量，网上有很多手动添加环境变量的教程，其实很简单，只需添加三个路径，当然更简单的是直接在安装的时候添加到path（可以无视warning）。我想在这里写的是环境变量的概念问题，其实直到不久前帮同学安装我才明白。<br>环境变量是指在操作系统中用来指定操作系统运行环境的一些参数。当要求系统运行一个程序而没有告诉它程序所在的完整路径时，系统除了在当前目录下面寻找此程序外，还会到path中指定的路径去找。这就是为什么不添加C:\Users\用户名\Anaconda3\Scripts到path就无法执行conda命令，因为此时conda.exe无法被找到。</p><hr><h1 id="conda与pip"><a href="#conda与pip" class="headerlink" title="conda与pip"></a>conda与pip</h1><p>利用conda install与pip install命令来安装各种包的过程中，想必你也对两者之间的区别很疑惑，下面我就总结一下我搜集到的相关解答。<br>简而言之，pip是python包的通用管理器，而conda是一个与语言无关的跨平台环境管理器。对我们而言，最显着的区别可能是这样的：pip在任何环境中安装python包，conda安装在conda环境中装任何包。因此往往conda list的数量会大于pip list。<br>要注意的是，如果使用conda install多个环境时，对于同一个包只需要安装一次，有conda集中进行管理。<br>但是如果使用pip，因为每个环境安装使用的pip在不同的路径下，故会重复安装，而包会从缓存中取。<br>总的来说，我推荐尽早安装anaconda并且使用conda来管理python的各种包。</p><hr><h1 id="升级"><a href="#升级" class="headerlink" title="升级"></a>升级</h1><p>我们可以在命令行中或者anaconda prompt中执行命令进行操作。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda update conda #升级conda</span><br><span class="line">conda update anaconda #升级anaconda前要先升级conda</span><br><span class="line">conda update --all #升级所有包</span><br></pre></td></tr></table></figure><p></p><p>在升级完成之后，我们可以使用命令来清理一些无用的包以释放一些空间：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda clean -p #删除没有用的包</span><br><span class="line">conda clean -t #删除保存下来的压缩文件（.tar）</span><br></pre></td></tr></table></figure><p></p><hr><h1 id="虚拟环境"><a href="#虚拟环境" class="headerlink" title="虚拟环境"></a>虚拟环境</h1><p>conda list命令用于查看conda下的包，而conda env list命令可以用来查看conda创建的所有虚拟环境。<br><img src="/anaconda20190913231748/conda环境列表.png" title="conda环境列表"><br>下面就简述一下如何创建这些虚拟环境。<br>使用如下命令，可以创建一个新的环境：<br><code>conda create -n Python27 python=2.7</code><br>其中Python27是自定义的一个名称，而python=2.7是一个格式，可以变动等号右边的数字来改变python环境的kernel版本，这里我们安装的是python2.7版本（将于2020年停止维护）。<br>在anaconda prompt中，我们可以看到我们处在的是base环境下，也就是我安装的python3环境下，我们可以使用下面两个命令来切换环境：<br><img src="/anaconda20190913231748/虚拟环境切换.png" title="虚拟环境切换"><br>在创建环境的过程中，难免会不小心取了个难听的环境名，别担心，我们有方法来删除环境。<br><code>conda remove -n 难听的名字 --all</code><br>有时候一个环境已经配置好了，但我们想要重命名，这怎么办呢？可以这样办：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">conda create -n 新名字 --clone 老名字</span><br><span class="line">conda remove -n 老名字 --all</span><br></pre></td></tr></table></figure><p></p><hr><h1 id="把环境添加到jupyter-notebook"><a href="#把环境添加到jupyter-notebook" class="headerlink" title="把环境添加到jupyter notebook"></a>把环境添加到jupyter notebook</h1><p>首先通过activate进入想要添加的环境中，然后安装ipykernel，接下来就可以进行添加了。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip install ipykernel</span><br><span class="line">python -m ipykernel install --name Python27 #Python27可以取与环境名不一样的名字，但方便起见建议统一</span><br></pre></td></tr></table></figure><p></p><p>我们可以使用如下命令来查看已添加到jupyter notebook的kernel：<br><code>jupyter kernelspec list</code><br>显示如下：<br><img src="/anaconda20190913231748/查看kernel.png" title="查看kernel"><br>我们也可以在jupyter notebook中的new或者kernel下查看新环境是否成功添加。<br>在这里我想说明一下为什么要分开python的环境。<br>由于python是不向后兼容的，分开环境可以避免语法版本不一引起的错误，同时这也可以避免工具包安装与调用的混乱。</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;anaconda是一个开源的包、环境管理器，可以比较有效地配置多个虚拟环境，当python入门到一定程度时，安装anaconda是很必要的。前段
      
    
    </summary>
    
    
      <category term="编程及环境" scheme="https://gsy00517.github.io/categories/%E7%BC%96%E7%A8%8B%E5%8F%8A%E7%8E%AF%E5%A2%83/"/>
    
    
      <category term="命令操作" scheme="https://gsy00517.github.io/tags/%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>jupyter notebook笔记：一些细小的操作</title>
    <link href="https://gsy00517.github.io/jupyter-notebook20190913225022/"/>
    <id>https://gsy00517.github.io/jupyter-notebook20190913225022/</id>
    <published>2019-09-13T14:50:22.000Z</published>
    <updated>2019-11-02T07:04:22.538Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>首先强烈安利jupyter notebook，它是一种交互式笔记本，安装anaconda的时候会一并安装，下载VS的时候也可以选择安装。<br>我是在初学机器学习的时候接触jupyter notebook的，立刻就被它便捷的交互与结果呈现方式所吸引，现在python编程基本不使用其他的软件。其实完全可以在初学python的时候使用jupyter notebook，可以立即得到反馈以及分析错误，可以进步很快！</p><hr><h1 id="打开操作"><a href="#打开操作" class="headerlink" title="打开操作"></a>打开操作</h1><p>当初安装好之后还不了解，每次打开jupyter notebook都会先弹出一个黑框框，这时候千万别关掉，等一会就能来到网页。另外打开之后也别关掉，使用的时候是一直需要的，因为只有开着才能访问本机web服务器发布的内容。<br><img src="/jupyter-notebook20190913225022/神秘的黑框框.png" title="神秘的黑框框"><br>另外你也可以不通过快捷方式，直接在命令行中直接输入jupyter notebook来打开它。<br>有些时候，当你插入硬盘或者需要直接在特定的目录下打开jupyter notebook（它的默认打开是在“usr/用户名/”路径下），那你可以在输入命令的后面加上你想要的路径。<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook D:\ #打开D盘，于我是我的移动硬盘</span><br><span class="line">jupyter notebook E:\ #我的U盘</span><br><span class="line">jupyter notebook C:\Users\用户名\Desktop #在桌面打开</span><br></pre></td></tr></table></figure><p></p><hr><h1 id="快捷键操作"><a href="#快捷键操作" class="headerlink" title="快捷键操作"></a>快捷键操作</h1><p>在jupyter notebook中可以通过选中cell然后按h的方式查询快捷键。<br><img src="/jupyter-notebook20190913225022/快捷键查询.png" title="快捷键查询"></p><hr><h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>在jupyter notebook中可以直接使用markdown，这对学习可以起到很大的辅助作用，markdown的基本操作可以看我的另一篇博文<a href="https://gsy00517.github.io/markdown20190913211144/" target="_blank">markdown笔记：markdown的基本使用</a><br>此外，在我的博文<a href="https://gsy00517.github.io/anaconda20190913231748/" target="_blank">anaconda笔记：conda的各种命令行操作</a>中，也介绍了如何将python的虚拟环境添加到jupyter notebook中，欢迎阅读。<br>VScode前段时间也开始支持ipynb，喜欢高端暗黑科技风又懒得自己修改jupyter notebook的小伙伴可以试一试，不过我在kernel配置方面似乎还有一些小问题有待解决。</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;首先强烈安利jupyter notebook，它是一种交互式笔记本，安装anaconda的时候会一并安装，下载VS的时候也可以选择安装。&lt;br&gt;
      
    
    </summary>
    
    
      <category term="编程及环境" scheme="https://gsy00517.github.io/categories/%E7%BC%96%E7%A8%8B%E5%8F%8A%E7%8E%AF%E5%A2%83/"/>
    
    
      <category term="命令操作" scheme="https://gsy00517.github.io/tags/%E5%91%BD%E4%BB%A4%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>markdown笔记：markdown的基本使用</title>
    <link href="https://gsy00517.github.io/markdown20190913211144/"/>
    <id>https://gsy00517.github.io/markdown20190913211144/</id>
    <published>2019-09-13T13:11:44.000Z</published>
    <updated>2019-11-02T02:23:03.324Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>既然要写技术博客，那么markdown肯定是必备的了，这篇文章就来介绍一下markdown的基本使用操作。</p><p>本文参考自：<a href="https://www.jianshu.com/p/191d1e21f7ed" target="_blank" rel="noopener">https://www.jianshu.com/p/191d1e21f7ed</a></p><hr><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>Markdown是一种可以使用普通文本编辑器编写的标记语言，其功能比纯文本更强，因此许多程序员用它来写blog。在这里我先推荐一款markdown编辑器——<a href="https://www.typora.io/" target="_blank">typora</a>，大家可以免费下载使用。</p><hr><h1 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h1><p>在我刚开始使用markdown的时候总是跳进这个坑，在这里提上来提醒一下，在使用markdown标记后要添加文字时，需要在相应标记后空一格，否则标记也会被当作文本来处理，例如我输入“#####错误”时：</p><h5 id="错误"><a href="#错误" class="headerlink" title="错误"></a>错误</h5><p>正确的做法是输入“##### 正确”：</p><h5 id="正确"><a href="#正确" class="headerlink" title="正确"></a>正确</h5><p>一种简单的判别方法就是使用IDE，这样对应的标记就会有语法高亮。</p><hr><h1 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h1><ol><li><h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><p>话不多说，直接示范：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 这是一级标题</span><br><span class="line">## 这是二级标题</span><br><span class="line">### 这是三级标题</span><br><span class="line">#### 这是四级标题</span><br><span class="line">##### 这是五级标题</span><br><span class="line">###### 这是六级标题</span><br></pre></td></tr></table></figure><p>效果如下：</p><h1 id="这是一级标题"><a href="#这是一级标题" class="headerlink" title="这是一级标题"></a>这是一级标题</h1><h2 id="这是二级标题"><a href="#这是二级标题" class="headerlink" title="这是二级标题"></a>这是二级标题</h2><h3 id="这是三级标题"><a href="#这是三级标题" class="headerlink" title="这是三级标题"></a>这是三级标题</h3><h4 id="这是四级标题"><a href="#这是四级标题" class="headerlink" title="这是四级标题"></a>这是四级标题</h4><h5 id="这是五级标题"><a href="#这是五级标题" class="headerlink" title="这是五级标题"></a>这是五级标题</h5><h6 id="这是六级标题"><a href="#这是六级标题" class="headerlink" title="这是六级标题"></a>这是六级标题</h6></li><li><h2 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h2><p>还是直接示范：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">**这是加粗的文字**</span><br><span class="line">*这是倾斜的文字*`</span><br><span class="line">***这是斜体加粗的文字***</span><br><span class="line">~~这是加删除线的文字~~</span><br></pre></td></tr></table></figure><p><strong>这是加粗的文字</strong><br><em>这是倾斜的文字</em><br><strong><em>这是斜体加粗的文字</em></strong><br><del>这是加删除线的文字</del></p></li><li><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;我引用</span><br><span class="line">&gt;&gt;我还引用</span><br><span class="line">&gt;&gt;&gt;我再引用</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;扶我起来，我还能继续引用！</span><br></pre></td></tr></table></figure><blockquote><p>我引用</p><blockquote><p>我还引用</p><blockquote><p>我再引用</p><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><blockquote><p>扶我起来，我还能继续引用！</p></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote></blockquote><p>引用是可以嵌套的，可以加很多层，我一般使用一个&gt;来表示额外的需要注意的内容。另外，如果想让下一段文字不被引用，需要空一行。</p></li><li><h2 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h2><p>分割线使用三个及以上的<code>-</code>或<code>*</code>就可以。<br>有时候用<code>---</code>会造成别的文字的格式变化，因此我在使用VScode编辑时，如果看到<code>---</code>被高亮（分割线正常其作用时应该不高亮），就会改用<code>***</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">***</span><br></pre></td></tr></table></figure><p>效果如下：</p><hr><hr></li><li><h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><p>markdown中添加图片的语法是这样的：<br><code>![显示在图片下方的文字]（图片地址 &quot;图片title&quot;）</code><br>其中title可加可不加，它就是鼠标移动到图片上时显示的文字。<br>然而我在使用hexo搭建我的个人博客的过程中，遇到了使用上述语法图片却无法显示的情况，因此我改用了下列标签插件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% asset_img xxxxx.xxx 图片下方的名字 %&#125;</span><br></pre></td></tr></table></figure><p>其中xxxxx.xxx只需直接输入图片名称以及格式即可，因为我使用了hexo-asset-image插件，它可以在_posts文件中创建与博文名称相同的对应的文件夹，只需把图片移入即可。<br>其安装命令：<code>npm install hexo-asset-image --save</code><br>也可用cnpm更快地安装：<code>cnpm install hexo-asset-image --save</code></p></li><li><h2 id="超链接"><a href="#超链接" class="headerlink" title="超链接"></a>超链接</h2>由于我希望在新的页面打开链接，而似乎markdown本身的语法不支持在新标签页打开链接，因此我推荐直接使用html语言来代替。<br><code>&lt;a href=&quot;超链接地址&quot; target=&quot;_blank&quot;&gt;超链接名&lt;/a&gt;</code></li><li><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><ul><li><p>无序列表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- 列表内容</span><br><span class="line">+ 列表内容</span><br><span class="line">* 列表内容</span><br></pre></td></tr></table></figure><ul><li>列表内容</li></ul><ul><li>列表内容</li></ul><ul><li>列表内容</li></ul></li><li><p>有序列表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 列表内容</span><br><span class="line">2. 列表内容</span><br><span class="line">3. 列表内容</span><br></pre></td></tr></table></figure><ol><li>列表内容</li><li>列表内容</li><li>列表内容<br>可以看到，上面显示的列表是有嵌套的，方法就是敲三个空格缩进。</li></ol></li></ul></li><li><h2 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">表头|表头|表头</span><br><span class="line">---|:--:|---:</span><br><span class="line">内容|内容|内容</span><br><span class="line">内容|内容|内容</span><br></pre></td></tr></table></figure><p>其中第二行的作用分割表头和内容，<code>-</code>有一个就行，为了对齐可多加几个。<br>此外文字默认居左，有两种改变方法：<br>两边加：表示文字居中。<br>右边加：表示文字居右。<br>然而我在hexo使用表格时，出现了无法正常转换的问题，因此我改用了如下HTML的表格形式。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;table border=&quot;1&quot;&gt;</span><br><span class="line">&lt;tr&gt;</span><br><span class="line">&lt;td&gt;第一行第一列&lt;/td&gt;</span><br><span class="line">&lt;td&gt;第一行第二列&lt;/td&gt;</span><br><span class="line">&lt;/tr&gt;</span><br><span class="line">&lt;tr&gt;</span><br><span class="line">&lt;td&gt;第二行第一列&lt;/td&gt;</span><br><span class="line">&lt;td&gt;第三行第二列&lt;/td&gt;</span><br><span class="line">&lt;/tr&gt;</span><br><span class="line">&lt;/table&gt;</span><br></pre></td></tr></table></figure><p>效果如下：</p><table border="1"><tr><td>第一行第一列</td><td>第一行第二列</td></tr><tr><td>第二行第一列</td><td>第二行第二列</td></tr></table></li><li><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><p>最后的最后，是我最喜欢ctrl+C+V的代码了。<br>单行或句中代码输入方式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`来复制我呀`</span><br></pre></td></tr></table></figure><p>显示：<br><code>来复制我呀</code><br>其中`在键盘的左上角，我当初找了好久。<br>多行代码块的写法就是用上下两对```围住。<br>好了于是你现在就可以自由的复制粘贴啦。</p><img src="/markdown20190913211144/如何写代码.JPG" title="如何写代码"></li></ol><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;既然要写技术博客，那么markdown肯定是必备的了，这篇文章就来介绍一下markdown的基本使用操作。&lt;/p&gt;&lt;p&gt;本文参考自：&lt;a hre
      
    
    </summary>
    
    
      <category term="操作与使用" scheme="https://gsy00517.github.io/categories/%E6%93%8D%E4%BD%9C%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="markdown" scheme="https://gsy00517.github.io/tags/markdown/"/>
    
  </entry>
  
  <entry>
    <title>hexo笔记：开始创建个人博客——方法及原因</title>
    <link href="https://gsy00517.github.io/hexo20190913153310/"/>
    <id>https://gsy00517.github.io/hexo20190913153310/</id>
    <published>2019-09-13T07:33:10.000Z</published>
    <updated>2019-11-02T02:22:05.701Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --><p>大家好，这是我的第一篇博文，这也是我的第一个自己搭建的网站，既然搭了，那第一篇就讲讲我搭建的过程吧。</p><hr><h1 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h1><ol><li><h2 id="安装node-js"><a href="#安装node-js" class="headerlink" title="安装node.js"></a>安装node.js</h2>进入<a href="https://nodejs.org" target="_blank">官网</a>。<br>选择对应系统（我这里用win10），选择LTS（长期支持版本）安装，安装步骤中一直选择next即可。<br>安装完后就可以把安装包删除了。</li><li><h2 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h2>进入<a href="https://git-scm.com/downloads" target="_blank">官网</a>。<br>选择对应系统的版本下载，同样也是按默认安装。<br>安装成功后，你会在开始菜单中看到git文件夹。 <img src="/hexo20190913153310/成功安装git.png" title="成功安装git"> 其中Git Bash与linux和mac中的终端类似，它是git自带的程序，提供了linux风格的shell，我们可以在这里面执行相应的命令。<blockquote><p>注意：bash中的复制粘贴操作与linux中类似，ctrl+C用于终止进程，可以用鼠标中键进行粘贴操作。不嫌麻烦的话可以使用ctrl+shift+C和ctrl+shift+V进行复制粘贴操作。</p></blockquote></li><li><h2 id="安装hexo"><a href="#安装hexo" class="headerlink" title="安装hexo"></a>安装hexo</h2>hexo是一个快速、简洁且高效的博客框架，在这里我们使用hexo来搭建博客。<br>首先，新建一个名为“blog”的空文件夹，以后我们的操作都在这个文件夹里进行，可以在bash中使用pwd命令查看当前所处位置。<br>创建这个文件夹的目的是万一因为创建的博客出现问题或者不满意想重来等原因可以直接简单地把文件夹删除，也方便了对整个网站本地内容的移动。<br>打开新建的文件夹，右键空白处，选择Git Bash Here。 <img src="/hexo20190913153310/打开bash.png" title="打开bash"> 接下来我们输入两行命令来验证node.js是否安装成功。 <img src="/hexo20190913153310/成功安装node.js.png" title="成功安装node.js"> 如出现如图所示结果，则表明安装成功。<br>为了提高以后的下载速度，我们需要安装cnpm。cnpm是淘宝的国内镜像，因为npm的服务器位于国外有时可能会影响安装。<br>继续在bash中输入如下命令安装cnpm：<br><code>npm install -g cnpm --registry=https://registry.npm.taobao.org</code><br>检验安装是否成功，输入<code>cnpm</code>： <img src="/hexo20190913153310/成功安装cnpm.png" title="成功安装cnpm"> 接下来我们安装hexo，输入命令：<br><code>cnpm install -g hexo-cli</code><br>和上面一样，我们可以用<code>hexo -v</code>来验证是否成功安装hexo，这里就不贴图了。<br>接下来我们输入如下命令来建立整个项目：<br><code>hexo init</code><br>你会发现你的文件夹中多了许多文件，你也可以用ls -l命令来看到新增的文件。 <img src="/hexo20190913153310/新增文件.png" title="新增文件"></li><li><h2 id="完成本地环境的搭建"><a href="#完成本地环境的搭建" class="headerlink" title="完成本地环境的搭建"></a>完成本地环境的搭建</h2><p>至此，我们已经完成了本地环境的搭建，在这里，我想先介绍hexo中常用的命令。<br><code>hexo n &quot;文章标题&quot;</code>用于创建新的博文（欲删除文章，直接删除md文件并用下面的命令更新即可）。<br><code>hexo s</code>hexo会监视文件变动并自动更新，通过所给的localhost:4000/就可以直接在本地预览更新后的网站了。<br>部署到远端服务器三步曲：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hexo clean #清除缓存，网页正常情况下可以忽略此条命令，执行该指令后，会删掉站点根目录下的public文件夹。</span><br><span class="line">hexo g #generate静态网页（静态网页这里指没有前端后端的网页而不是静止），该命令把md编译为html并存到public文件目录下。</span><br><span class="line">hexo d #将本地的更改部署到远端服务器（需要一点时间，请过一会再刷新网页）。</span><br></pre></td></tr></table></figure><p>此外，上面最后两步也可以使用<code>hexo g -d</code>直接代替。<br>如果出现ERROR Deployer not found: git报错，可以使用<code>npm install --save hexo-deployer-git</code>命令解决。</p><blockquote><p>注意：由于部署到远端输入密码时密码不可见，有时候会导致部署失败，只有出现INFO Deploy done: git的结果才表明部署成功，否则再次部署重输密码即可。</p></blockquote><p>现在我们在bash中运行<code>hexo s</code>，打开浏览器，输入<code>localhost:4000/</code>，就可以看到hexo默认创建的页面了。</p></li><li><h2 id="部署到远端服务器"><a href="#部署到远端服务器" class="headerlink" title="部署到远端服务器"></a>部署到远端服务器</h2>为了让别人能访问到你搭建的网站，我们需要部署到远端服务器。<br>这里有两种选择，一种是部署到github上，新建一个repository，然后创建一个xxxxx.github.io域名（这里xxxxx必须为你的github用户名）。<br>另一种选择是部署到国内的coding，这是考虑到访问速度的问题，不过我选择的是前者，亲测并没感觉有速度的困扰。<br>个人比较推荐用github pages创建个人博客。<br>部署这块网上有许多教程，这里不详细解释了，以后有机会补上。<br>在部署的时候涉及到对主题配置文件的操作，linux和mac用户可以使用vim进行编辑，不过也可以使用VScode、sublime等代码编辑器进行操作。<blockquote><p>注：为了国内的访问速度，我最后添加了coding/github双线部署，两者的操作方式大同小异。值得注意的是，如果使用的是leancloud的阅读量与评论统计系统，那么还得在leancloud的安全中心中添加coding的web域名。</p></blockquote></li></ol><hr><h1 id="创建原因"><a href="#创建原因" class="headerlink" title="创建原因"></a>创建原因</h1><p>首先说明，我只是一个刚起步的入门级小白，懂得不多，别喷我哈~<br>步入大二，虽然我是大学才算真正接触编程，但一年多下来我也接触并且学习了不少技术知识。接触的多了、遇到的问题也复杂了起来，导致每次百度到的答案不一定能够解决我遇到的问题。此外，之前在学习编程语言、操作系统、ml、dl等知识的时候，为方便起见利用文本记了些笔记。然而笔记分散在四处，不方便管理与查看，因此就萌生了写博客的想法。由于个人比较喜欢自由DIY，所以没有使用CSDN、博客园等知名技术博客网站。<br>最后还是非常感谢我们华科的校友<a href="https://www.codesheep.cn/" target="_blank">程序羊</a>在b站和其他站点上分享的各种经验，我就是通过他的<a href="https://www.bilibili.com/video/av44544186" target="_blank">视频</a>来搭建起自己的第一个博客网站的。他的其他视频也给了我很多启迪。<br>最后，最关键的原因，还是因为今天中秋节有空闲的时间哈哈，祝大家节日快乐！</p><script type="text/javascript" src="/js/src/bai.js"></script><!-- rebuild by neat -->]]></content>
    
    <summary type="html">
    
      
      
        &lt;!-- build time:Sat Nov 02 2019 15:04:43 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;大家好，这是我的第一篇博文，这也是我的第一个自己搭建的网站，既然搭了，那第一篇就讲讲我搭建的过程吧。&lt;/p&gt;&lt;hr&gt;&lt;h1 id=&quot;安装步骤&quot;&gt;
      
    
    </summary>
    
    
      <category term="操作与使用" scheme="https://gsy00517.github.io/categories/%E6%93%8D%E4%BD%9C%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    
    
      <category term="hexo" scheme="https://gsy00517.github.io/tags/hexo/"/>
    
      <category term="安装教程" scheme="https://gsy00517.github.io/tags/%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"/>
    
  </entry>
  
</feed>
