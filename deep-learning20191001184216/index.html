<!-- build time:Wed Nov 06 2019 12:11:00 GMT+0800 (GMT+08:00) --><!DOCTYPE html><html class="theme-next gemini use-motion" lang="zh-Hans"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><meta name="google-site-verification" content="YV24rdmIIf8GuLLOBH5IYEWm0Z3TGAqiLS-LLlspD7w"><script src="/lib/pace/pace.min.js?v=1.0.2"></script><link href="/lib/pace/pace-theme-big-counter.min.css?v=1.0.2" rel="stylesheet"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="baidu-site-verification" content="true"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/haizei.ico?v=5.1.4"><link rel="icon" type="image/png" sizes="32x32" href="/images/haizei.ico?v=5.1.4"><link rel="icon" type="image/png" sizes="16x16" href="/images/haizei.ico?v=5.1.4"><link rel="mask-icon" href="/images/haizei.ico?v=5.1.4" color="#222"><meta name="keywords" content="深度学习,论文分享,代码实现,pytorch,"><link rel="alternate" href="/atom.xml" title="高深远的博客" type="application/atom+xml"><meta name="description" content="之前我用pytorch把ResNet18实现了一下，但由于上周准备国家奖学金答辩没有时间来写我实现的过程与总结。今天是祖国70周年华诞，借着这股喜庆劲，把这篇文章补上。本文参考自：https://blog.csdn.net/weixin_43624538/article/details/85049699https://blog.csdn.net/u013289254/article/details"><meta name="keywords" content="深度学习,论文分享,代码实现,pytorch"><meta property="og:type" content="article"><meta property="og:title" content="deep learning笔记：使网络能够更深——ResNet简介与pytorch实现"><meta property="og:url" content="https://gsy00517.github.io/deep-learning20191001184216/index.html"><meta property="og:site_name" content="高深远的博客"><meta property="og:description" content="之前我用pytorch把ResNet18实现了一下，但由于上周准备国家奖学金答辩没有时间来写我实现的过程与总结。今天是祖国70周年华诞，借着这股喜庆劲，把这篇文章补上。本文参考自：https://blog.csdn.net/weixin_43624538/article/details/85049699https://blog.csdn.net/u013289254/article/details"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="https://gsy00517.github.io/deep-learning20191001184216/基本残差模块.png"><meta property="og:image" content="https://gsy00517.github.io/deep-learning20191001184216/各版本ResNet.png"><meta property="og:image" content="https://gsy00517.github.io/deep-learning20191001184216/基本结构.JPG"><meta property="og:image" content="https://gsy00517.github.io/deep-learning20191001184216/输出全为1.png"><meta property="og:image" content="https://gsy00517.github.io/deep-learning20191001184216/结果.png"><meta property="og:image" content="https://gsy00517.github.io/deep-learning20191001184216/感知器.jpg"><meta property="og:image" content="https://gsy00517.github.io/deep-learning20191001184216/归一化.png"><meta property="og:updated_time" content="2019-11-02T02:21:37.312Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="deep learning笔记：使网络能够更深——ResNet简介与pytorch实现"><meta name="twitter:description" content="之前我用pytorch把ResNet18实现了一下，但由于上周准备国家奖学金答辩没有时间来写我实现的过程与总结。今天是祖国70周年华诞，借着这股喜庆劲，把这篇文章补上。本文参考自：https://blog.csdn.net/weixin_43624538/article/details/85049699https://blog.csdn.net/u013289254/article/details"><meta name="twitter:image" content="https://gsy00517.github.io/deep-learning20191001184216/基本残差模块.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"5.1.4",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!1},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="https://gsy00517.github.io/deep-learning20191001184216/"><meta name="baidu-site-verification" content="o5QfpvLBz5"><title>deep learning笔记：使网络能够更深——ResNet简介与pytorch实现 | 高深远的博客</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">高深远的博客</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description"></h1></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i> </span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"><input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="https://gsy00517.github.io/deep-learning20191001184216/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="高深远"><meta itemprop="description" content><meta itemprop="image" content="/images/lufei.jpg"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="高深远的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">deep learning笔记：使网络能够更深——ResNet简介与pytorch实现</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-01T18:42:16+08:00">2019-10-01 </time><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于&#58;</span> <time title="更新于" itemprop="dateModified" datetime="2019-11-02T10:21:37+08:00">2019-11-02 </time></span><span class="post-category"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/人工智能/" itemprop="url" rel="index"><span itemprop="name">人工智能</span> </a></span></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/deep-learning20191001184216/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/deep-learning20191001184216/" itemprop="commentCount"></span> </a></span><span id="/deep-learning20191001184216/" class="leancloud_visitors" data-flag-title="deep learning笔记：使网络能够更深——ResNet简介与pytorch实现"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数&#58;</span> <span class="leancloud-visitors-count"></span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计&#58;</span> <span title="字数统计">5k字 </span><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span title="阅读时长">25分钟</span></div></div></header><div class="post-body" itemprop="articleBody"><p>之前我用pytorch把ResNet18实现了一下，但由于上周准备国家奖学金答辩没有时间来写我实现的过程与总结。今天是祖国70周年华诞，借着这股喜庆劲，把这篇文章补上。</p><p>本文参考自：<a href="https://blog.csdn.net/weixin_43624538/article/details/85049699" target="_blank" rel="noopener">https://blog.csdn.net/weixin_43624538/article/details/85049699</a><br><a href="https://blog.csdn.net/u013289254/article/details/98785869" target="_blank" rel="noopener">https://blog.csdn.net/u013289254/article/details/98785869</a></p><hr><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>ResNet残差网络是由何凯明等四名微软研究院的华人提出的，当初看到论文标题下面的中国名字还是挺高兴的。文章引入部分，作者就探讨了深度神经网络的优化是否就只是叠加层数、增加深度那么简单。显然这是不可能的，增加深度带来的首要问题就是梯度爆炸、消散的问题，这是由于随着层数的增多，在网络中反向传播的梯度会随着连乘变得不稳定，从而变得特别大或者特别小。其中以梯度消散更为常见。值得注意的是，论文中还提到深度更深的网络反而出现准确率下降并不是由过拟合所引起的。<br>为了解决这个问题，研究者们做出了很多思考与尝试，其中的代表有relu激活函数的使用，Batch Normalization的使用等。关于这两种方法，可以参考网上的资料以及我的博文<a href="https://gsy00517.github.io/deep-learning20190915113859/" target="_blank">deep-learning笔记：开启深度学习热潮——AlexNet</a>和<a href="https://gsy00517.github.io/deep-learning20191001151454/" target="_blank">deep-learning笔记：学习率衰减与批归一化</a>。<br>对于上面这个问题，ResNet作出的贡献是引入skip/identity connection。如下所示就是两个基本的残差模块。<br><img src="/deep-learning20191001184216/基本残差模块.png" title="基本残差模块"><br>上面这个block可表示为：$ F(X)=H(X)-x $。在这里，X为浅层输出，H(x)为深层的输出。当浅层的X代表的特征已经足够成熟，即当任何对于特征X的改变都会让loss变大时，F(X)会自动趋向于学习成为0，X则从恒等映射的路径继续传递。<br>这样，我们就可以在不增加计算成本的情况下使得在前向传递过程中，如果浅层的输出已经足够成熟（optimal），那么就让深层网络后面的层仅实现恒等映射的作用。<br>当X与F（X）通道数目不同时，作者尝试了两种identity mapping的方式。一种即对X缺失的通道直接补零从而使其能够对齐，这种方式比较简单直接，无需额外的参数；另一种则是通过使用1x1的conv来映射从而使通道也能达成一致。</p><hr><h1 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h1><p>老规矩，这里还是先呈上我用黄色荧光高亮出我认为比较重要的要点的论文原文，这里我只有<a href="1512.03385.pdf" target="_blank">英文版</a>。<br>如果需要没有被我标注过的原文，可以直接搜索，这里我仅提供一次，可以<a href="https://arxiv.org/abs/1512.03385" target="_blank">点击这里</a>下载。<br>不过，虽然没有pdf中文版，但其实深度学习CV方向一些比较经典的论文的英文、中文、中英对照都可以到<a href="https://github.com/SnailTyan/deep-learning-papers-translation" target="_blank">Deep Learning Papers Translation</a>上看到，非常方便。</p><hr><h1 id="自己实现"><a href="#自己实现" class="headerlink" title="自己实现"></a>自己实现</h1><p>在论文中，作者提到了如下几个ResNet的版本的结构。<br><img src="/deep-learning20191001184216/各版本ResNet.png" title="各版本ResNet"><br>这里我实现的是ResNet18。<br>由于这不是我第一次使用pytorch进行实现，一些基本的使用操作我就不加注释了，想看注释来理解的话可以参考我之前VGG的实现。<br>由于残差的引入，导致ResNet的结构比较复杂，而论文中并没有非常详细的阐述，在研究官方源码之后，我对它的结构才有了完整的了解，这里我画出来以便参考。<br><img src="/deep-learning20191001184216/基本结构.JPG" title="基本结构"><br>ResNet18的每一layer包括了两个这样的basic block，其中1x1的卷积核仅在X与F（X）通道数目不一致时进行操作，在我的代码中，我定义shortcut函数来对应一切通道一致、无需处理的情况。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(ResNet, self).__init__()</span><br><span class="line">        </span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels = <span class="number">3</span>, out_channels = <span class="number">64</span>, kernel_size = <span class="number">7</span>, stride = <span class="number">2</span>, padding = <span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.max = nn.MaxPool2d(kernel_size = <span class="number">3</span>, stride = <span class="number">2</span>, padding = <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(<span class="number">64</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(<span class="number">128</span>)</span><br><span class="line">        self.bn4 = nn.BatchNorm2d(<span class="number">256</span>)</span><br><span class="line">        self.bn5 = nn.BatchNorm2d(<span class="number">512</span>)</span><br><span class="line">        </span><br><span class="line">        self.shortcut = nn.Sequential()</span><br><span class="line">        self.shortcut3 = nn.Sequential(nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size = <span class="number">1</span>, stride = <span class="number">2</span>, bias = <span class="literal">False</span>), nn.BatchNorm2d(<span class="number">128</span>)) </span><br><span class="line">        self.shortcut4 = nn.Sequential(nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size = <span class="number">1</span>, stride = <span class="number">2</span>, bias = <span class="literal">False</span>), nn.BatchNorm2d(<span class="number">256</span>))</span><br><span class="line">        self.shortcut5 = nn.Sequential(nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size = <span class="number">1</span>, stride = <span class="number">2</span>, bias = <span class="literal">False</span>), nn.BatchNorm2d(<span class="number">512</span>))</span><br><span class="line">        </span><br><span class="line">        self.conv2 = nn.Conv2d(in_channels = <span class="number">64</span>, out_channels = <span class="number">64</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">1</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv3_1 = nn.Conv2d(in_channels = <span class="number">64</span>, out_channels = <span class="number">128</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">2</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        self.conv3_2 = nn.Conv2d(in_channels = <span class="number">128</span>, out_channels = <span class="number">128</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">1</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv4_1 = nn.Conv2d(in_channels = <span class="number">128</span>, out_channels = <span class="number">256</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">2</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        self.conv4_2 = nn.Conv2d(in_channels = <span class="number">256</span>, out_channels = <span class="number">256</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">1</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        self.conv5_1 = nn.Conv2d(in_channels = <span class="number">256</span>, out_channels = <span class="number">512</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">2</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        self.conv5_2 = nn.Conv2d(in_channels = <span class="number">512</span>, out_channels = <span class="number">512</span>, kernel_size = <span class="number">3</span>, stride = <span class="number">1</span>, padding = <span class="number">1</span>, bias = <span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        self.avg = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        self.fc = nn.Linear(<span class="number">512</span>, <span class="number">1000</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        x1 = self.max(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#layer1</span></span><br><span class="line">        x = F.relu(self.bn2(self.conv2(x1)))</span><br><span class="line">        x = self.bn2(self.conv2(x))</span><br><span class="line">        x += self.shortcut(x1)</span><br><span class="line">        x2 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.bn2(self.conv2(x2)))</span><br><span class="line">        x = self.bn2(self.conv2(x))</span><br><span class="line">        x += self.shortcut(x2)</span><br><span class="line">        x3 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#layer2</span></span><br><span class="line">        x = F.relu(self.bn3(self.conv3_1(x3)))</span><br><span class="line">        x = self.bn3(self.conv3_2(x))</span><br><span class="line">        x += self.shortcut3(x3)</span><br><span class="line">        x4 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.bn3(self.conv3_2(x4)))</span><br><span class="line">        x = self.bn3(self.conv3_2(x))</span><br><span class="line">        x += self.shortcut(x4)</span><br><span class="line">        x5 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#layer3</span></span><br><span class="line">        x = F.relu(self.bn4(self.conv4_1(x5)))</span><br><span class="line">        x = self.bn4(self.conv4_2(x))</span><br><span class="line">        x += self.shortcut4(x5)</span><br><span class="line">        x6 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.bn4(self.conv4_2(x6)))</span><br><span class="line">        x = self.bn4(self.conv4_2(x))</span><br><span class="line">        x += self.shortcut(x6)</span><br><span class="line">        x7 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#layer4</span></span><br><span class="line">        x = F.relu(self.bn5(self.conv5_1(x7)))</span><br><span class="line">        x = self.bn5(self.conv5_2(x))</span><br><span class="line">        x += self.shortcut5(x7)</span><br><span class="line">        x8 = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        x = F.relu(self.bn5(self.conv5_2(x8)))</span><br><span class="line">        x = self.bn5(self.conv5_2(x))</span><br><span class="line">        x += self.shortcut(x8)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#ending</span></span><br><span class="line">        x = self.avg(x)</span><br><span class="line">        </span><br><span class="line">        x = x.view(<span class="number">-1</span>, self.num_flat_features(x))</span><br><span class="line">        x = self.fc(x)</span><br><span class="line">        </span><br><span class="line">        x = F.softmax(x, dim = <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:]</span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line">        </span><br><span class="line">net = ResNet()</span><br></pre></td></tr></table></figure><p></p><p>同样的，我们可以随机生成一个张量来进行验证：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">input = torch.randn(<span class="number">1</span>, <span class="number">3</span>, <span class="number">48</span>, <span class="number">48</span>)</span><br><span class="line">out = net(input)</span><br><span class="line">print(out)</span><br></pre></td></tr></table></figure><p></p><p>如果可以顺利地输出，那么模型基本上是没有问题的。</p><hr><h1 id="出现的问题"><a href="#出现的问题" class="headerlink" title="出现的问题"></a>出现的问题</h1><p>在这里我还是想把自己踩的一些简单的坑记下来，引以为戒。</p><ol><li><h2 id="softmax输出全为1"><a href="#softmax输出全为1" class="headerlink" title="softmax输出全为1"></a>softmax输出全为1</h2><p>当我使用F.softmax之后，出现了这样的一个问题：</p><img src="/deep-learning20191001184216/输出全为1.png" title="输出全为1"><p>查找资料后发现，我错误的把对每一行softmax当作了对每一列softmax。因为这个softmax语句是我从之前的自己做的一道kaggle题目写的代码中ctrl+C+V过来的，复制过来的是<code>x = F.softmax(x, dim = 0)</code>，在这里，dim = 0意味着我对张量的每一列进行softmax，这是因为我之前的场景中需要处理的张量是一维的，也就是tensor（）里面只有一对“[]”，此时它默认只有一列，我对列进行softmax自然就没有问题。<br>而放到这里，我再对列进行softmax时，每列上就只有一个元素。那么结果就都是1即100%了。解决的方法就是把dim设为1。<br>下面我在用一组代码直观地展示一下softmax的用法与区别。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line">x1= torch.Tensor( [ [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], [<span class="number">1</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>], [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line">y11= F.softmax(x1, dim = <span class="number">0</span>) <span class="comment">#对每一列进行softmax</span></span><br><span class="line">y12 = F.softmax(x1, dim = <span class="number">1</span>) <span class="comment">#对每一行进行softmax</span></span><br><span class="line">x2 = torch.Tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">y2 = F.softmax(x2, dim = <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>我们输出每个结果，可以看到：</p><img src="/deep-learning20191001184216/结果.png" title="结果"></li><li><h2 id="bias"><a href="#bias" class="headerlink" title="bias"></a>bias</h2>或许你可以发现，在我的代码中，每个卷积层中都设置了<code>bias = False</code>，这是我在参考官方源码之后补上的。那么，这个bias是什么，又有什么用呢？<br>我们在学深度学习的时候，最早接触到的神经网络应该是感知器，它的结构如下图所示。 <img src="/deep-learning20191001184216/感知器.jpg" title="感知器"> 要想激活这个感知器，就必须使<code>x1 * w1 + x2 * w2 + ... + xn * wn &gt; T</code>（T为一个阈值），而T越大，想激活这个感知器的难度越大。<br>考虑样本较多的情况，我不可能手动选择一个阈值，使得模型整体表现最佳，因此我们不如使得T变成可学习的，这样一来，T会自动学习到一个数，使得模型的整体表现最佳。当把T移动到左边，它就成了bias偏置，<code>x1 * w1 + x2 * w2 + ... + xn * wn - T &gt; 0</code>。显然，偏置的大小控制着激活这个感知器的难易程度。<br>在比感知器高级的神经网络中，也是如此。<br>但倘若我们要在卷积后面加上归一化操作，那么bias的作用就无法体现了。<br>我们以ResNet卷积层后的BN层为例。<br>可参考我的上一篇博文，BN处理过程中有这样一步： <img src="/deep-learning20191001184216/归一化.png" title="归一化"> 对于分子而言，无论有没有bias，对结果都没有影响；而对于下面分母而言，因为是方差操作，所以也没有影响。因此，在ResNet中，因为每次卷积之后都要进行BN操作，那就不需要启用bias，否则非但不起作用，还会消耗一定的显卡内存。</li></ol><hr><h1 id="官方源码"><a href="#官方源码" class="headerlink" title="官方源码"></a>官方源码</h1><p>如果你此时对ResNet的结构已经有了比较清晰的理解，那么可以尝试着来理解一下官方源码的思路。其实我觉得先看像我这样直观的代码实现再看官方源码更有助理解且更高效。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> .utils <span class="keyword">import</span> load_state_dict_from_url</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">__all__ = [<span class="string">'ResNet'</span>, <span class="string">'resnet18'</span>, <span class="string">'resnet34'</span>, <span class="string">'resnet50'</span>, <span class="string">'resnet101'</span>,</span><br><span class="line">           <span class="string">'resnet152'</span>, <span class="string">'resnext50_32x4d'</span>, <span class="string">'resnext101_32x8d'</span>,</span><br><span class="line">           <span class="string">'wide_resnet50_2'</span>, <span class="string">'wide_resnet101_2'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model_urls = &#123;</span><br><span class="line">    <span class="string">'resnet18'</span>: <span class="string">'https://download.pytorch.org/models/resnet18-5c106cde.pth'</span>,</span><br><span class="line">    <span class="string">'resnet34'</span>: <span class="string">'https://download.pytorch.org/models/resnet34-333f7ec4.pth'</span>,</span><br><span class="line">    <span class="string">'resnet50'</span>: <span class="string">'https://download.pytorch.org/models/resnet50-19c8e357.pth'</span>,</span><br><span class="line">    <span class="string">'resnet101'</span>: <span class="string">'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'</span>,</span><br><span class="line">    <span class="string">'resnet152'</span>: <span class="string">'https://download.pytorch.org/models/resnet152-b121ed2d.pth'</span>,</span><br><span class="line">    <span class="string">'resnext50_32x4d'</span>: <span class="string">'https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth'</span>,</span><br><span class="line">    <span class="string">'resnext101_32x8d'</span>: <span class="string">'https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth'</span>,</span><br><span class="line">    <span class="string">'wide_resnet50_2'</span>: <span class="string">'https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth'</span>,</span><br><span class="line">    <span class="string">'wide_resnet101_2'</span>: <span class="string">'https://download.pytorch.org/models/wide_resnet101_2-32ee1156.pth'</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv3x3</span><span class="params">(in_planes, out_planes, stride=<span class="number">1</span>, groups=<span class="number">1</span>, dilation=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""3x3 convolution with padding"""</span></span><br><span class="line">    <span class="keyword">return</span> nn.Conv2d(in_planes, out_planes, kernel_size=<span class="number">3</span>, stride=stride,</span><br><span class="line">                     padding=dilation, groups=groups, bias=<span class="literal">False</span>, dilation=dilation)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv1x1</span><span class="params">(in_planes, out_planes, stride=<span class="number">1</span>)</span>:</span></span><br><span class="line">    <span class="string">"""1x1 convolution"""</span></span><br><span class="line">    <span class="keyword">return</span> nn.Conv2d(in_planes, out_planes, kernel_size=<span class="number">1</span>, stride=stride, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BasicBlock</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    expansion = <span class="number">1</span></span><br><span class="line">    __constants__ = [<span class="string">'downsample'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inplanes, planes, stride=<span class="number">1</span>, downsample=None, groups=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 base_width=<span class="number">64</span>, dilation=<span class="number">1</span>, norm_layer=None)</span>:</span></span><br><span class="line">        super(BasicBlock, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm2d</span><br><span class="line">        <span class="keyword">if</span> groups != <span class="number">1</span> <span class="keyword">or</span> base_width != <span class="number">64</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">'BasicBlock only supports groups=1 and base_width=64'</span>)</span><br><span class="line">        <span class="keyword">if</span> dilation &gt; <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">raise</span> NotImplementedError(<span class="string">"Dilation &gt; 1 not supported in BasicBlock"</span>)</span><br><span class="line">        <span class="comment"># Both self.conv1 and self.downsample layers downsample the input when stride != 1</span></span><br><span class="line">        self.conv1 = conv3x3(inplanes, planes, stride)</span><br><span class="line">        self.bn1 = norm_layer(planes)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.conv2 = conv3x3(planes, planes)</span><br><span class="line">        self.bn2 = norm_layer(planes)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        identity = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bottleneck</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    expansion = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, inplanes, planes, stride=<span class="number">1</span>, downsample=None, groups=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 base_width=<span class="number">64</span>, dilation=<span class="number">1</span>, norm_layer=None)</span>:</span></span><br><span class="line">        super(Bottleneck, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm2d</span><br><span class="line">        width = int(planes * (base_width / <span class="number">64.</span>)) * groups</span><br><span class="line">        <span class="comment"># Both self.conv2 and self.downsample layers downsample the input when stride != 1</span></span><br><span class="line">        self.conv1 = conv1x1(inplanes, width)</span><br><span class="line">        self.bn1 = norm_layer(width)</span><br><span class="line">        self.conv2 = conv3x3(width, width, stride, groups, dilation)</span><br><span class="line">        self.bn2 = norm_layer(width)</span><br><span class="line">        self.conv3 = conv1x1(width, planes * self.expansion)</span><br><span class="line">        self.bn3 = norm_layer(planes * self.expansion)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.downsample = downsample</span><br><span class="line">        self.stride = stride</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        identity = x</span><br><span class="line"></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.downsample <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            identity = self.downsample(x)</span><br><span class="line"></span><br><span class="line">        out += identity</span><br><span class="line">        out = self.relu(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ResNet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, block, layers, num_classes=<span class="number">1000</span>, zero_init_residual=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                 groups=<span class="number">1</span>, width_per_group=<span class="number">64</span>, replace_stride_with_dilation=None,</span></span></span><br><span class="line"><span class="function"><span class="params">                 norm_layer=None)</span>:</span></span><br><span class="line">        super(ResNet, self).__init__()</span><br><span class="line">        <span class="keyword">if</span> norm_layer <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            norm_layer = nn.BatchNorm2d</span><br><span class="line">        self._norm_layer = norm_layer</span><br><span class="line"></span><br><span class="line">        self.inplanes = <span class="number">64</span></span><br><span class="line">        self.dilation = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> replace_stride_with_dilation <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># each element in the tuple indicates if we should replace</span></span><br><span class="line">            <span class="comment"># the 2x2 stride with a dilated convolution instead</span></span><br><span class="line">            replace_stride_with_dilation = [<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>]</span><br><span class="line">        <span class="keyword">if</span> len(replace_stride_with_dilation) != <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">"replace_stride_with_dilation should be None "</span></span><br><span class="line">                             <span class="string">"or a 3-element tuple, got &#123;&#125;"</span>.format(replace_stride_with_dilation))</span><br><span class="line">        self.groups = groups</span><br><span class="line">        self.base_width = width_per_group</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, self.inplanes, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>,</span><br><span class="line">                               bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn1 = norm_layer(self.inplanes)</span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line">        self.layer1 = self._make_layer(block, <span class="number">64</span>, layers[<span class="number">0</span>])</span><br><span class="line">        self.layer2 = self._make_layer(block, <span class="number">128</span>, layers[<span class="number">1</span>], stride=<span class="number">2</span>,</span><br><span class="line">                                       dilate=replace_stride_with_dilation[<span class="number">0</span>])</span><br><span class="line">        self.layer3 = self._make_layer(block, <span class="number">256</span>, layers[<span class="number">2</span>], stride=<span class="number">2</span>,</span><br><span class="line">                                       dilate=replace_stride_with_dilation[<span class="number">1</span>])</span><br><span class="line">        self.layer4 = self._make_layer(block, <span class="number">512</span>, layers[<span class="number">3</span>], stride=<span class="number">2</span>,</span><br><span class="line">                                       dilate=replace_stride_with_dilation[<span class="number">2</span>])</span><br><span class="line">        self.avgpool = nn.AdaptiveAvgPool2d((<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        self.fc = nn.Linear(<span class="number">512</span> * block.expansion, num_classes)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">            <span class="keyword">if</span> isinstance(m, nn.Conv2d):</span><br><span class="line">                nn.init.kaiming_normal_(m.weight, mode=<span class="string">'fan_out'</span>, nonlinearity=<span class="string">'relu'</span>)</span><br><span class="line">            <span class="keyword">elif</span> isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):</span><br><span class="line">                nn.init.constant_(m.weight, <span class="number">1</span>)</span><br><span class="line">                nn.init.constant_(m.bias, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Zero-initialize the last BN in each residual branch,</span></span><br><span class="line">        <span class="comment"># so that the residual branch starts with zeros, and each residual block behaves like an identity.</span></span><br><span class="line">        <span class="comment"># This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677</span></span><br><span class="line">        <span class="keyword">if</span> zero_init_residual:</span><br><span class="line">            <span class="keyword">for</span> m <span class="keyword">in</span> self.modules():</span><br><span class="line">                <span class="keyword">if</span> isinstance(m, Bottleneck):</span><br><span class="line">                    nn.init.constant_(m.bn3.weight, <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">elif</span> isinstance(m, BasicBlock):</span><br><span class="line">                    nn.init.constant_(m.bn2.weight, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_make_layer</span><span class="params">(self, block, planes, blocks, stride=<span class="number">1</span>, dilate=False)</span>:</span></span><br><span class="line">        norm_layer = self._norm_layer</span><br><span class="line">        downsample = <span class="literal">None</span></span><br><span class="line">        previous_dilation = self.dilation</span><br><span class="line">        <span class="keyword">if</span> dilate:</span><br><span class="line">            self.dilation *= stride</span><br><span class="line">            stride = <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> self.inplanes != planes * block.expansion:</span><br><span class="line">            downsample = nn.Sequential(</span><br><span class="line">                conv1x1(self.inplanes, planes * block.expansion, stride),</span><br><span class="line">                norm_layer(planes * block.expansion),</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,</span><br><span class="line">                            self.base_width, previous_dilation, norm_layer))</span><br><span class="line">        self.inplanes = planes * block.expansion</span><br><span class="line">        <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1</span>, blocks):</span><br><span class="line">            layers.append(block(self.inplanes, planes, groups=self.groups,</span><br><span class="line">                                base_width=self.base_width, dilation=self.dilation,</span><br><span class="line">                                norm_layer=norm_layer))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.bn1(x)</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        x = self.maxpool(x)</span><br><span class="line"></span><br><span class="line">        x = self.layer1(x)</span><br><span class="line">        x = self.layer2(x)</span><br><span class="line">        x = self.layer3(x)</span><br><span class="line">        x = self.layer4(x)</span><br><span class="line"></span><br><span class="line">        x = self.avgpool(x)</span><br><span class="line">        x = torch.flatten(x, <span class="number">1</span>)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_resnet</span><span class="params">(arch, block, layers, pretrained, progress, **kwargs)</span>:</span></span><br><span class="line">    model = ResNet(block, layers, **kwargs)</span><br><span class="line">    <span class="keyword">if</span> pretrained:</span><br><span class="line">        state_dict = load_state_dict_from_url(model_urls[arch],</span><br><span class="line">                                              progress=progress)</span><br><span class="line">        model.load_state_dict(state_dict)</span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet18</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNet-18 model from</span></span><br><span class="line"><span class="string">    `"Deep Residual Learning for Image Recognition" &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnet18'</span>, BasicBlock, [<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], pretrained, progress,</span><br><span class="line">                   **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet34</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNet-34 model from</span></span><br><span class="line"><span class="string">    `"Deep Residual Learning for Image Recognition" &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnet34'</span>, BasicBlock, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], pretrained, progress,</span><br><span class="line">                   **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet50</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNet-50 model from</span></span><br><span class="line"><span class="string">    `"Deep Residual Learning for Image Recognition" &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnet50'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>], pretrained, progress,</span><br><span class="line">                   **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet101</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNet-101 model from</span></span><br><span class="line"><span class="string">    `"Deep Residual Learning for Image Recognition" &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnet101'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>], pretrained, progress,</span><br><span class="line">                   **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnet152</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNet-152 model from</span></span><br><span class="line"><span class="string">    `"Deep Residual Learning for Image Recognition" &lt;https://arxiv.org/pdf/1512.03385.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnet152'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">8</span>, <span class="number">36</span>, <span class="number">3</span>], pretrained, progress,</span><br><span class="line">                   **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnext50_32x4d</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNeXt-50 32x4d model from</span></span><br><span class="line"><span class="string">    `"Aggregated Residual Transformation for Deep Neural Networks" &lt;https://arxiv.org/pdf/1611.05431.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    kwargs[<span class="string">'groups'</span>] = <span class="number">32</span></span><br><span class="line">    kwargs[<span class="string">'width_per_group'</span>] = <span class="number">4</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnext50_32x4d'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>],</span><br><span class="line">                   pretrained, progress, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resnext101_32x8d</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""ResNeXt-101 32x8d model from</span></span><br><span class="line"><span class="string">    `"Aggregated Residual Transformation for Deep Neural Networks" &lt;https://arxiv.org/pdf/1611.05431.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    kwargs[<span class="string">'groups'</span>] = <span class="number">32</span></span><br><span class="line">    kwargs[<span class="string">'width_per_group'</span>] = <span class="number">8</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'resnext101_32x8d'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>],</span><br><span class="line">                   pretrained, progress, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wide_resnet50_2</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""Wide ResNet-50-2 model from</span></span><br><span class="line"><span class="string">    `"Wide Residual Networks" &lt;https://arxiv.org/pdf/1605.07146.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The model is the same as ResNet except for the bottleneck number of channels</span></span><br><span class="line"><span class="string">    which is twice larger in every block. The number of channels in outer 1x1</span></span><br><span class="line"><span class="string">    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048</span></span><br><span class="line"><span class="string">    channels, and in Wide ResNet-50-2 has 2048-1024-2048.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    kwargs[<span class="string">'width_per_group'</span>] = <span class="number">64</span> * <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'wide_resnet50_2'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">3</span>],</span><br><span class="line">                   pretrained, progress, **kwargs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wide_resnet101_2</span><span class="params">(pretrained=False, progress=True, **kwargs)</span>:</span></span><br><span class="line">    <span class="string">r"""Wide ResNet-101-2 model from</span></span><br><span class="line"><span class="string">    `"Wide Residual Networks" &lt;https://arxiv.org/pdf/1605.07146.pdf&gt;`_</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    The model is the same as ResNet except for the bottleneck number of channels</span></span><br><span class="line"><span class="string">    which is twice larger in every block. The number of channels in outer 1x1</span></span><br><span class="line"><span class="string">    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048</span></span><br><span class="line"><span class="string">    channels, and in Wide ResNet-50-2 has 2048-1024-2048.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span></span><br><span class="line"><span class="string">        progress (bool): If True, displays a progress bar of the download to stderr</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    kwargs[<span class="string">'width_per_group'</span>] = <span class="number">64</span> * <span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> _resnet(<span class="string">'wide_resnet101_2'</span>, Bottleneck, [<span class="number">3</span>, <span class="number">4</span>, <span class="number">23</span>, <span class="number">3</span>],</span><br><span class="line">                   pretrained, progress, **kwargs)</span><br></pre></td></tr></table></figure><p></p><hr><h1 id="pth文件"><a href="#pth文件" class="headerlink" title="pth文件"></a>pth文件</h1><p>在阅读官方源码时，我们会注意到官方提供了一系列版本的model_urls，其中，每一个url都是以.pth结尾的。<br>当我下载了对应的文件之后，并不知道如何处理，于是我通过搜索，简单的了解了pth文件的概念与使用方法。<br>简单来说，pth文件就是一个表示Python的模块搜索路径（module search path）的文本文件，在xxx.pth文件里面，会书写一些路径，一行一个。如果我们将xxx.pth文件放在特定位置，则可以让python在加载模块时，读取xxx.pth中指定的路径。<br>下面我使用pytorch对pth文件进行加载操作。<br>首先，我把<a href="https://download.pytorch.org/models/resnet18-5c106cde.pth" target="_blank">ResNet18对应的pth文件</a>下载到桌面。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line"><span class="comment"># pretrained = True就可以使用预训练的模型</span></span><br><span class="line">net = models.resnet18(pretrained = <span class="literal">False</span>)</span><br><span class="line"><span class="comment">#注意，根据model的不同，这里models.xxx的内容也是不同的，比如models.squeezenet1_1</span></span><br><span class="line"></span><br><span class="line">pthfile = <span class="string">r'C:\Users\sheny\Desktop\resnet18-5c106cde.pth'</span><span class="comment">#pth文件所在路径</span></span><br><span class="line">net.load_state_dict(torch.load(pthfile))</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure><p></p><p>输出结果如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">ResNet(</span><br><span class="line">  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)</span><br><span class="line">  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">  (relu): ReLU(inplace=True)</span><br><span class="line">  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)</span><br><span class="line">  (layer1): Sequential(</span><br><span class="line">    (0): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    )</span><br><span class="line">    (1): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer2): Sequential(</span><br><span class="line">    (0): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)</span><br><span class="line">        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer3): Sequential(</span><br><span class="line">    (0): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)</span><br><span class="line">        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (layer4): Sequential(</span><br><span class="line">    (0): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (downsample): Sequential(</span><br><span class="line">        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)</span><br><span class="line">        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      )</span><br><span class="line">    )</span><br><span class="line">    (1): BasicBlock(</span><br><span class="line">      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">      (relu): ReLU(inplace=True)</span><br><span class="line">      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</span><br><span class="line">      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</span><br><span class="line">    )</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))</span><br><span class="line">  (fc): Linear(in_features=512, out_features=1000, bias=True)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p></p><p>这样你就可以看到很详尽的参数设置了。<br>我们还可以加载所有的参数。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">pthfile = <span class="string">r'C:\Users\sheny\Desktop\resnet18-5c106cde.pth'</span></span><br><span class="line"></span><br><span class="line">net = torch.load(pthfile)</span><br><span class="line"></span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure><p></p><p>输出如下：<br></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">OrderedDict([(&apos;conv1.weight&apos;, Parameter containing:</span><br><span class="line">tensor([[[[-1.0419e-02, -6.1356e-03, -1.8098e-03,  ...,  5.6615e-02,</span><br><span class="line">            1.7083e-02, -1.2694e-02],</span><br><span class="line">          [ 1.1083e-02,  9.5276e-03, -1.0993e-01,  ..., -2.7124e-01,</span><br><span class="line">           -1.2907e-01,  3.7424e-03],</span><br><span class="line">          [-6.9434e-03,  5.9089e-02,  2.9548e-01,  ...,  5.1972e-01,</span><br><span class="line">            2.5632e-01,  6.3573e-02],</span><br><span class="line">          ...,</span><br></pre></td></tr></table></figure><p></p><script type="text/javascript" src="/js/src/bai.js"></script></div><div><div><hr style="FILTER:progid:DXImageTransform.Microsoft.Shadow(color:#987cb9,direction:145,strength:15)" width="100%" color="#987cb9" size="1"><div style="text-align:center;color:#555;font-size:16px"><i class="fa fa-hand-o-up" aria-hidden="true"></i> 碰到底线咯 <i class="fa fa-handshake-o" aria-hidden="true"></i> 后面没有啦 <i class="fa fa-hand-o-down" aria-hidden="true"></i></div></div></div><div><div class="my_post_copyright"><script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script><script src="https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js"></script><script src="https://unpkg.com/sweetalert/dist/sweetalert.min.js"></script><p><span>本文标题:</span><a href="/deep-learning20191001184216/">deep learning笔记：使网络能够更深——ResNet简介与pytorch实现</a></p><p><span>文章作者:</span><a href="/" title="访问 高深远 的个人博客">高深远</a></p><p><span>发布时间:</span>2019年10月01日 - 18:42</p><p><span>最后更新:</span>2019年11月02日 - 10:21</p><p><span>原始链接:</span><a href="/deep-learning20191001184216/" title="deep learning笔记：使网络能够更深——ResNet简介与pytorch实现">https://gsy00517.github.io/deep-learning20191001184216/</a> <span class="copy-path" title="点击复制文章链接"><i class="fa fa-clipboard" data-clipboard-text="https://gsy00517.github.io/deep-learning20191001184216/" aria-label="复制成功！"></i></span></p><p><span>许可协议:</span><i class="fa fa-creative-commons"></i> <a rel="license" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" title="Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)">署名-非商业性使用-禁止演绎 4.0 国际</a> 转载请保留原文链接及作者。</p></div><script>var clipboard=new Clipboard(".fa-clipboard");$(".fa-clipboard").click(function(){clipboard.on("success",function(){swal({title:"复制成功",text:"感谢您的阅读与参考！欢迎留下任何建议噢！",icon:"success",showConfirmButton:!0})})})</script></div><footer class="post-footer"><div class="post-tags"><a href="/tags/深度学习/" rel="tag"><i class="fa fa-tag"></i> 深度学习</a> <a href="/tags/论文分享/" rel="tag"><i class="fa fa-tag"></i> 论文分享</a> <a href="/tags/代码实现/" rel="tag"><i class="fa fa-tag"></i> 代码实现</a> <a href="/tags/pytorch/" rel="tag"><i class="fa fa-tag"></i> pytorch</a></div><div class="post-widgets"><div class="wp_rating"><div id="wpac-rating"></div></div></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/deep-learning20191001151454/" rel="next" title="deep learning笔记：学习率衰减与批归一化"><i class="fa fa-chevron-left"></i> deep learning笔记：学习率衰减与批归一化</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/hexo20191006232704/" rel="prev" title="hexo笔记：ssh与https以及双线部署的一些注意点">hexo笔记：ssh与https以及双线部署的一些注意点 <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"></div></div></div><div class="comments" id="comments"></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/lufei.jpg" alt="高深远"><p class="site-author-name" itemprop="name">高深远</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">30</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">6</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">20</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-blogroll motion-element links-of-blogroll-inline"><div class="links-of-blogroll-title"><i class="fa fa-fw fa-link"></i> 网站收藏</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="https://www.runoob.com/" title="菜鸟教程" target="_blank">菜鸟教程</a></li><li class="links-of-blogroll-item"><a href="https://paperswithcode.com/" title="PaperWithCode" target="_blank">PaperWithCode</a></li><li class="links-of-blogroll-item"><a href="https://www.jiqizhixin.com/sota" title="机器之心" target="_blank">机器之心</a></li><li class="links-of-blogroll-item"><a href="http://pytorch123.com/" title="Pytorch中文文档" target="_blank">Pytorch中文文档</a></li></ul></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#简介"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#论文"><span class="nav-number">2.</span> <span class="nav-text">论文</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#自己实现"><span class="nav-number">3.</span> <span class="nav-text">自己实现</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#出现的问题"><span class="nav-number">4.</span> <span class="nav-text">出现的问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#softmax输出全为1"><span class="nav-number">4.1.</span> <span class="nav-text">softmax输出全为1</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#bias"><span class="nav-number">4.2.</span> <span class="nav-text">bias</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#官方源码"><span class="nav-number">5.</span> <span class="nav-text">官方源码</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#pth文件"><span class="nav-number">6.</span> <span class="nav-text">pth文件</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2019</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">高深远</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span class="post-meta-item-text">Site words total count&#58;</span> <span title="Site words total count">48.4k</span></div><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_site_pv">访客已留下<span id="busuanzi_value_site_pv"></span>个脚印 </span><span id="busuanzi_container_site_uv">你是第<span id="busuanzi_value_site_uv"></span>位小伙伴</span></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/lib/three/three.min.js"></script><script type="text/javascript" src="/lib/three/three-waves.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine/dist/Valine.min.js"></script><script type="text/javascript">var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: false,
        appId: 'SVKPF4oiwJLMtpySQxvJLnLm-gzGzoHsz',
        appKey: '46OfvvEe65XMeUi79STU895I',
        placeholder: '动动手指，写下您的意见、疑惑或者鼓励吧！留下您的邮箱，这样您就可以收到别人的回复啦！',
        avatar:'wavatar',
        guest_info:guest,
        pageSize:'10' || 10,
    });

    var infoEle = document.querySelector('#comments .info');
    if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0){
    infoEle.childNodes.forEach(function(item) {
    item.parentNode.removeChild(item);
    });
  }</script><script type="text/javascript">function proceedsearch(){$("body").append('<div class="search-popup-overlay local-search-pop-overlay"></div>').css("overflow","hidden"),$(".search-popup-overlay").click(onPopupClose),$(".popup").toggle();var t=$("#local-search-input");t.attr("autocapitalize","none"),t.attr("autocorrect","off"),t.focus()}var isfetched=!1,isXml=!0,search_path="search.xml";0===search_path.length?search_path="search.xml":/json$/i.test(search_path)&&(isXml=!1);var path="/"+search_path,onPopupClose=function(t){$(".popup").hide(),$("#local-search-input").val(""),$(".search-result-list").remove(),$("#no-result").remove(),$(".local-search-pop-overlay").remove(),$("body").css("overflow","")},searchFunc=function(t,e,o){"use strict";$("body").append('<div class="search-popup-overlay local-search-pop-overlay"><div id="search-loading-icon"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div>').css("overflow","hidden"),$("#search-loading-icon").css("margin","20% auto 0 auto").css("text-align","center"),$.ajax({url:t,dataType:isXml?"xml":"json",async:!0,success:function(t){isfetched=!0,$(".popup").detach().appendTo(".header-inner");var n=isXml?$("entry",t).map(function(){return{title:$("title",this).text(),content:$("content",this).text(),url:$("url",this).text()}}).get():t,r=document.getElementById(e),s=document.getElementById(o),a=function(){var t=r.value.trim().toLowerCase(),e=t.split(/[\s\-]+/);e.length>1&&e.push(t);var o=[];if(t.length>0&&n.forEach(function(n){function r(e,o,n,r){for(var s=r[r.length-1],a=s.position,i=s.word,l=[],h=0;a+i.length<=n&&0!=r.length;){i===t&&h++,l.push({position:a,length:i.length});var p=a+i.length;for(r.pop();0!=r.length&&(s=r[r.length-1],a=s.position,i=s.word,p>a);)r.pop()}return c+=h,{hits:l,start:o,end:n,searchTextCount:h}}function s(t,e){var o="",n=e.start;return e.hits.forEach(function(e){o+=t.substring(n,e.position);var r=e.position+e.length;o+='<b class="search-keyword">'+t.substring(e.position,r)+"</b>",n=r}),o+=t.substring(n,e.end)}var a=!1,i=0,c=0,l=n.title.trim(),h=l.toLowerCase(),p=n.content.trim().replace(/<[^>]+>/g,""),u=p.toLowerCase(),f=decodeURIComponent(n.url),d=[],g=[];if(""!=l&&(e.forEach(function(t){function e(t,e,o){var n=t.length;if(0===n)return[];var r=0,s=[],a=[];for(o||(e=e.toLowerCase(),t=t.toLowerCase());(s=e.indexOf(t,r))>-1;)a.push({position:s,word:t}),r=s+n;return a}d=d.concat(e(t,h,!1)),g=g.concat(e(t,u,!1))}),(d.length>0||g.length>0)&&(a=!0,i=d.length+g.length)),a){[d,g].forEach(function(t){t.sort(function(t,e){return e.position!==t.position?e.position-t.position:t.word.length-e.word.length})});var v=[];0!=d.length&&v.push(r(l,0,l.length,d));for(var $=[];0!=g.length;){var C=g[g.length-1],m=C.position,x=C.word,w=m-20,y=m+80;0>w&&(w=0),y<m+x.length&&(y=m+x.length),y>p.length&&(y=p.length),$.push(r(p,w,y,g))}$.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hits.length!==e.hits.length?e.hits.length-t.hits.length:t.start-e.start});var T=parseInt("1");T>=0&&($=$.slice(0,T));var b="";b+=0!=v.length?"<li><a href='"+f+"' class='search-result-title'>"+s(l,v[0])+"</a>":"<li><a href='"+f+"' class='search-result-title'>"+l+"</a>",$.forEach(function(t){b+="<a href='"+f+'\'><p class="search-result">'+s(p,t)+"...</p></a>"}),b+="</li>",o.push({item:b,searchTextCount:c,hitCount:i,id:o.length})}}),1===e.length&&""===e[0])s.innerHTML='<div id="no-result"><i class="fa fa-search fa-5x" /></div>';else if(0===o.length)s.innerHTML='<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>';else{o.sort(function(t,e){return t.searchTextCount!==e.searchTextCount?e.searchTextCount-t.searchTextCount:t.hitCount!==e.hitCount?e.hitCount-t.hitCount:e.id-t.id});var a='<ul class="search-result-list">';o.forEach(function(t){a+=t.item}),a+="</ul>",s.innerHTML=a}};r.addEventListener("input",a),$(".local-search-pop-overlay").remove(),$("body").css("overflow",""),proceedsearch()}})};$(".popup-trigger").click(function(t){t.stopPropagation(),isfetched===!1?searchFunc(path,"local-search-input","local-search-result"):proceedsearch()}),$(".popup-btn-close").click(onPopupClose),$(".popup").click(function(t){t.stopPropagation()}),$(document).on("keyup",function(t){var e=27===t.which&&$(".search-popup").is(":visible");e&&onPopupClose()})</script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script><script>AV.initialize("SVKPF4oiwJLMtpySQxvJLnLm-gzGzoHsz","46OfvvEe65XMeUi79STU895I")</script><script>function showTime(e){var t=new AV.Query(e),n=[],o=$(".leancloud_visitors");o.each(function(){n.push($(this).attr("id").trim())}),t.containedIn("url",n),t.find().done(function(e){var t=".leancloud-visitors-count";if(0===e.length)return void o.find(t).text(0);for(var i=0;i<e.length;i++){var r=e[i],s=r.get("url"),l=r.get("time"),c=document.getElementById(s);$(c).find(t).text(l)}for(var i=0;i<n.length;i++){var s=n[i],c=document.getElementById(s),u=$(c).find(t);""==u.text()&&u.text(0)}}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(e){var t=$(".leancloud_visitors"),n=t.attr("id").trim(),o=t.attr("data-flag-title").trim(),i=new AV.Query(e);i.equalTo("url",n),i.find({success:function(t){if(t.length>0){var i=t[0];i.fetchWhenSave(!0),i.increment("time"),i.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var r=new e,s=new AV.ACL;s.setPublicReadAccess(!0),s.setPublicWriteAccess(!0),r.setACL(s),r.set("title",o),r.set("url",n),r.set("time",1),r.save(null,{success:function(e){var t=$(document.getElementById(n));t.find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):$(".post-title-link").length>1&&showTime(e)})</script><script>!function(){var t=document.createElement("script"),s=window.location.protocol.split(":")[0];"https"===s?t.src="https://zz.bdstatic.com/linksubmit/push.js":t.src="http://push.zhanzhang.baidu.com/push.js";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script><script type="text/javascript">wpac_init=window.wpac_init||[],wpac_init.push({widget:"Rating",id:21228,el:"wpac-rating",color:"fc6423"}),function(){if(!("WIDGETPACK_LOADED"in window)){WIDGETPACK_LOADED=!0;var e=document.createElement("script");e.type="text/javascript",e.async=!0,e.src="//embed.widgetpack.com/widget.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t.nextSibling)}}()</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><canvas class="fireworks" style="position:fixed;left:0;top:0;z-index:1;pointer-events:none"></canvas><script type="text/javascript" src="//cdn.bootcss.com/animejs/2.2.0/anime.min.js"></script><script type="text/javascript" src="/js/src/fireworks.js"></script><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({pluginRootPath:"live2dw/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!0,log:!1,model:{jsonPath:"/live2dw/assets/hijiki.model.json"},display:{position:"left",width:250,height:500},mobile:{show:!1},react:{opacity:.7}})</script></body></html><script type="text/javascript" src="/js/src/crash_cheat.js"></script><!-- rebuild by neat -->